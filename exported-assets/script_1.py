# –°–æ–∑–¥–∞–¥–∏–º –¥–µ—Ç–∞–ª—å–Ω—É—é —Ç–∞–±–ª–∏—Ü—É –∞–ª–≥–æ—Ä–∏—Ç–º–æ–≤ –∏ –º–µ—Ç–æ–¥–æ–≤ –¥–ª—è —É–º–Ω–æ–π —Å–∏—Å—Ç–µ–º—ã –æ–±—É—á–µ–Ω–∏—è
algorithms_data = {
    '–ú–æ–¥—É–ª—å': [
        'Context Analyzer',
        'Context Analyzer', 
        'Context Analyzer',
        'Multi-Agent Optimizer',
        'Multi-Agent Optimizer',
        'Multi-Agent Optimizer',
        'Adaptive Loss Controller',
        'Adaptive Loss Controller',
        'Adaptive Loss Controller',
        'Dynamic Attention Supervisor',
        'Dynamic Attention Supervisor',
        'Dynamic Attention Supervisor',
        'Meta-Learning Engine',
        'Meta-Learning Engine',
        'Meta-Learning Engine',
        'Feedback Loop Manager',
        'Feedback Loop Manager',
        'Risk Assessment Module',
        'Risk Assessment Module',
        'Rollback Controller'
    ],
    '–ê–ª–≥–æ—Ä–∏—Ç–º/–ú–µ—Ç–æ–¥': [
        'Bayesian Phase Classification',
        'Temporal Pattern Analysis', 
        'Multi-Scale Trend Detection',
        'MARL (Multi-Agent RL)',
        'Consensus Algorithm',
        'Nash Equilibrium Solver',
        'Gradient-Based Reweighting',
        'Dynamic Tversky Loss',
        'Focal Loss Adaptation',
        'Attention Flow Analysis',
        'Monotonic Alignment Search',
        'Self-Supervised Attention',
        'Model-Agnostic Meta-Learning',
        'Episodic Memory Networks',
        'Few-Shot Learning',
        'Kalman Filtering',
        'Cross-Correlation Analysis',
        'Monte Carlo Simulation',
        'Confidence Intervals',
        'State Checkpointing'
    ],
    '–¢–µ—Ö–Ω–∏—á–µ—Å–∫–∞—è —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è': [
        'Gaussian Mixture Models –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ —Ñ–∞–∑',
        'LSTM + Attention –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ä—è–¥–æ–≤',
        'Wavelet Transform + Statistical Tests',
        'PPO/SAC –∞–≥–µ–Ω—Ç—ã —Å shared experience replay',
        'Byzantine Fault Tolerant consensus',
        'Iterative best response —Å –∫–æ–Ω–≤–µ—Ä–≥–µ–Ω—Ü–∏–µ–π',
        'Automated gradient scaling –ø–æ GradNorm',
        '–ê–¥–∞–ø—Ç–∏–≤–Ω—ã–µ Œ±,Œ≤ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –Ω–∞ –æ—Å–Ω–æ–≤–µ FP/FN',
        'Dynamic Œ≥ factor –æ—Å–Ω–æ–≤–∞–Ω–Ω—ã–π –Ω–∞ class difficulty',
        'Graph Neural Networks –¥–ª—è attention flow',
        'Dynamic Programming —Å constraints',
        'Contrastive learning –¥–ª—è attention maps',
        'Gradient-based meta-optimization (MAML)',
        'Differentiable Neural Dictionary',
        'Prototypical Networks –¥–ª—è task adaptation',
        'Extended Kalman Filter –¥–ª—è –Ω–µ–ª–∏–Ω–µ–π–Ω—ã—Ö —Å–∏—Å—Ç–µ–º',
        'Sliding window cross-correlation',
        'Importance sampling –¥–ª—è rare events',
        'Bootstrap sampling –¥–ª—è uncertainty estimation',
        'Copy-on-write memory management'
    ],
    '–ü–∞—Ä–∞–º–µ—Ç—Ä—ã –Ω–∞—Å—Ç—Ä–æ–π–∫–∏': [
        'n_components=3-5, covariance_type="full"',
        'hidden_size=256, seq_len=50, attention_heads=8',
        'wavelet="db4", levels=4, significance=0.05',
        'lr=1e-4, buffer_size=1M, batch_size=256',
        'f=1/3, timeout=30s, quorum=2/3',
        'tolerance=1e-6, max_iterations=100',
        'update_freq=10, momentum=0.9',
        'A=0.3, B=0.4, eps=1e-8',
        'alpha=0.25, gamma=2.0, reduction="mean"',
        'hidden_dim=512, num_layers=3, dropout=0.1',
        'beam_width=8, max_iterations=500',
        'temperature=0.1, projection_dim=128',
        'inner_lr=1e-3, outer_lr=1e-4, n_inner_steps=5',
        'memory_size=1000, key_dim=128, value_dim=256',
        'n_support=5, n_query=15, distance="cosine"',
        'Q_noise=1e-4, R_noise=1e-2, P_init=1e-1',
        'window_size=20, max_lag=10',
        'n_samples=10000, confidence=0.95',
        'n_bootstrap=1000, alpha=0.05',
        'checkpoint_freq=100, max_checkpoints=10'
    ]
}

algorithms_df = pd.DataFrame(algorithms_data)
print("–î–µ—Ç–∞–ª—å–Ω–∞—è —Å–ø–µ—Ü–∏—Ñ–∏–∫–∞—Ü–∏—è –∞–ª–≥–æ—Ä–∏—Ç–º–æ–≤ –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω–æ–π —Å–∏—Å—Ç–µ–º—ã –æ–±—É—á–µ–Ω–∏—è:")
print("=" * 120)
print(algorithms_df.to_string(index=False))

# –ì—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∞ –ø–æ –º–æ–¥—É–ª—è–º –¥–ª—è –ª—É—á—à–µ–≥–æ –ø–æ–Ω–∏–º–∞–Ω–∏—è
print("\n\n" + "="*50)
print("–ì–†–£–ü–ü–ò–†–û–í–ö–ê –ü–û –ú–û–î–£–õ–Ø–ú:")
print("="*50)

for module in algorithms_df['–ú–æ–¥—É–ª—å'].unique():
    module_data = algorithms_df[algorithms_df['–ú–æ–¥—É–ª—å'] == module]
    print(f"\nüîπ {module}:")
    for _, row in module_data.iterrows():
        print(f"  ‚Ä¢ {row['–ê–ª–≥–æ—Ä–∏—Ç–º/–ú–µ—Ç–æ–¥']}")
        print(f"    –†–µ–∞–ª–∏–∑–∞—Ü–∏—è: {row['–¢–µ—Ö–Ω–∏—á–µ—Å–∫–∞—è —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è']}")
        print(f"    –ü–∞—Ä–∞–º–µ—Ç—Ä—ã: {row['–ü–∞—Ä–∞–º–µ—Ç—Ä—ã –Ω–∞—Å—Ç—Ä–æ–π–∫–∏']}")
        print()

# –°–æ—Ö—Ä–∞–Ω–∏–º –≤ CSV
algorithms_df.to_csv('intelligent_system_algorithms.csv', index=False, encoding='utf-8')
print(f"\nüìÅ –¢–∞–±–ª–∏—Ü–∞ –∞–ª–≥–æ—Ä–∏—Ç–º–æ–≤ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤ —Ñ–∞–π–ª: intelligent_system_algorithms.csv")