# –°–æ–∑–¥–∞–µ–º –¥–µ—Ç–∞–ª—å–Ω—ã–µ —Ä–µ—à–µ–Ω–∏—è –∫–æ–¥–∞ –¥–ª—è –æ—Å–Ω–æ–≤–Ω—ã—Ö –ø—Ä–æ–±–ª–µ–º
solutions_code = {}

# 1. –†–µ—à–µ–Ω–∏–µ –ø—Ä–æ–±–ª–µ–º—ã tuple object has no attribute device
solutions_code['device_fix'] = """
# –§–ê–ô–õ: data_utils.py
# –ü–†–û–ë–õ–ï–ú–ê: AttributeError: 'tuple' object has no attribute 'device' –≤ train.py:897

import torch
from torch.utils.data import DataLoader

def custom_collate_fn(batch):
    '''
    –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω–∞—è collate_fn –¥–ª—è –ø—Ä–∞–≤–∏–ª—å–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏ device transfer
    '''
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ batch –Ω–µ –ø—É—Å—Ç–æ–π
    if not batch:
        return torch.tensor([]), torch.tensor([])
    
    # –†–∞–∑–¥–µ–ª—è–µ–º –¥–∞–Ω–Ω—ã–µ –∏ –º–µ—Ç–∫–∏
    data_batch = []
    target_batch = []
    
    for sample in batch:
        if isinstance(sample, (list, tuple)) and len(sample) >= 2:
            data, target = sample[0], sample[1]
            
            # –£–±–µ–∂–¥–∞–µ–º—Å—è, —á—Ç–æ data —ç—Ç–æ —Ç–µ–Ω–∑–æ—Ä
            if not isinstance(data, torch.Tensor):
                data = torch.tensor(data)
            
            # –£–±–µ–∂–¥–∞–µ–º—Å—è, —á—Ç–æ target —ç—Ç–æ —Ç–µ–Ω–∑–æ—Ä
            if not isinstance(target, torch.Tensor):
                target = torch.tensor(target)
                
            data_batch.append(data)
            target_batch.append(target)
    
    # –°—Ç–µ–∫–∏—Ä—É–µ–º —Ç–µ–Ω–∑–æ—Ä—ã
    try:
        data_tensor = torch.stack(data_batch)
        target_tensor = torch.stack(target_batch)
    except RuntimeError as e:
        # –ï—Å–ª–∏ —Ä–∞–∑–º–µ—Ä—ã –Ω–µ —Å–æ–≤–ø–∞–¥–∞—é—Ç, –∏—Å–ø–æ–ª—å–∑—É–µ–º pad_sequence
        from torch.nn.utils.rnn import pad_sequence
        data_tensor = pad_sequence(data_batch, batch_first=True)
        target_tensor = pad_sequence(target_batch, batch_first=True)
    
    return data_tensor, target_tensor

# –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï –í train.py —Å—Ç—Ä–æ–∫–∞ 897:
def train_step_fixed(model, data_loader, device):
    for batch_idx, batch_data in enumerate(data_loader):
        # –ë–´–õ–û: device = x.device  # –≥–¥–µ x –º–æ–∂–µ—Ç –±—ã—Ç—å tuple
        # –°–¢–ê–õ–û:
        if isinstance(batch_data, (list, tuple)):
            x, y = batch_data
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ x - —ç—Ç–æ —Ç–µ–Ω–∑–æ—Ä
            if isinstance(x, torch.Tensor):
                device = x.device
            else:
                # –ï—Å–ª–∏ x –Ω–µ —Ç–µ–Ω–∑–æ—Ä, –∏—Å–ø–æ–ª—å–∑—É–µ–º –ø–µ—Ä–µ–¥–∞–Ω–Ω—ã–π device
                x = x.to(device) if hasattr(x, 'to') else torch.tensor(x).to(device)
                y = y.to(device) if hasattr(y, 'to') else torch.tensor(y).to(device)
        else:
            x = batch_data.to(device)
        
        # –ü—Ä–æ–¥–æ–ª–∂–∞–µ–º –æ–±—É—á–µ–Ω–∏–µ...
"""

# 2. SQLite WAL fix
solutions_code['sqlite_wal_fix'] = """
# –§–ê–ô–õ: optimization_engine.py
# –ü–†–û–ë–õ–ï–ú–ê: SQLite database locked error

import sqlite3
import time
import optuna
from sqlalchemy import create_engine, pool

class RobustOptimizationEngine:
    def __init__(self):
        self.setup_sqlite_wal()
    
    def setup_sqlite_wal(self):
        '''
        –ù–∞—Å—Ç—Ä–æ–π–∫–∞ SQLite –¥–ª—è —Ä–∞–±–æ—Ç—ã –≤ WAL —Ä–µ–∂–∏–º–µ —Å retry –º–µ—Ö–∞–Ω–∏–∑–º–æ–º
        '''
        storage_path = "smart_tuner/optuna_studies.db"
        
        # –ü—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–∞—è –Ω–∞—Å—Ç—Ä–æ–π–∫–∞ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö
        conn = None
        try:
            conn = sqlite3.connect(storage_path, timeout=30)
            
            # –í–∫–ª—é—á–∞–µ–º WAL —Ä–µ–∂–∏–º –¥–ª—è –ª—É—á—à–µ–π –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–Ω–æ—Å—Ç–∏
            conn.execute('PRAGMA journal_mode=WAL;')
            conn.execute('PRAGMA synchronous=NORMAL;')
            conn.execute('PRAGMA cache_size=10000;')
            conn.execute('PRAGMA temp_store=MEMORY;')
            conn.execute('PRAGMA mmap_size=268435456;')  # 256MB
            conn.execute('PRAGMA busy_timeout=30000;')   # 30 —Å–µ–∫—É–Ω–¥
            
            conn.commit()
            print("‚úÖ SQLite –Ω–∞—Å—Ç—Ä–æ–µ–Ω –≤ WAL —Ä–µ–∂–∏–º–µ")
            
        except sqlite3.Error as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ SQLite: {e}")
        finally:
            if conn:
                conn.close()
    
    def create_study_with_retry(self, study_name=None, max_retries=5):
        '''
        –°–æ–∑–¥–∞–Ω–∏–µ Optuna study —Å retry –º–µ—Ö–∞–Ω–∏–∑–º–æ–º
        '''
        storage_url = f"sqlite:///smart_tuner/optuna_studies.db"
        
        for attempt in range(max_retries):
            try:
                # –°–æ–∑–¥–∞–µ–º engine —Å connection pooling
                engine = create_engine(
                    storage_url,
                    poolclass=pool.NullPool,  # –û—Ç–∫–ª—é—á–∞–µ–º pooling
                    connect_args={
                        "timeout": 30,
                        "check_same_thread": False,
                        "isolation_level": None  # Autocommit —Ä–µ–∂–∏–º
                    }
                )
                
                self.study = optuna.create_study(
                    study_name=study_name,
                    storage=storage_url,
                    direction="minimize",
                    load_if_exists=True
                )
                
                print(f"‚úÖ Optuna study —Å–æ–∑–¥–∞–Ω: {study_name}")
                return self.study
                
            except Exception as e:
                if "database is locked" in str(e) and attempt < max_retries - 1:
                    wait_time = (2 ** attempt) + random.uniform(0, 1)
                    print(f"‚ö†Ô∏è –ë–∞–∑–∞ –∑–∞–±–ª–æ–∫–∏—Ä–æ–≤–∞–Ω–∞, –æ–∂–∏–¥–∞–Ω–∏–µ {wait_time:.1f}—Å...")
                    time.sleep(wait_time)
                    continue
                else:
                    print(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è study: {e}")
                    raise
                    
        raise Exception("–ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å study –ø–æ—Å–ª–µ –≤—Å–µ—Ö –ø–æ–ø—ã—Ç–æ–∫")
"""

# 3. MLflow nested runs fix
solutions_code['mlflow_nested_fix'] = """
# –§–ê–ô–õ: smart_tuner_main.py
# –ü–†–û–ë–õ–ï–ú–ê: MLflow parameter overwrite error

import mlflow
import uuid

class MLflowManager:
    def __init__(self, experiment_name):
        self.experiment_name = experiment_name
        self.parent_run = None
        
    def start_parent_run(self, run_name=None):
        '''
        –ó–∞–ø—É—Å–∫ —Ä–æ–¥–∏—Ç–µ–ª—å—Å–∫–æ–≥–æ run –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏
        '''
        mlflow.set_experiment(self.experiment_name)
        
        self.parent_run = mlflow.start_run(
            run_name=run_name or f"smart_tuner_{int(time.time())}"
        )
        
        # –õ–æ–≥–∏—Ä—É–µ–º –æ–±—â–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã —Ç–æ–ª—å–∫–æ –æ–¥–∏–Ω —Ä–∞–∑
        mlflow.log_param("optimization_engine", "smart_tuner_v2")
        mlflow.log_param("framework", "tacotron2")
        
        print(f"‚úÖ –†–æ–¥–∏—Ç–µ–ª—å—Å–∫–∏–π run –∑–∞–ø—É—â–µ–Ω: {self.parent_run.info.run_id}")
        return self.parent_run
    
    def start_trial_run(self, trial_number, trial_params):
        '''
        –ó–∞–ø—É—Å–∫ –¥–æ—á–µ—Ä–Ω–µ–≥–æ run –¥–ª—è –∫–∞–∂–¥–æ–≥–æ trial
        '''
        if not self.parent_run:
            raise Exception("–†–æ–¥–∏—Ç–µ–ª—å—Å–∫–∏–π run –Ω–µ –∑–∞–ø—É—â–µ–Ω!")
        
        # –°–æ–∑–¥–∞–µ–º —É–Ω–∏–∫–∞–ª—å–Ω–æ–µ –∏–º—è –¥–ª—è trial
        trial_name = f"trial_{trial_number}_{uuid.uuid4().hex[:8]}"
        
        trial_run = mlflow.start_run(
            run_name=trial_name,
            nested=True
        )
        
        # –õ–æ–≥–∏—Ä—É–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã trial –±–µ–∑ –∫–æ–Ω—Ñ–ª–∏–∫—Ç–æ–≤
        trial_params_prefixed = {
            f"trial_{trial_number}_{k}": v for k, v in trial_params.items()
        }
        
        mlflow.log_params(trial_params_prefixed)
        mlflow.log_param("trial_number", trial_number)
        
        print(f"‚úÖ Trial run –∑–∞–ø—É—â–µ–Ω: {trial_number}")
        return trial_run
    
    def log_trial_metrics(self, metrics, step=None):
        '''
        –ë–µ–∑–æ–ø–∞—Å–Ω–æ–µ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –º–µ—Ç—Ä–∏–∫ trial
        '''
        try:
            for metric_name, value in metrics.items():
                if isinstance(value, (int, float)) and not math.isnan(value):
                    mlflow.log_metric(metric_name, value, step=step)
        except Exception as e:
            print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è –º–µ—Ç—Ä–∏–∫: {e}")
    
    def end_trial_run(self):
        '''
        –ó–∞–≤–µ—Ä—à–µ–Ω–∏–µ trial run
        '''
        try:
            mlflow.end_run()
        except Exception as e:
            print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è trial run: {e}")
    
    def end_parent_run(self):
        '''
        –ó–∞–≤–µ—Ä—à–µ–Ω–∏–µ —Ä–æ–¥–∏—Ç–µ–ª—å—Å–∫–æ–≥–æ run
        '''
        try:
            if self.parent_run:
                mlflow.end_run()
                self.parent_run = None
        except Exception as e:
            print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è parent run: {e}")

# –ò–°–ü–û–õ–¨–ó–û–í–ê–ù–ò–ï:
# mlflow_manager = MLflowManager("tacotron2_optimization")
# mlflow_manager.start_parent_run("smart_tuner_experiment")
# 
# for trial in trials:
#     trial_run = mlflow_manager.start_trial_run(trial.number, trial.params)
#     # ... –æ–±—É—á–µ–Ω–∏–µ ...
#     mlflow_manager.log_trial_metrics({"loss": loss_value})
#     mlflow_manager.end_trial_run()
#
# mlflow_manager.end_parent_run()
"""

# 4. Memory cleanup fix
solutions_code['memory_cleanup_fix'] = """
# –§–ê–ô–õ: smart_tuner_main.py
# –ü–†–û–ë–õ–ï–ú–ê: –£—Ç–µ—á–∫–∏ –ø–∞–º—è—Ç–∏ –≤ –¥–æ–ª–≥–∏—Ö trial

import gc
import torch
import psutil
import time

class MemoryManager:
    def __init__(self, memory_threshold=85):
        self.memory_threshold = memory_threshold
        self.last_cleanup = time.time()
        
    def cleanup_trial_memory(self, force=False):
        '''
        –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–∞—è –æ—á–∏—Å—Ç–∫–∞ –ø–∞–º—è—Ç–∏ –ø–æ—Å–ª–µ trial
        '''
        current_time = time.time()
        memory_percent = psutil.virtual_memory().percent
        
        # –û—á–∏—â–∞–µ–º –∫–∞–∂–¥—ã–µ 30 —Å–µ–∫—É–Ω–¥ –∏–ª–∏ –ø—Ä–∏ –ø—Ä–µ–≤—ã—à–µ–Ω–∏–∏ –ø–æ—Ä–æ–≥–∞
        if force or (current_time - self.last_cleanup > 30) or memory_percent > self.memory_threshold:
            
            # Python garbage collection
            collected = gc.collect()
            
            # PyTorch cache cleanup
            if torch.cuda.is_available():
                torch.cuda.empty_cache()
                torch.cuda.synchronize()
                
            # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –æ—á–∏—Å—Ç–∫–∞ –¥–ª—è del –æ–±—ä–µ–∫—Ç–æ–≤
            for obj in gc.get_objects():
                if isinstance(obj, torch.Tensor) and obj.device.type == 'cuda':
                    del obj
            
            gc.collect()  # –ï—â–µ –æ–¥–∏–Ω –ø—Ä–æ—Ö–æ–¥
            
            self.last_cleanup = current_time
            new_memory_percent = psutil.virtual_memory().percent
            
            print(f"üßπ –û—á–∏—Å—Ç–∫–∞ –ø–∞–º—è—Ç–∏: {memory_percent:.1f}% -> {new_memory_percent:.1f}% "
                  f"(–æ—Å–≤–æ–±–æ–∂–¥–µ–Ω–æ {collected} –æ–±—ä–µ–∫—Ç–æ–≤)")
    
    def monitor_memory_usage(self):
        '''
        –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –ø–∞–º—è—Ç–∏
        '''
        memory = psutil.virtual_memory()
        gpu_memory = None
        
        if torch.cuda.is_available():
            gpu_memory = torch.cuda.memory_summary()
            
        return {
            "ram_percent": memory.percent,
            "ram_available": memory.available // (1024**3),  # GB
            "gpu_memory": gpu_memory
        }
    
    def check_memory_health(self):
        '''
        –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–æ—Å—Ç–æ—è–Ω–∏—è –ø–∞–º—è—Ç–∏
        '''
        stats = self.monitor_memory_usage()
        
        if stats["ram_percent"] > 90:
            print(f"‚ö†Ô∏è –ö—Ä–∏—Ç–∏—á–µ—Å–∫–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ RAM: {stats['ram_percent']:.1f}%")
            self.cleanup_trial_memory(force=True)
            return False
            
        return True

# –ò–ù–¢–ï–ì–†–ê–¶–ò–Ø –í –û–ë–£–ß–ï–ù–ò–ï:
def tts_objective_function_with_memory_management(trial):
    memory_manager = MemoryManager()
    
    try:
        # –ü–æ–ª—É—á–∞–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã trial
        suggested_params = get_trial_params(trial)
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–∞–º—è—Ç—å –ø–µ—Ä–µ–¥ –Ω–∞—á–∞–ª–æ–º
        if not memory_manager.check_memory_health():
            print("‚ö†Ô∏è –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –ø–∞–º—è—Ç–∏ –¥–ª—è trial")
            return float('inf')
        
        # –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏
        metrics = train_model_with_params(suggested_params)
        
        return metrics.get('validation_loss', float('inf'))
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –≤ trial: {e}")
        return float('inf')
        
    finally:
        # –û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–ê–Ø –æ—á–∏—Å—Ç–∫–∞ –ø–∞–º—è—Ç–∏
        memory_manager.cleanup_trial_memory(force=True)
"""

print("‚úÖ –°–æ–∑–¥–∞–Ω—ã –¥–µ—Ç–∞–ª—å–Ω—ã–µ —Ä–µ—à–µ–Ω–∏—è –¥–ª—è –æ—Å–Ω–æ–≤–Ω—ã—Ö –ø—Ä–æ–±–ª–µ–º:")
print("1. device_fix - –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –ø—Ä–æ–±–ª–µ–º—ã 'tuple' object has no attribute 'device'")
print("2. sqlite_wal_fix - –Ω–∞—Å—Ç—Ä–æ–π–∫–∞ SQLite WAL —Ä–µ–∂–∏–º–∞")  
print("3. mlflow_nested_fix - –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ MLflow nested runs")
print("4. memory_cleanup_fix - —É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –ø–∞–º—è—Ç—å—é –≤ trials")

# –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ—à–µ–Ω–∏—è –≤ —Ñ–∞–π–ª—ã
for solution_name, code in solutions_code.items():
    with open(f"{solution_name}.py", "w", encoding="utf-8") as f:
        f.write(code)
    print(f"üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω —Ñ–∞–π–ª: {solution_name}.py")