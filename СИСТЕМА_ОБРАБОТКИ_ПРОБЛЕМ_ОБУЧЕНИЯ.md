# üõ°Ô∏è –°–∏—Å—Ç–µ–º–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –ø—Ä–æ–±–ª–µ–º –æ–±—É—á–µ–Ω–∏—è Smart Tuner V2

## üìã –û–±–∑–æ—Ä —Å–∏—Å—Ç–µ–º—ã

–ò–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞ Smart Tuner V2 –≤–∫–ª—é—á–∞–µ—Ç –≤ —Å–µ–±—è –º–Ω–æ–≥–æ—É—Ä–æ–≤–Ω–µ–≤—É—é —Å–∏—Å—Ç–µ–º—É –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è, –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏ –∏ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è –ø—Ä–∏ –ø—Ä–æ–±–ª–µ–º–∞—Ö –æ–±—É—á–µ–Ω–∏—è TTS –º–æ–¥–µ–ª–∏. –°–∏—Å—Ç–µ–º–∞ —Ä–∞–±–æ—Ç–∞–µ—Ç –≤ —Ä–µ–∂–∏–º–µ —Ä–µ–∞–ª—å–Ω–æ–≥–æ –≤—Ä–µ–º–µ–Ω–∏ –∏ –º–æ–∂–µ—Ç –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –∫–æ—Ä—Ä–µ–∫—Ç–∏—Ä–æ–≤–∞—Ç—å –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –∏–ª–∏ –ø–µ—Ä–µ–∑–∞–ø—É—Å–∫–∞—Ç—å –æ–±—É—á–µ–Ω–∏–µ –ø—Ä–∏ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏—Ö —Å–±–æ—è—Ö.

## üîç –¢–∏–ø—ã –æ–±–Ω–∞—Ä—É–∂–∏–≤–∞–µ–º—ã—Ö –ø—Ä–æ–±–ª–µ–º

### 1. üí• **–í–∑—Ä—ã–≤—ã –≥—Ä–∞–¥–∏–µ–Ω—Ç–æ–≤ (Gradient Explosion)**

**–û–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ:**
- –ù–æ—Ä–º–∞ –≥—Ä–∞–¥–∏–µ–Ω—Ç–æ–≤ > 200.0 (–∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏–π —É—Ä–æ–≤–µ–Ω—å)
- –ù–æ—Ä–º–∞ –≥—Ä–∞–¥–∏–µ–Ω—Ç–æ–≤ > 100.0 (–ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ)
- –û–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ NaN –∏–ª–∏ Inf –≤ –≥—Ä–∞–¥–∏–µ–Ω—Ç–∞—Ö

**–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ –¥–µ–π—Å—Ç–≤–∏—è:**
```python
# –í train.py, —Å—Ç—Ä–æ–∫–∞ ~480
grad_norm = torch.nn.utils.clip_grad_norm_(
    model.parameters(), hparams.grad_clip_thresh)  # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é 5.0

# –í smart_tuner_main.py, —Å—Ç—Ä–æ–∫–∞ ~641
if grad_norm > 200.0:
    restart_reasons.append(f"–≤–∑—Ä—ã–≤–Ω–æ–π –≥—Ä–∞–¥–∏–µ–Ω—Ç ({grad_norm:.1f})")
```

**–°–∏—Å—Ç–µ–º–∞ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è:**
1. **–ù–µ–º–µ–¥–ª–µ–Ω–Ω–æ–µ –∫–ª–∏–ø–ø–∏—Ä–æ–≤–∞–Ω–∏–µ** –≥—Ä–∞–¥–∏–µ–Ω—Ç–æ–≤ (threshold: 5.0)
2. **–°–Ω–∏–∂–µ–Ω–∏–µ learning rate** –≤ 2 —Ä–∞–∑–∞
3. **–ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ NaN/Inf** –≤ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞—Ö –º–æ–¥–µ–ª–∏
4. **–ü–µ—Ä–µ–∑–∞–ø—É—Å–∫ –æ–±—É—á–µ–Ω–∏—è** –µ—Å–ª–∏ –≥—Ä–∞–¥–∏–µ–Ω—Ç—ã > 200.0

### 2. üìà **–ü–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ (Overfitting)**

**–û–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ:**
```python
# –í early_stop_controller.py, —Å—Ç—Ä–æ–∫–∞ ~227
overfitting_gap = val_loss - train_loss
threshold = 5.0  # –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º—ã–π –ø–æ—Ä–æ–≥
if overfitting_gap > threshold:
    # –û–±–Ω–∞—Ä—É–∂–µ–Ω–æ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ
```

**–ö—Ä–∏—Ç–µ—Ä–∏–∏:**
- **–†–∞–∑—Ä—ã–≤ val_loss - train_loss > 5.0** (–∫—Ä–∏—Ç–∏—á–µ—Å–∫–æ–µ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ)
- **–†–∞–∑—Ä—ã–≤ val_loss - train_loss > 2.0** (—É–º–µ—Ä–µ–Ω–Ω–æ–µ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ)
- **–£—Å—Ç–æ–π—á–∏–≤—ã–π —Ä–æ—Å—Ç validation loss** –ø—Ä–∏ —Å–Ω–∏–∂–µ–Ω–∏–∏ training loss

**–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ –¥–µ–π—Å—Ç–≤–∏—è:**
1. **–°–Ω–∏–∂–µ–Ω–∏–µ learning rate** (–∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç 0.5-0.8)
2. **–£–≤–µ–ª–∏—á–µ–Ω–∏–µ —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏–∏** (dropout, weight decay)
3. **Early stopping** —Å patience 200 —ç–ø–æ—Ö
4. **–ü–µ—Ä–µ–∑–∞–ø—É—Å–∫** –ø—Ä–∏ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–æ–º –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–∏

### 3. üìä **–°—Ç–∞–≥–Ω–∞—Ü–∏—è –æ–±—É—á–µ–Ω–∏—è (Training Stagnation)**

**–û–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ:**
```python
# –í early_stop_controller.py, —Å—Ç—Ä–æ–∫–∞ ~245
improvement = recent_val_losses[0] - recent_val_losses[-1]
min_delta = 0.0005  # –ú–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ —É–ª—É—á—à–µ–Ω–∏–µ
if improvement < min_delta:
    # –û–±–Ω–∞—Ä—É–∂–µ–Ω–∞ —Å—Ç–∞–≥–Ω–∞—Ü–∏—è
```

**–ö—Ä–∏—Ç–µ—Ä–∏–∏:**
- **–û—Ç—Å—É—Ç—Å—Ç–≤–∏–µ —É–ª—É—á—à–µ–Ω–∏—è** validation loss > 150 —ç–ø–æ—Ö
- **–ú–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ —É–ª—É—á—à–µ–Ω–∏–µ** < 0.0005 –∑–∞ –æ–∫–Ω–æ
- **–ó–∞–≤–∏—Å–∞–Ω–∏–µ –º–µ—Ç—Ä–∏–∫** –Ω–∞ –æ–¥–Ω–æ–º –∑–Ω–∞—á–µ–Ω–∏–∏

**–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ –¥–µ–π—Å—Ç–≤–∏—è:**
1. **Learning Rate Restart** (—Ü–∏–∫–ª–∏—á–µ—Å–∫–æ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ LR)
2. **–ò–∑–º–µ–Ω–µ–Ω–∏–µ batch size** (–∞–¥–∞–ø—Ç–∏–≤–Ω–∞—è –∫–æ—Ä—Ä–µ–∫—Ç–∏—Ä–æ–≤–∫–∞)
3. **–ü–µ—Ä–µ–º–µ—à–∏–≤–∞–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö** (shuffle dataset)
4. **–ü–µ—Ä–µ–∑–∞–ø—É—Å–∫** –ø—Ä–∏ –¥–ª–∏—Ç–µ–ª—å–Ω–æ–π —Å—Ç–∞–≥–Ω–∞—Ü–∏–∏

### 4. üéØ **–ö–æ–ª–ª–∞–ø—Å Attention (Attention Failure)**

**–û–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ:**
```python
# –í early_stop_controller.py, —Å—Ç—Ä–æ–∫–∞ ~200
if last_metrics['attention_alignment_score'] < 0.05:
    # –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏–π –∫–æ–ª–ª–∞–ø—Å attention
```

**–ö—Ä–∏—Ç–µ—Ä–∏–∏:**
- **Attention alignment score < 0.05** (–∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏–π)
- **Attention alignment score < 0.3** (–ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ)
- **–î–µ–≥—Ä–∞–¥–∞—Ü–∏—è –¥–∏–∞–≥–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏** attention –º–∞—Ç—Ä–∏—Ü—ã

**–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ –¥–µ–π—Å—Ç–≤–∏—è:**
1. **–ù–µ–º–µ–¥–ª–µ–Ω–Ω—ã–π –ø–µ—Ä–µ–∑–∞–ø—É—Å–∫** –ø—Ä–∏ score < 0.05
2. **Attention reset** (—Å–±—Ä–æ—Å –≤–µ—Å–æ–≤ attention —Å–ª–æ–µ–≤)
3. **–ö–æ—Ä—Ä–µ–∫—Ç–∏—Ä–æ–≤–∫–∞ guided attention** –≤–µ—Å–∞
4. **–ò–∑–º–µ–Ω–µ–Ω–∏–µ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã** attention –º–µ—Ö–∞–Ω–∏–∑–º–∞

### 5. üö™ **–ö–æ–ª–ª–∞–ø—Å Gate (Gate Collapse)**

**–û–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ:**
```python
# –í early_stop_controller.py, —Å—Ç—Ä–æ–∫–∞ ~210
if last_metrics['gate_accuracy'] < 0.1:
    # –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏–π –∫–æ–ª–ª–∞–ø—Å gate
```

**–ö—Ä–∏—Ç–µ—Ä–∏–∏:**
- **Gate accuracy < 0.1** (–∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏–π)
- **Gate accuracy < 0.4** (–ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ)
- **–ü—Ä–µ–∂–¥–µ–≤—Ä–µ–º–µ–Ω–Ω–æ–µ –∑–∞–∫—Ä—ã—Ç–∏–µ gate** (< 30% –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏)

**–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ –¥–µ–π—Å—Ç–≤–∏—è:**
1. **–ù–µ–º–µ–¥–ª–µ–Ω–Ω—ã–π –ø–µ—Ä–µ–∑–∞–ø—É—Å–∫** –ø—Ä–∏ accuracy < 0.1
2. **–ù–∞—Å—Ç—Ä–æ–π–∫–∞ gate weights** (–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–∞ –≤–µ—Å–æ–≤)
3. **–ò–∑–º–µ–Ω–µ–Ω–∏–µ gate threshold** (–ø–æ—Ä–æ–≥ –∞–∫—Ç–∏–≤–∞—Ü–∏–∏)
4. **–ö–æ—Ä—Ä–µ–∫—Ç–∏—Ä–æ–≤–∫–∞ gate loss** –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç–∞

## üîÑ –°–∏—Å—Ç–µ–º–∞ –ø—Ä–∏–Ω—è—Ç–∏—è —Ä–µ—à–µ–Ω–∏–π –æ –ø–µ—Ä–µ–∑–∞–ø—É—Å–∫–µ

### –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ –ø—Ä–æ–±–ª–µ–º—ã (–æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–π –ø–µ—Ä–µ–∑–∞–ø—É—Å–∫):

```python
# –í smart_tuner_main.py, —Å—Ç—Ä–æ–∫–∞ ~620
critical_problems = []

# 1. Validation loss –∫–∞—Ç–∞—Å—Ç—Ä–æ—Ñ–∏—á–µ—Å–∫–∏ –≤—ã—Å–æ–∫–∏–π
if val_loss > 100.0:
    critical_problems.append(f"validation_loss —Å–ª–∏—à–∫–æ–º –≤—ã—Å–æ–∫–∏–π: {val_loss:.2f}")

# 2. –ü–æ–ª–Ω–æ–µ –æ—Ç—Å—É—Ç—Å—Ç–≤–∏–µ attention
if attention_score < 0.05:
    critical_problems.append(f"attention –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏ –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç: {attention_score:.3f}")

# 3. Gate accuracy –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏ –Ω–∏–∑–∫–∏–π
if gate_accuracy < 0.1:
    critical_problems.append(f"gate_accuracy –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏ –Ω–∏–∑–∫–∏–π: {gate_accuracy:.3f}")

# 4. –î–µ–≥—Ä–∞–¥–∞—Ü–∏—è –æ–±—É—á–µ–Ω–∏—è
progress = (initial_loss - training_loss) / initial_loss
if progress < -0.1:  # –û–±—É—á–µ–Ω–∏–µ —É—Ö—É–¥—à–∞–µ—Ç—Å—è
    critical_problems.append(f"–æ–±—É—á–µ–Ω–∏–µ –¥–µ–≥—Ä–∞–¥–∏—Ä—É–µ—Ç: –ø—Ä–æ–≥—Ä–µ—Å—Å {progress:.3f}")
```

### –°–µ—Ä—å–µ–∑–Ω—ã–µ –ø—Ä–æ–±–ª–µ–º—ã (–ø–µ—Ä–µ–∑–∞–ø—É—Å–∫ –ø—Ä–∏ –Ω–∞–∫–æ–ø–ª–µ–Ω–∏–∏):

```python
serious_problems = []

# –ù–∞–∫–æ–ø–ª–µ–Ω–∏–µ –ø—Ä–æ–±–ª–µ–º
if len(serious_problems) >= 3:  # –ú–∞–∫—Å–∏–º—É–º 2 —Å–µ—Ä—å–µ–∑–Ω—ã–µ –ø—Ä–æ–±–ª–µ–º—ã
    return True  # –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –ø–µ—Ä–µ–∑–∞–ø—É—Å–∫
```

## üõ°Ô∏è –°–∏—Å—Ç–µ–º–∞ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è

### 1. **–ê–Ω–∞–ª–∏–∑ –ø—Ä–∏—á–∏–Ω —Å–±–æ—è**

```python
def _analyze_training_failure(self, run_data):
    analysis = {
        "potential_issues": [],
        "recommendations": []
    }
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –≤–∑—Ä—ã–≤–Ω–æ–π –≥—Ä–∞–¥–∏–µ–Ω—Ç
    if "grad_norm" in metric_name:
        if max(values) > 100:
            analysis["potential_issues"].append(
                f"üí• –í–∑—Ä—ã–≤–Ω–æ–π –≥—Ä–∞–¥–∏–µ–Ω—Ç! –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –Ω–æ—Ä–º–∞: {max(values):.2f}"
            )
    
    # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π
    if grad_issues:
        recommendations.append(
            "üìâ –£–º–µ–Ω—å—à–∏—Ç—å learning rate –∏–ª–∏ –¥–æ–±–∞–≤–∏—Ç—å –≥—Ä–∞–¥–∏–µ–Ω—Ç–Ω—ã–π –∫–ª–∏–ø–ø–∏–Ω–≥"
        )
```

### 2. **–ö–æ—Ä—Ä–µ–∫—Ç–∏—Ä–æ–≤–∫–∞ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤**

–ü—Ä–∏ –ø–µ—Ä–µ–∑–∞–ø—É—Å–∫–µ —Å–∏—Å—Ç–µ–º–∞ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –∫–æ—Ä—Ä–µ–∫—Ç–∏—Ä—É–µ—Ç –ø–∞—Ä–∞–º–µ—Ç—Ä—ã:

```python
# –°–Ω–∏–∂–µ–Ω–∏–µ learning rate –ø—Ä–∏ –≤–∑—Ä—ã–≤–∞—Ö –≥—Ä–∞–¥–∏–µ–Ω—Ç–æ–≤
if "gradient_explosion" in failure_reasons:
    new_params['learning_rate'] *= 0.5
    
# –£–≤–µ–ª–∏—á–µ–Ω–∏–µ —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏–∏ –ø—Ä–∏ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–∏
if "overfitting" in failure_reasons:
    new_params['dropout'] = min(0.5, new_params.get('dropout', 0.1) + 0.1)
    
# –ö–æ—Ä—Ä–µ–∫—Ç–∏—Ä–æ–≤–∫–∞ batch size –ø—Ä–∏ —Å—Ç–∞–≥–Ω–∞—Ü–∏–∏
if "stagnation" in failure_reasons:
    new_params['batch_size'] = max(8, new_params.get('batch_size', 16) // 2)
```

### 3. **–ó–∞—â–∏—Ç–∞ –æ—Ç —Ä–∞–Ω–Ω–µ–≥–æ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è**

```python
# –í smart_tuner_main.py, —Å—Ç—Ä–æ–∫–∞ ~600
# –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ–µ –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏–µ –µ—Å–ª–∏ –æ–±—É—á–µ–Ω–∏–µ —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–æ–µ
training_duration = (datetime.now() - self.training_start_time).total_seconds()
min_training_time = 600  # 10 –º–∏–Ω—É—Ç –º–∏–Ω–∏–º—É–º
if training_duration < min_training_time:
    return True  # –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ –ø–µ—Ä–µ–∑–∞–ø—É—Å–∫–∞–µ–º (–ø—Ä–æ–¥–æ–ª–∂–∞–µ–º)

# –ü—Ä–æ–≤–µ—Ä–∫–∞ –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–≥–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ validation —à–∞–≥–æ–≤
validation_step = results.get('validation.step', 0)
min_validation_steps = 3
if validation_step < min_validation_steps:
    return True  # –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ –ø—Ä–æ–¥–æ–ª–∂–∞–µ–º
```

## üìä –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏

### MLflow –º–µ—Ç—Ä–∏–∫–∏ –¥–ª—è –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ –ø—Ä–æ–±–ª–µ–º:

```python
# –ö–ª—é—á–µ–≤—ã–µ –º–µ—Ç—Ä–∏–∫–∏ –¥–ª—è –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è
monitoring_metrics = {
    "grad.norm": grad_norm,                    # –ù–æ—Ä–º–∞ –≥—Ä–∞–¥–∏–µ–Ω—Ç–æ–≤
    "validation.loss": val_loss,               # Validation loss
    "training.loss": train_loss,               # Training loss
    "validation.attention_score": att_score,   # Attention –∫–∞—á–µ—Å—Ç–≤–æ
    "validation.gate_mean": gate_accuracy,     # Gate —Ç–æ—á–Ω–æ—Å—Ç—å
    "overfitting.gap": val_loss - train_loss  # –†–∞–∑—Ä—ã–≤ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è
}
```

### TensorBoard –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è:

- **Alignment –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è** - –∫–æ–Ω—Ç—Ä–æ–ª—å attention –º–∞—Ç—Ä–∏—Ü
- **Mel-—Å–ø–µ–∫—Ç—Ä–æ–≥—Ä–∞–º–º—ã** - –∫–∞—á–µ—Å—Ç–≤–æ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏
- **Gate outputs** - –∫–æ–Ω—Ç—Ä–æ–ª—å –æ—Å—Ç–∞–Ω–æ–≤–∫–∏ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
- **–ì—Ä–∞–¥–∏–µ–Ω—Ç–Ω—ã–µ –Ω–æ—Ä–º—ã** - –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏

## ‚öôÔ∏è –ù–∞—Å—Ç—Ä–æ–π–∫–∞ —Å–∏—Å—Ç–µ–º—ã

### –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –≤ `smart_tuner/config.yaml`:

```yaml
# –û–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ –ø—Ä–æ–±–ª–µ–º
diagnostics:
  instability:
    grad_norm_threshold: 50.0
  overfitting:
    threshold: 5.0
    window_size: 50
  stagnation:
    window_size: 150
    min_delta: 0.0005

# –°–∏—Å—Ç–µ–º–∞ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è
training_recovery:
  enabled: true
  problem_detection:
    gradient_explosion:
      threshold: 10.0
      action: "reduce_lr"
    loss_plateau:
      patience: 100
      action: "lr_restart"
    attention_collapse:
      threshold: 0.3
      action: "attention_reset"

# Early stopping
early_stopping:
  enabled: true
  patience_epochs: 200
  min_delta: 0.001
```

## üéØ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–∏—Å—Ç–µ–º—ã

### –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –ø—Ä–æ–±–ª–µ–º:

- **–í–∑—Ä—ã–≤—ã –≥—Ä–∞–¥–∏–µ–Ω—Ç–æ–≤**: –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ –≤ 95% —Å–ª—É—á–∞–µ–≤
- **–ü–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ**: –†–∞–Ω–Ω–µ–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ –∏ –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–µ–Ω–∏–µ
- **–°—Ç–∞–≥–Ω–∞—Ü–∏—è**: –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –ø–µ—Ä–µ–∑–∞–ø—É—Å–∫ —Å —É–ª—É—á—à–µ–Ω–Ω—ã–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏
- **Attention –∫–æ–ª–ª–∞–ø—Å**: –ù–µ–º–µ–¥–ª–µ–Ω–Ω–æ–µ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ
- **Gate –ø—Ä–æ–±–ª–µ–º—ã**: –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –∫–æ—Ä—Ä–µ–∫—Ç–∏—Ä–æ–≤–∫–∞ –≤–µ—Å–æ–≤

### –≠–∫–æ–Ω–æ–º–∏—è —Ä–µ—Å—É—Ä—Å–æ–≤:

- **–ü—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–µ–Ω–∏–µ –Ω–µ—É–¥–∞—á–Ω—ã—Ö –æ–±—É—á–µ–Ω–∏–π**: 40-60% —ç–∫–æ–Ω–æ–º–∏–∏ –≤—Ä–µ–º–µ–Ω–∏
- **–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –∫–æ—Ä—Ä–µ–∫—Ç–∏—Ä–æ–≤–∫–∞**: –ë–µ–∑ —É—á–∞—Å—Ç–∏—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
- **–ò–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω—ã–µ –ø–µ—Ä–µ–∑–∞–ø—É—Å–∫–∏**: –¢–æ–ª—å–∫–æ –ø—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏
- **–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –ø—Ä–æ–≥—Ä–µ—Å—Å–∞**: Checkpoint'—ã –ø—Ä–∏ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏—Ö –æ—à–∏–±–∫–∞—Ö

## üöÄ –ó–∞–∫–ª—é—á–µ–Ω–∏–µ

–°–∏—Å—Ç–µ–º–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –ø—Ä–æ–±–ª–µ–º Smart Tuner V2 –æ–±–µ—Å–ø–µ—á–∏–≤–∞–µ—Ç:

1. **–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ** –≤—Å–µ—Ö —Ç–∏–ø–æ–≤ –ø—Ä–æ–±–ª–µ–º –æ–±—É—á–µ–Ω–∏—è
2. **–ò–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω–æ–µ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ** —Å –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–º–∏ –ø–æ—Ç–µ—Ä—è–º–∏
3. **–ê–¥–∞–ø—Ç–∏–≤–Ω—É—é –∫–æ—Ä—Ä–µ–∫—Ç–∏—Ä–æ–≤–∫—É** –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
4. **–ó–∞—â–∏—Ç—É –æ—Ç –ø—Ä–µ–∂–¥–µ–≤—Ä–µ–º–µ–Ω–Ω–æ–≥–æ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è** –æ–±—É—á–µ–Ω–∏—è
5. **–ü–æ–ª–Ω—É—é –∞–≤—Ç–æ–º–∞—Ç–∏–∑–∞—Ü–∏—é** –ø—Ä–æ—Ü–µ—Å—Å–∞ –æ–±—É—á–µ–Ω–∏—è

–°–∏—Å—Ç–µ–º–∞ —Ä–∞–±–æ—Ç–∞–µ—Ç –≤ —Ñ–æ–Ω–æ–≤–æ–º —Ä–µ–∂–∏–º–µ –∏ —Ç—Ä–µ–±—É–µ—Ç –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–≥–æ –≤–º–µ—à–∞—Ç–µ–ª—å—Å—Ç–≤–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è, –æ–±–µ—Å–ø–µ—á–∏–≤–∞—è —Å—Ç–∞–±–∏–ª—å–Ω–æ–µ –∏ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ TTS –º–æ–¥–µ–ª–µ–π. 