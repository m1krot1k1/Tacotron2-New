#!/usr/bin/env python3
"""
Smart Tuner V2 - Main Entry Point
–ê–≤—Ç–æ–º–∞—Ç–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞ –æ–±—É—á–µ–Ω–∏—è Tacotron2 —Å TTS-—Å–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã–º–∏ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—è–º–∏

–û—Å–Ω–æ–≤–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏:
- TTS-–æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ 
- –ò–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω–æ–µ —É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –æ–±—É—á–µ–Ω–∏–µ–º —Å –∫–æ–º–ø–æ–∑–∏—Ç–Ω—ã–º–∏ –º–µ—Ç—Ä–∏–∫–∞–º–∏
- –§–∞–∑–æ–≤–æ–µ –æ–±—É—á–µ–Ω–∏–µ —Å –∞–¥–∞–ø—Ç–∞—Ü–∏–µ–π –∫ —Å—Ç–∞–¥–∏—è–º TTS
- –ü—Ä–æ–∞–∫—Ç–∏–≤–Ω–æ–µ —É—Å—Ç—Ä–∞–Ω–µ–Ω–∏–µ –ø—Ä–æ–±–ª–µ–º –æ–±—É—á–µ–Ω–∏—è
- –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –∏ —ç–∫—Å–ø–æ—Ä—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
"""

import os
import sys
import yaml
import logging
import argparse
import time
from datetime import datetime
from pathlib import Path
from typing import Dict, Any, Optional

# –î–æ–±–∞–≤–ª—è–µ–º –∫–æ—Ä–Ω–µ–≤—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –≤ –ø—É—Ç—å
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

# –ü–æ–¥–∞–≤–ª—è–µ–º –ª–∏—à–Ω–∏–µ warning'–∏ –¥–ª—è —á–∏—Å—Ç–æ–≥–æ –≤—ã–≤–æ–¥–∞
import warnings
warnings.filterwarnings("ignore", category=FutureWarning)
warnings.filterwarnings("ignore", category=UserWarning, message=".*torch.cuda.*DtypeTensor.*")
warnings.filterwarnings("ignore", message=".*deprecated.*")
warnings.filterwarnings("ignore", message=".*multivariate.*experimental.*")

# –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º —É—Ä–æ–≤–Ω–∏ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è –¥–ª—è —É–º–µ–Ω—å—à–µ–Ω–∏—è "–º—É—Å–æ—Ä–∞"
import logging
# –ü–æ–ª–Ω–æ—Å—Ç—å—é –æ—Ç–∫–ª—é—á–∞–µ–º –≤—Å–µ –ª–æ–≥–∏ –æ—Ç –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤ Smart Tuner –¥–ª—è —á–∏—Å—Ç–æ—Ç—ã –≤—ã–≤–æ–¥–∞
logging.getLogger("smart_tuner.early_stop_controller").disabled = True
logging.getLogger("smart_tuner.optimization_engine").disabled = True
logging.getLogger("smart_tuner.alert_manager").disabled = True
logging.getLogger("smart_tuner.model_registry").disabled = True
logging.getLogger("smart_tuner.trainer_wrapper").disabled = True

# –¢–∞–∫–∂–µ –æ—Ç–∫–ª—é—á–∞–µ–º timestamp –ª–æ–≥–∏
class NoTimestampFilter(logging.Filter):
    def filter(self, record):
        # –§–∏–ª—å—Ç—Ä—É–µ–º –ª–æ–≥–∏ —Å timestamp –∏ [INFO] - (EarlyStopController)
        message = record.getMessage()
        return not any(pattern in message for pattern in [
            "[INFO] - (EarlyStopController)",
            "[WARNING] - (EarlyStopController)",
            "OptimizationEngine - INFO",
            "AlertManager - INFO",
            "ModelRegistry - INFO"
        ])

# –ü—Ä–∏–º–µ–Ω—è–µ–º —Ñ–∏–ª—å—Ç—Ä –∫ –∫–æ—Ä–Ω–µ–≤–æ–º—É –ª–æ–≥–≥–µ—Ä—É
logging.getLogger().addFilter(NoTimestampFilter())

# –ò–º–ø–æ—Ä—Ç—ã –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤ Smart Tuner
from smart_tuner.trainer_wrapper import TrainerWrapper
from smart_tuner.optimization_engine import OptimizationEngine
from smart_tuner.early_stop_controller import EarlyStopController
from smart_tuner.alert_manager import AlertManager
from smart_tuner.model_registry import ModelRegistry
from smart_tuner.intelligent_epoch_optimizer import IntelligentEpochOptimizer

# –ò–º–ø–æ—Ä—Ç—ã —Å–∏—Å—Ç–µ–º –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è (—É–ø—Ä–æ—â–µ–Ω–Ω—ã–µ)
try:
    from training_integration import (
        setup_training_logging, 
        finish_training_logging,
        export_current_training
    )
    INTEGRATION_AVAILABLE = True
except ImportError:
    INTEGRATION_AVAILABLE = False
    # –ó–∞–≥–ª—É—à–∫–∏ –¥–ª—è —Ñ—É–Ω–∫—Ü–∏–π –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
    def setup_training_logging(*args, **kwargs):
        return None, None
    def finish_training_logging(*args, **kwargs):
        pass
    def export_current_training(*args, **kwargs):
        return None

class SmartTunerMain:
    """
    –ì–ª–∞–≤–Ω—ã–π –∫–æ–Ω—Ç—Ä–æ–ª–ª–µ—Ä TTS-–æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–π —Å–∏—Å—Ç–µ–º—ã —É–º–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è
    """
    
    def __init__(self, config_path: str = "smart_tuner/config.yaml"):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è Smart Tuner —Å TTS –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–µ–π
        
        Args:
            config_path: –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
        """
        self.config_path = config_path
        self.config = self._load_config()
        self.logger = self._setup_logger()
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤
        self.trainer_wrapper = None
        self.optimization_engine = None
        self.early_stop_controller = None
        self.alert_manager = None
        self.model_registry = None
        
        # TTS-—Å–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏
        self.tts_config = self.config.get('tts_phase_training', {})
        self.current_phase = "pre_alignment"
        self.training_start_time = None
        
        # –°–∏—Å—Ç–µ–º–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
        self.training_logger = None
        self.export_system = None
        
        self.logger.info("üöÄ Smart Tuner V2 TTS –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
        
    def _load_config(self) -> Dict[str, Any]:
        """–ó–∞–≥—Ä—É–∑–∫–∞ TTS –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏"""
        try:
            with open(self.config_path, 'r', encoding='utf-8') as f:
                return yaml.safe_load(f)
        except FileNotFoundError:
            print(f"‚ùå –§–∞–π–ª –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ {self.config_path} –Ω–µ –Ω–∞–π–¥–µ–Ω")
            sys.exit(1)
        except yaml.YAMLError as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏: {e}")
            sys.exit(1)
            
    def _setup_logger(self) -> logging.Logger:
        """–ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–≥–µ—Ä–∞ –¥–ª—è TTS"""
        logger = logging.getLogger('SmartTunerMain')
        logger.setLevel(logging.INFO)
        
        if not logger.handlers:
            # –ö–æ–Ω—Å–æ–ª—å–Ω—ã–π handler
            console_handler = logging.StreamHandler(sys.stdout)
            console_formatter = logging.Formatter(
                '%(asctime)s - üß† Smart Tuner - %(levelname)s - %(message)s',
                datefmt='%H:%M:%S'
            )
            console_handler.setFormatter(console_formatter)
            logger.addHandler(console_handler)
            
            # –§–∞–π–ª–æ–≤—ã–π handler –¥–ª—è TTS –ª–æ–≥–æ–≤
            log_dir = Path("smart_tuner/logs")
            log_dir.mkdir(parents=True, exist_ok=True)
            
            file_handler = logging.FileHandler(
                log_dir / f"smart_tuner_{datetime.now().strftime('%Y%m%d_%H%M%S')}.log"
            )
            file_formatter = logging.Formatter(
                '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
            )
            file_handler.setFormatter(file_formatter)
            logger.addHandler(file_handler)
            
        return logger
        
    def initialize_components(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –≤—Å–µ—Ö TTS –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤ —Å–∏—Å—Ç–µ–º—ã"""
        try:
            self.logger.info("üîß –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è TTS –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤...")
            
            # –û–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä —Å TTS –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π
            self.optimization_engine = OptimizationEngine(self.config_path)
            self.logger.info("‚úÖ TTS OptimizationEngine –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
            
            # –ö–æ–Ω—Ç—Ä–æ–ª–ª–µ—Ä —Ä–∞–Ω–Ω–µ–≥–æ –æ—Å—Ç–∞–Ω–æ–≤–∞ —Å TTS –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–æ–π
            self.early_stop_controller = EarlyStopController(self.config_path)
            self.logger.info("‚úÖ TTS EarlyStopController –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
            
            # –ú–µ–Ω–µ–¥–∂–µ—Ä –∞–ª–µ—Ä—Ç–æ–≤
            self.alert_manager = AlertManager(self.config_path)
            self.logger.info("‚úÖ AlertManager –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
            
            # –†–µ–µ—Å—Ç—Ä –º–æ–¥–µ–ª–µ–π
            self.model_registry = ModelRegistry(self.config_path)
            self.logger.info("‚úÖ ModelRegistry –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
            
            # –û–±–µ—Ä—Ç–∫–∞ —Ç—Ä–µ–Ω–µ—Ä–∞ —Å TTS –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–µ–π (–ø—Ä–∏–Ω–∏–º–∞–µ—Ç —Å–ª–æ–≤–∞—Ä—å config)
            self.trainer_wrapper = TrainerWrapper(self.config)
            self.logger.info("‚úÖ TTS TrainerWrapper –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
            
            # –°–∏—Å—Ç–µ–º–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è TTS –±—É–¥–µ—Ç –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞ –ø—Ä–∏ —Å—Ç–∞—Ä—Ç–µ –æ–±—É—á–µ–Ω–∏—è
            self.training_logger = None
            self.export_system = None
            self.logger.info("‚úÖ TTS —Å–∏—Å—Ç–µ–º–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è –ø–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω–∞")
            
            self.logger.info("üéâ –í—Å–µ TTS –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã —É—Å–ø–µ—à–Ω–æ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω—ã!")
            
        except Exception as e:
            self.logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤: {e}")
            raise
    
    def run_optimization(self) -> Dict[str, Any]:
        """
        –ó–∞–ø—É—Å–∫ TTS-–æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –ø—Ä–æ—Ü–µ—Å—Å–∞ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
        
        Returns:
            –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏
        """
        self.logger.info("üéØ –ó–∞–ø—É—Å–∫ TTS –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤...")
        
        try:
            # –°–æ–∑–¥–∞–µ–º –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ —Å TTS –Ω–∞—Å—Ç—Ä–æ–π–∫–∞–º–∏
            study = self.optimization_engine.create_study(
                study_name=f"tacotron2_tts_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
            )
            
            # –ü–æ–ª—É—á–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ trials –∏–∑ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
            n_trials = self.config.get('optimization', {}).get('n_trials', 30)
            
            def tts_objective_function(trial):
                """
                üéØ TTS-–æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è —Ü–µ–ª–µ–≤–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è Optuna
                –£—á–∏—Ç—ã–≤–∞–µ—Ç —Å–ø–µ—Ü–∏—Ñ–∏–∫—É –æ–±—É—á–µ–Ω–∏—è TTS –º–æ–¥–µ–ª–µ–π
                """
                # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –≤—Ä–µ–º—è –Ω–∞—á–∞–ª–∞ –æ–±—É—á–µ–Ω–∏—è
                from datetime import datetime
                self.training_start_time = datetime.now()
                
                try:
                    self.logger.info(f"üéØ TTS trial {trial.number} –Ω–∞—á–∞—Ç")
                    
                    # –ü–æ–ª—É—á–∞–µ–º –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–Ω—ã–µ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä—ã
                    suggested_params = self.optimization_engine.suggest_hyperparameters(trial)
                    self.logger.info(f"üéõÔ∏è TTS –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è trial {trial.number}: {suggested_params}")
                    
                    # –°–æ–∑–¥–∞–µ–º TensorBoard writer –¥–ª—è —ç—Ç–æ–≥–æ trial
                    from torch.utils.tensorboard import SummaryWriter
                    log_dir = os.path.join("output", "optuna_trials", f"trial_{trial.number}")
                    os.makedirs(log_dir, exist_ok=True)
                    writer = SummaryWriter(log_dir)
                    
                    # –ó–∞–ø—É—Å–∫–∞–µ–º –æ–±—É—á–µ–Ω–∏–µ —Å –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–Ω—ã–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏
                    metrics = self.trainer_wrapper.train_with_params(
                        suggested_params, 
                        trial=trial,
                        writer=writer
                    )
                    
                    # –ó–∞–∫—Ä—ã–≤–∞–µ–º writer
                    writer.close()
                    
                    self.logger.info(f"üìä TTS trial {trial.number} –ø–æ–ª—É—á–∏–ª –º–µ—Ç—Ä–∏–∫–∏: {metrics}")
                    
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–∞—á–µ—Å—Ç–≤–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
                    if self._check_tts_quality_thresholds(metrics):
                        self.logger.info(f"‚úÖ TTS trial {trial.number} –ø—Ä–æ—à–µ–ª –ø—Ä–æ–≤–µ—Ä–∫—É –∫–∞—á–µ—Å—Ç–≤–∞")
                    else:
                        self.logger.warning(f"‚ö†Ô∏è TTS trial {trial.number} –Ω–µ –ø—Ä–æ—à–µ–ª –ø—Ä–æ–≤–µ—Ä–∫—É –∫–∞—á–µ—Å—Ç–≤–∞")
                    
                    # –í—ã—á–∏—Å–ª—è–µ–º –∫–æ–º–ø–æ–∑–∏—Ç–Ω—É—é –æ—Ü–µ–Ω–∫—É
                    composite_score = self.optimization_engine.calculate_composite_tts_objective(metrics)
                    
                    self.logger.info(f"üéØ TTS trial {trial.number} –∑–∞–≤–µ—Ä—à–µ–Ω: {composite_score}")
                    return composite_score
                    
                except Exception as e:
                    self.logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≤ TTS trial {trial.number}: {e}")
                    import traceback
                    self.logger.error(f"–ü–æ–ª–Ω—ã–π traceback: {traceback.format_exc()}")
                    return float('inf')  # –í–æ–∑–≤—Ä–∞—â–∞–µ–º —Ö—É–¥—à–∏–π –≤–æ–∑–º–æ–∂–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç
            
            # –ó–∞–ø—É—Å–∫–∞–µ–º TTS –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—é
            results = self.optimization_engine.optimize(
                tts_objective_function, 
                n_trials=n_trials
            )
            
            self.logger.info("üéâ TTS –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ!")
            
            # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
            self._save_tts_optimization_results(results)
            
            return results
            
        except Exception as e:
            self.logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ TTS –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏: {e}")
            raise
    
    def _check_tts_quality_thresholds(self, metrics: Dict[str, float]) -> bool:
        """
        üéØ –£–õ–£–ß–®–ï–ù–ù–ê–Ø –ø—Ä–æ–≤–µ—Ä–∫–∞ TTS –º–µ—Ç—Ä–∏–∫ –Ω–∞ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã–º —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è–º
        –¢–µ–ø–µ—Ä—å –±–æ–ª–µ–µ —Ä–µ–∞–ª–∏—Å—Ç–∏—á–Ω–∞—è –∏ –∞–¥–∞–ø—Ç–∏–≤–Ω–∞—è + –∑–∞—â–∏—Ç–∞ –æ—Ç –ø—Ä–µ–∂–¥–µ–≤—Ä–µ–º–µ–Ω–Ω–æ–≥–æ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è
        """
        if not metrics:
            self.logger.warning("–ü—É—Å—Ç—ã–µ –º–µ—Ç—Ä–∏–∫–∏ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞")
            return False
        
        # üõ°Ô∏è –î–û–ü–û–õ–ù–ò–¢–ï–õ–¨–ù–ê–Ø –ó–ê–©–ò–¢–ê: –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ –≤—Ä–µ–º—è –∏ —à–∞–≥–∏ –æ–±—É—á–µ–Ω–∏—è
        training_duration = 0
        if hasattr(self, 'training_start_time') and self.training_start_time is not None:
            from datetime import datetime
            training_duration = (datetime.now() - self.training_start_time).total_seconds()
            min_training_time = 600  # 10 –º–∏–Ω—É—Ç –º–∏–Ω–∏–º—É–º
            if training_duration < min_training_time:
                self.logger.info(f"‚è∞ –û–±—É—á–µ–Ω–∏–µ —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–æ–µ ({training_duration/60:.1f} –º–∏–Ω < {min_training_time/60:.1f} –º–∏–Ω). –ü—Ä–æ–¥–æ–ª–∂–∞–µ–º...")
                return False
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ validation —à–∞–≥–æ–≤
        validation_step = metrics.get('validation.step', 0)
        min_validation_steps = 3  # –ú–∏–Ω–∏–º—É–º 3 validation —à–∞–≥–∞
        if validation_step < min_validation_steps:
            self.logger.info(f"üìä –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ validation —à–∞–≥–æ–≤ ({validation_step} < {min_validation_steps}). –ü—Ä–æ–¥–æ–ª–∂–∞–µ–º...")
            return False
            
        quality_checks = self.config.get('training_safety', {}).get('tts_quality_checks', {})
        
        # üìä –°–æ–±–∏—Ä–∞–µ–º –≤—Å–µ –ø—Ä–æ–≤–µ—Ä–∫–∏ —Å –±–æ–ª–µ–µ —Ä–µ–∞–ª–∏—Å—Ç–∏—á–Ω—ã–º–∏ –ø–æ—Ä–æ–≥–∞–º–∏
        checks = []
        check_details = []
        
        # 1. –ü—Ä–æ–≤–µ—Ä–∫–∞ attention alignment (–±–æ–ª–µ–µ –º—è–≥–∫–∞—è)
        min_attention = quality_checks.get('min_attention_alignment', 0.4)  # –°–Ω–∏–∂–µ–Ω–æ —Å 0.6
        current_attention = metrics.get('attention_alignment_score', 0.0)
        attention_check = current_attention >= min_attention
        checks.append(attention_check)
        check_details.append(f"attention_alignment: {current_attention:.3f} >= {min_attention} ({'‚úÖ' if attention_check else '‚ùå'})")
        
        # 2. –ü—Ä–æ–≤–µ—Ä–∫–∞ gate accuracy (–±–æ–ª–µ–µ –¥–æ—Å—Ç–∏–∂–∏–º–∞—è)
        min_gate = quality_checks.get('min_gate_accuracy', 0.5)  # –°–Ω–∏–∂–µ–Ω–æ —Å 0.7
        current_gate = metrics.get('gate_accuracy', 0.0)
        gate_check = current_gate >= min_gate
        checks.append(gate_check)
        check_details.append(f"gate_accuracy: {current_gate:.3f} >= {min_gate} ({'‚úÖ' if gate_check else '‚ùå'})")
        
        # 3. –ü—Ä–æ–≤–µ—Ä–∫–∞ validation loss (–±–æ–ª–µ–µ —Ä–∞–∑—É–º–Ω–∞—è)
        max_val_loss = quality_checks.get('max_validation_loss', 25.0)  # –°–Ω–∏–∂–µ–Ω–æ —Å 50.0
        current_val_loss = metrics.get('val_loss', float('inf'))
        val_loss_check = current_val_loss <= max_val_loss
        checks.append(val_loss_check)
        check_details.append(f"val_loss: {current_val_loss:.3f} <= {max_val_loss} ({'‚úÖ' if val_loss_check else '‚ùå'})")
        
        # 4. –ü—Ä–æ–≤–µ—Ä–∫–∞ mel quality (–±–æ–ª–µ–µ –¥–æ—Å—Ç–∏–∂–∏–º–∞—è)
        min_mel_quality = quality_checks.get('mel_quality_threshold', 0.3)  # –°–Ω–∏–∂–µ–Ω–æ —Å 0.5
        current_mel_quality = metrics.get('mel_quality_score', 0.0)
        mel_check = current_mel_quality >= min_mel_quality
        checks.append(mel_check)
        check_details.append(f"mel_quality: {current_mel_quality:.3f} >= {min_mel_quality} ({'‚úÖ' if mel_check else '‚ùå'})")
        
        # 5. –ù–û–í–ê–Ø –ø—Ä–æ–≤–µ—Ä–∫–∞ –ø—Ä–æ–≥—Ä–µ—Å—Å–∞ –æ–±—É—á–µ–Ω–∏—è
        min_progress = quality_checks.get('min_training_progress', 0.05)
        training_loss = metrics.get('training_loss', float('inf'))
        initial_loss = metrics.get('initial_training_loss', training_loss)
        progress = (initial_loss - training_loss) / initial_loss if initial_loss > 0 else 0
        progress_check = progress >= min_progress
        checks.append(progress_check)
        check_details.append(f"training_progress: {progress:.3f} >= {min_progress} ({'‚úÖ' if progress_check else '‚ùå'})")
        
        # üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø—Ä–æ–≤–µ—Ä–æ–∫
        passed_checks = sum(checks)
        total_checks = len(checks)
        
        # üéØ –ë–û–õ–ï–ï –°–¢–†–û–ì–ê–Ø –õ–û–ì–ò–ö–ê: —Ç—Ä–µ–±—É–µ–º –ø—Ä–æ—Ö–æ–∂–¥–µ–Ω–∏—è –º–∏–Ω–∏–º—É–º 80% –ø—Ä–æ–≤–µ—Ä–æ–∫ + –≤—Å–µ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ
        min_required_checks = max(2, int(total_checks * 0.8))  # –ú–∏–Ω–∏–º—É–º 80% –ø—Ä–æ–≤–µ—Ä–æ–∫
        critical_checks_passed = attention_check and gate_check and val_loss_check  # –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ –ø—Ä–æ–≤–µ—Ä–∫–∏
        
        quality_passed = passed_checks >= min_required_checks and critical_checks_passed
        
        # –ü–æ–¥—Ä–æ–±–Ω—ã–π –ª–æ–≥ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        self.logger.info(f"üîç –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ TTS:")
        for detail in check_details:
            self.logger.info(f"  ‚Ä¢ {detail}")
        self.logger.info(f"‚è∞ –í—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è: {training_duration/60:.1f} –º–∏–Ω, validation —à–∞–≥–æ–≤: {validation_step}")
        
        if quality_passed:
            self.logger.info(f"‚úÖ –ö–∞—á–µ—Å—Ç–≤–æ –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ–µ: {passed_checks}/{total_checks} –ø—Ä–æ–≤–µ—Ä–æ–∫ –ø—Ä–æ–π–¥–µ–Ω–æ ({passed_checks/total_checks*100:.1f}%)")
        else:
            self.logger.warning(f"‚ö†Ô∏è –ü—Ä–æ–±–ª–µ–º—ã –∫–∞—á–µ—Å—Ç–≤–∞: {passed_checks}/{total_checks} –ø—Ä–æ–≤–µ—Ä–æ–∫ –ø—Ä–æ–π–¥–µ–Ω–æ, —Ç—Ä–µ–±—É–µ—Ç—Å—è –º–∏–Ω–∏–º—É–º {min_required_checks} + –≤—Å–µ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ –ø—Ä–æ–≤–µ—Ä–∫–∏")
        
        return quality_passed
    
    def run_single_training(self, hyperparams: Optional[Dict[str, Any]] = None) -> Dict[str, Any]:
        """
        –ó–∞–ø—É—Å–∫ –∞–¥–∞–ø—Ç–∏–≤–Ω–æ–≥–æ TTS –æ–±—É—á–µ–Ω–∏—è —Å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–π –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–µ–π
        
        Args:
            hyperparams: –ì–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è –æ–±—É—á–µ–Ω–∏—è (–∏—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è –ª—É—á—à–∏–µ –µ—Å–ª–∏ –Ω–µ —É–∫–∞–∑–∞–Ω–æ)
            
        Returns:
            –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ–±—É—á–µ–Ω–∏—è
        """
        self.logger.info("üöÇ –ó–∞–ø—É—Å–∫ –∞–¥–∞–ø—Ç–∏–≤–Ω–æ–≥–æ TTS –æ–±—É—á–µ–Ω–∏—è —Å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–π –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–µ–π...")
        
        from datetime import datetime
        self.training_start_time = datetime.now()
        max_restarts = 3
        current_restart = 0
        best_results = None
        best_score = float('inf')
        
        try:
            while current_restart <= max_restarts:
                self.logger.info(f"üîÑ –ò—Ç–µ—Ä–∞—Ü–∏—è –æ–±—É—á–µ–Ω–∏—è: {current_restart + 1}/{max_restarts + 1}")
                
                # –ï—Å–ª–∏ —ç—Ç–æ –Ω–µ –ø–µ—Ä–≤—ã–π –∑–∞–ø—É—Å–∫, –ø—Ä–æ–≤–æ–¥–∏–º –º–∏–Ω–∏-–æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—é
                if current_restart > 0:
                    self.logger.info("üîç –ó–∞–ø—É—Å–∫ –º–∏–Ω–∏-–æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤...")
                    mini_optimization_results = self._run_mini_optimization(n_trials=8)
                    
                    if mini_optimization_results and mini_optimization_results.get('best_params'):
                        hyperparams = mini_optimization_results['best_params']
                        self.logger.info(f"‚úÖ –ù–∞–π–¥–µ–Ω—ã —É–ª—É—á—à–µ–Ω–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã: {hyperparams}")
                
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ª—É—á—à–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –µ—Å–ª–∏ –æ–Ω–∏ –Ω–µ –ø–µ—Ä–µ–¥–∞–Ω—ã
                if hyperparams is None:
                    hyperparams = self._get_best_hyperparams()
                    
                if not hyperparams:
                    self.logger.warning("–ò—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –∏–∑ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏")
                    hyperparams = self._get_default_hyperparams()
                
                self.logger.info(f"üéõÔ∏è TTS –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä—ã (–∏—Ç–µ—Ä–∞—Ü–∏—è {current_restart + 1}): {hyperparams}")
                
                # –°–æ–∑–¥–∞–µ–º TensorBoard writer –¥–ª—è single training
                from torch.utils.tensorboard import SummaryWriter
                log_dir = os.path.join("output", "latest", f"single_training_restart_{current_restart}")
                os.makedirs(log_dir, exist_ok=True)
                writer = SummaryWriter(log_dir)
                
                # –ó–∞–ø—É—Å–∫–∞–µ–º –æ–±—É—á–µ–Ω–∏–µ —Å TTS –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–æ–º
                results = self.trainer_wrapper.train_with_params(
                    hyperparams,
                    writer=writer,
                    tts_phase_training=self.tts_config.get('enabled', True),
                    single_training=True,
                    restart_iteration=current_restart
                )
                
                # –ó–∞–∫—Ä—ã–≤–∞–µ–º writer
                writer.close()
                
                if results:
                    # –í—ã—á–∏—Å–ª—è–µ–º –∫–æ–º–ø–æ–∑–∏—Ç–Ω—É—é –æ—Ü–µ–Ω–∫—É –∫–∞—á–µ—Å—Ç–≤–∞
                    current_score = self.optimization_engine.calculate_composite_tts_objective(results)
                    self.logger.info(f"üìä –û—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ –∏—Ç–µ—Ä–∞—Ü–∏–∏ {current_restart + 1}: {current_score:.4f}")
                    
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —É–ª—É—á—à–∏–ª–∏—Å—å –ª–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
                    if current_score < best_score:
                        best_score = current_score
                        best_results = results.copy()
                        self.logger.info(f"‚úÖ –ù–æ–≤—ã–π –ª—É—á—à–∏–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç: {best_score:.4f}")
                        
                        # –ï—Å–ª–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —Ö–æ—Ä–æ—à, –ø—Ä–µ–∫—Ä–∞—â–∞–µ–º
                        if self._check_tts_quality_thresholds(results):
                            self.logger.info("üéâ –î–æ—Å—Ç–∏–≥–Ω—É—Ç–æ –≤—ã—Å–æ–∫–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ TTS! –ó–∞–≤–µ—Ä—à–∞–µ–º –æ–±—É—á–µ–Ω–∏–µ.")
                            break
                    else:
                        self.logger.info(f"‚ö†Ô∏è –†–µ–∑—É–ª—å—Ç–∞—Ç –Ω–µ —É–ª—É—á—à–∏–ª—Å—è. –õ—É—á—à–∏–π: {best_score:.4f}")
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω—É–∂–µ–Ω –ª–∏ –ø–µ—Ä–µ–∑–∞–ø—É—Å–∫
                if current_restart < max_restarts:
                    if self._should_restart_training(results):
                        self.logger.info("üîÑ –û–±–Ω–∞—Ä—É–∂–µ–Ω—ã –ø—Ä–æ–±–ª–µ–º—ã –∫–∞—á–µ—Å—Ç–≤–∞. –ü–ª–∞–Ω–∏—Ä—É–µ—Ç—Å—è –ø–µ—Ä–µ–∑–∞–ø—É—Å–∫ —Å –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–µ–π...")
                        
                        # üì± –û—Ç–ø—Ä–∞–≤–ª—è–µ–º Telegram —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ –æ –ø–µ—Ä–µ–∑–∞–ø—É—Å–∫–µ
                        if self.alert_manager:
                            try:
                                restart_reason = self._get_restart_reason(results)
                                improvement_plan = self._create_improvement_plan(results, current_restart)
                                
                                self.alert_manager.send_training_restart(
                                    restart_reason=restart_reason,
                                    restart_number=current_restart + 1,
                                    current_metrics=results,
                                    improvement_plan=improvement_plan
                                )
                                self.logger.info("üì± Telegram —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ –æ –ø–µ—Ä–µ–∑–∞–ø—É—Å–∫–µ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–æ")
                            except Exception as e:
                                self.logger.warning(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –æ—Ç–ø—Ä–∞–≤–∏—Ç—å Telegram —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ –æ –ø–µ—Ä–µ–∑–∞–ø—É—Å–∫–µ: {e}")
                        
                        current_restart += 1
                        continue
                    else:
                        self.logger.info("‚úÖ –ö–∞—á–µ—Å—Ç–≤–æ —É–¥–æ–≤–ª–µ—Ç–≤–æ—Ä–∏—Ç–µ–ª—å–Ω–æ–µ. –ó–∞–≤–µ—Ä—à–∞–µ–º –æ–±—É—á–µ–Ω–∏–µ.")
                        break
                else:
                    self.logger.info("üìä –î–æ—Å—Ç–∏–≥–Ω—É—Ç–æ –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–µ—Ä–µ–∑–∞–ø—É—Å–∫–æ–≤.")
                    break
            
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ª—É—á—à–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
            final_results = best_results if best_results else results
            
            # –§–∏–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ TTS
            if self.training_logger and self.export_system:
                finish_training_logging(
                    self.training_logger, 
                    self.export_system,
                    final_metrics=final_results
                )
            
            from datetime import datetime
            training_duration = datetime.now() - self.training_start_time
            self.logger.info(f"üéâ –ê–¥–∞–ø—Ç–∏–≤–Ω–æ–µ TTS –æ–±—É—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ –∑–∞ {training_duration}")
            self.logger.info(f"üèÜ –õ—É—á—à–∞—è –æ—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞: {best_score:.4f}")
            self.logger.info(f"üîÑ –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–µ—Ä–µ–∑–∞–ø—É—Å–∫–æ–≤: {current_restart}")
            
            # –°–æ–∑–¥–∞–µ–º —ç–∫—Å–ø–æ—Ä—Ç –¥–ª—è AI –∞–Ω–∞–ª–∏–∑–∞
            try:
                export_path = export_current_training()
                self.logger.info(f"üì§ TTS —ç–∫—Å–ø–æ—Ä—Ç —Å–æ–∑–¥–∞–Ω: {export_path}")
            except Exception as e:
                self.logger.warning(f"–û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è —ç–∫—Å–ø–æ—Ä—Ç–∞: {e}")
            
            return final_results
            
        except Exception as e:
            self.logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∞–¥–∞–ø—Ç–∏–≤–Ω–æ–º TTS –æ–±—É—á–µ–Ω–∏–∏: {e}")
            
            # –ü–æ–ø—ã—Ç–∫–∞ —Ñ–∏–Ω–∞–ª–∏–∑–∞—Ü–∏–∏ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è –ø—Ä–∏ –æ—à–∏–±–∫–µ
            if self.training_logger:
                try:
                    finish_training_logging(
                        self.training_logger, 
                        self.export_system,
                        final_metrics={'error': str(e)},
                        training_completed=False
                    )
                except:
                    pass
            
            raise
    
    def _get_best_hyperparams(self) -> Optional[Dict[str, Any]]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –ª—É—á—à–∏—Ö TTS –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –∏–∑ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏"""
        if not self.optimization_engine or not self.optimization_engine.study:
            return None
            
        try:
            if self.optimization_engine.study.best_trial:
                return self.optimization_engine.study.best_params
        except:
            pass
            
        return None
    
    def _run_mini_optimization(self, n_trials: int = 8) -> Dict[str, Any]:
        """
        –ó–∞–ø—É—Å–∫ –º–∏–Ω–∏-–æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
        
        Args:
            n_trials: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ trials –¥–ª—è –º–∏–Ω–∏-–æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏
            
        Returns:
            –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –º–∏–Ω–∏-–æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏
        """
        self.logger.info(f"üîç –ú–∏–Ω–∏-–æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è: {n_trials} trials")
        
        try:
            study = self.optimization_engine.create_study(
                study_name=f"mini_opt_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
            )
            
            def mini_objective_function(trial):
                """–û–±–ª–µ–≥—á–µ–Ω–Ω–∞—è —Ü–µ–ª–µ–≤–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –º–∏–Ω–∏-–æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏"""
                suggested_params = self.optimization_engine.suggest_hyperparameters(trial)
                
                # –ó–∞–ø—É—Å–∫–∞–µ–º –∫–æ—Ä–æ—Ç–∫–æ–µ –æ–±—É—á–µ–Ω–∏–µ (50 —ç–ø–æ—Ö)
                suggested_params['epochs'] = 50
                
                try:
                    # –°–æ–∑–¥–∞–µ–º TensorBoard writer –¥–ª—è –º–∏–Ω–∏-–æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏
                    from torch.utils.tensorboard import SummaryWriter
                    log_dir = os.path.join("output", "latest", f"mini_opt_trial_{trial.number}")
                    os.makedirs(log_dir, exist_ok=True)
                    writer = SummaryWriter(log_dir)
                    
                    metrics = self.trainer_wrapper.train_with_params(
                        suggested_params, 
                        trial=trial,
                        writer=writer,
                        mini_optimization=True
                    )
                    
                    # –ó–∞–∫—Ä—ã–≤–∞–µ–º writer
                    writer.close()
                    
                    if metrics:
                        return self.optimization_engine.calculate_composite_tts_objective(metrics)
                    else:
                        return float('inf')
                        
                except Exception as e:
                    self.logger.warning(f"–û—à–∏–±–∫–∞ –≤ –º–∏–Ω–∏-trial {trial.number}: {e}")
                    return float('inf')
            
            # –ó–∞–ø—É—Å–∫–∞–µ–º –º–∏–Ω–∏-–æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—é
            study.optimize(mini_objective_function, n_trials=n_trials)
            
            if study.best_trial:
                return {
                    'best_params': study.best_params,
                    'best_score': study.best_value,
                    'n_trials': len(study.trials)
                }
            else:
                return None
                
        except Exception as e:
            self.logger.error(f"–û—à–∏–±–∫–∞ –º–∏–Ω–∏-–æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏: {e}")
            return None
    
    def _should_restart_training(self, results: Dict[str, Any]) -> bool:
        """
        üöÄ –£–õ–£–ß–®–ï–ù–ù–ê–Ø —Ñ—É–Ω–∫—Ü–∏—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏ –ø–µ—Ä–µ–∑–∞–ø—É—Å–∫–∞ –æ–±—É—á–µ–Ω–∏—è
        –¢–µ–ø–µ—Ä—å –±–æ–ª–µ–µ —É–º–Ω–∞—è –∏ –∞–¥–∞–ø—Ç–∏–≤–Ω–∞—è –ª–æ–≥–∏–∫–∞ –ø—Ä–∏–Ω—è—Ç–∏—è —Ä–µ—à–µ–Ω–∏–π + –∑–∞—â–∏—Ç–∞ –æ—Ç —Ä–∞–Ω–Ω–µ–≥–æ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è
        """
        if not results:
            self.logger.info("üìä –ü—É—Å—Ç—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã - —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –ø–µ—Ä–µ–∑–∞–ø—É—Å–∫")
            return True
            
        # üõ°Ô∏è –î–û–ü–û–õ–ù–ò–¢–ï–õ–¨–ù–ê–Ø –ó–ê–©–ò–¢–ê: –ø—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ–µ –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏–µ –µ—Å–ª–∏ –æ–±—É—á–µ–Ω–∏–µ —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–æ–µ
        training_duration = 0
        if hasattr(self, 'training_start_time') and self.training_start_time is not None:
            from datetime import datetime
            training_duration = (datetime.now() - self.training_start_time).total_seconds()
            min_training_time = 600  # 10 –º–∏–Ω—É—Ç –º–∏–Ω–∏–º—É–º
            if training_duration < min_training_time:
                self.logger.info(f"‚è∞ –û–±—É—á–µ–Ω–∏–µ —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–æ–µ ({training_duration/60:.1f} –º–∏–Ω < {min_training_time/60:.1f} –º–∏–Ω). –ü–†–ò–ù–£–î–ò–¢–ï–õ–¨–ù–û–ï –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏–µ...")
                return True  # –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ –ø–µ—Ä–µ–∑–∞–ø—É—Å–∫–∞–µ–º (–ø—Ä–æ–¥–æ–ª–∂–∞–µ–º)
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ validation —à–∞–≥–æ–≤
        validation_step = results.get('validation.step', 0)
        min_validation_steps = 3  # –ú–∏–Ω–∏–º—É–º 3 validation —à–∞–≥–∞
        if validation_step < min_validation_steps:
            self.logger.info(f"üìä –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ validation —à–∞–≥–æ–≤ ({validation_step} < {min_validation_steps}). –ü–†–ò–ù–£–î–ò–¢–ï–õ–¨–ù–û–ï –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏–µ...")
            return True  # –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ –ø–µ—Ä–µ–∑–∞–ø—É—Å–∫–∞–µ–º (–ø—Ä–æ–¥–æ–ª–∂–∞–µ–º)
        
        # üìä –ü–æ–ª—É—á–∞–µ–º –∫–ª—é—á–µ–≤—ã–µ –º–µ—Ç—Ä–∏–∫–∏ —Å –±–µ–∑–æ–ø–∞—Å–Ω—ã–º–∏ –∑–Ω–∞—á–µ–Ω–∏—è–º–∏ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
        val_loss = results.get('validation_loss', float('inf'))
        attention_score = results.get('attention_alignment_score', 0.0)
        gate_accuracy = results.get('gate_accuracy', 0.0)
        mel_quality = results.get('mel_quality_score', 0.0)
        training_loss = results.get('training_loss', float('inf'))
        initial_loss = results.get('initial_training_loss', training_loss)
        
        # üö® –ö–†–ò–¢–ò–ß–ï–°–ö–ò–ï –ü–†–û–ë–õ–ï–ú–´ (–æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–π –ø–µ—Ä–µ–∑–∞–ø—É—Å–∫)
        critical_problems = []
        
        # 1. Validation loss –∫–∞—Ç–∞—Å—Ç—Ä–æ—Ñ–∏—á–µ—Å–∫–∏ –≤—ã—Å–æ–∫–∏–π
        if val_loss > 100.0:
            critical_problems.append(f"validation_loss —Å–ª–∏—à–∫–æ–º –≤—ã—Å–æ–∫–∏–π: {val_loss:.2f}")
        
        # 2. –ü–æ–ª–Ω–æ–µ –æ—Ç—Å—É—Ç—Å—Ç–≤–∏–µ attention
        if attention_score < 0.05:
            critical_problems.append(f"attention –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏ –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç: {attention_score:.3f}")
        
        # 3. Gate accuracy –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏ –Ω–∏–∑–∫–∏–π
        if gate_accuracy < 0.1:
            critical_problems.append(f"gate_accuracy –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏ –Ω–∏–∑–∫–∏–π: {gate_accuracy:.3f}")
        
        # 4. –ü–æ–ª–Ω–æ–µ –æ—Ç—Å—É—Ç—Å—Ç–≤–∏–µ –ø—Ä–æ–≥—Ä–µ—Å—Å–∞ –æ–±—É—á–µ–Ω–∏—è
        progress = (initial_loss - training_loss) / initial_loss if initial_loss > 0 else 0
        if progress < -0.1:  # –û–±—É—á–µ–Ω–∏–µ —É—Ö—É–¥—à–∞–µ—Ç—Å—è
            critical_problems.append(f"–æ–±—É—á–µ–Ω–∏–µ –¥–µ–≥—Ä–∞–¥–∏—Ä—É–µ—Ç: –ø—Ä–æ–≥—Ä–µ—Å—Å {progress:.3f}")
        
        if critical_problems:
            self.logger.warning("üö® –û–±–Ω–∞—Ä—É–∂–µ–Ω—ã –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ –ø—Ä–æ–±–ª–µ–º—ã:")
            for problem in critical_problems:
                self.logger.warning(f"  ‚Ä¢ {problem}")
            self.logger.info("üîÑ –†–ï–ö–û–ú–ï–ù–î–£–ï–¢–°–Ø –ü–ï–†–ï–ó–ê–ü–£–°–ö")
            return True
        
        # ‚ö†Ô∏è –°–ï–†–¨–ï–ó–ù–´–ï –ü–†–û–ë–õ–ï–ú–´ (–ø–µ—Ä–µ–∑–∞–ø—É—Å–∫ –ø—Ä–∏ –Ω–∞–∫–æ–ø–ª–µ–Ω–∏–∏)
        serious_problems = []
        
        # 1. Validation loss –≤—ã—Å–æ–∫–∏–π, –Ω–æ –Ω–µ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏–π
        if 25.0 < val_loss <= 100.0:
            serious_problems.append(f"validation_loss –≤—ã—Å–æ–∫–∏–π: {val_loss:.2f}")
        
        # 2. Attention —Å–ª–∞–±—ã–π
        if 0.05 <= attention_score < 0.3:
            serious_problems.append(f"attention —Å–ª–∞–±—ã–π: {attention_score:.3f}")
        
        # 3. Gate accuracy –Ω–∏–∑–∫–∏–π
        if 0.1 <= gate_accuracy < 0.4:
            serious_problems.append(f"gate_accuracy –Ω–∏–∑–∫–∏–π: {gate_accuracy:.3f}")
        
        # 4. Mel quality –Ω–µ—É–¥–æ–≤–ª–µ—Ç–≤–æ—Ä–∏—Ç–µ–ª—å–Ω—ã–π
        if mel_quality < 0.2:
            serious_problems.append(f"mel_quality –Ω–µ—É–¥–æ–≤–ª–µ—Ç–≤–æ—Ä–∏—Ç–µ–ª—å–Ω—ã–π: {mel_quality:.3f}")
        
        # 5. –ú–µ–¥–ª–µ–Ω–Ω—ã–π –ø—Ä–æ–≥—Ä–µ—Å—Å
        if 0 <= progress < 0.02:
            serious_problems.append(f"–º–µ–¥–ª–µ–Ω–Ω—ã–π –ø—Ä–æ–≥—Ä–µ—Å—Å: {progress:.3f}")
        
        # –ü–µ—Ä–µ–∑–∞–ø—É—Å–∫ –µ—Å–ª–∏ –º–Ω–æ–≥–æ —Å–µ—Ä—å–µ–∑–Ω—ã—Ö –ø—Ä–æ–±–ª–µ–º
        serious_threshold = 3  # –ú–∞–∫—Å–∏–º—É–º 2 —Å–µ—Ä—å–µ–∑–Ω—ã–µ –ø—Ä–æ–±–ª–µ–º—ã
        if len(serious_problems) >= serious_threshold:
            self.logger.warning(f"‚ö†Ô∏è –û–±–Ω–∞—Ä—É–∂–µ–Ω–æ {len(serious_problems)} —Å–µ—Ä—å–µ–∑–Ω—ã—Ö –ø—Ä–æ–±–ª–µ–º:")
            for problem in serious_problems:
                self.logger.warning(f"  ‚Ä¢ {problem}")
            self.logger.info("üîÑ –†–ï–ö–û–ú–ï–ù–î–£–ï–¢–°–Ø –ü–ï–†–ï–ó–ê–ü–£–°–ö –∏–∑-–∑–∞ –Ω–∞–∫–æ–ø–ª–µ–Ω–∏—è –ø—Ä–æ–±–ª–µ–º")
            return True
        elif serious_problems:
            self.logger.info(f"‚ö†Ô∏è –û–±–Ω–∞—Ä—É–∂–µ–Ω–æ {len(serious_problems)} —Å–µ—Ä—å–µ–∑–Ω—ã—Ö –ø—Ä–æ–±–ª–µ–º (–¥–æ–ø—É—Å—Ç–∏–º–æ):")
            for problem in serious_problems:
                self.logger.info(f"  ‚Ä¢ {problem}")
        
        # üéØ –ü–û–õ–û–ñ–ò–¢–ï–õ–¨–ù–´–ï –ü–û–ö–ê–ó–ê–¢–ï–õ–ò (–ø—Ä–æ–¥–æ–ª–∂–∞–µ–º –æ–±—É—á–µ–Ω–∏–µ)
        good_indicators = []
        
        if val_loss <= 25.0:
            good_indicators.append(f"validation_loss –ø—Ä–∏–µ–º–ª–µ–º—ã–π: {val_loss:.2f}")
        if attention_score >= 0.3:
            good_indicators.append(f"attention —Ö–æ—Ä–æ—à–∏–π: {attention_score:.3f}")
        if gate_accuracy >= 0.4:
            good_indicators.append(f"gate_accuracy –ø—Ä–∏–µ–º–ª–µ–º—ã–π: {gate_accuracy:.3f}")
        if mel_quality >= 0.2:
            good_indicators.append(f"mel_quality –ø—Ä–∏–µ–º–ª–µ–º—ã–π: {mel_quality:.3f}")
        if progress >= 0.02:
            good_indicators.append(f"—Ö–æ—Ä–æ—à–∏–π –ø—Ä–æ–≥—Ä–µ—Å—Å: {progress:.3f}")
        
        should_restart = len(good_indicators) < 2  # –ù—É–∂–Ω–æ –º–∏–Ω–∏–º—É–º 2 —Ö–æ—Ä–æ—à–∏—Ö –ø–æ–∫–∞–∑–∞—Ç–µ–ª—è
        
        if should_restart:
            self.logger.info(f"üîÑ –†–ï–ö–û–ú–ï–ù–î–£–ï–¢–°–Ø –ü–ï–†–ï–ó–ê–ü–£–°–ö: –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —Ö–æ—Ä–æ—à–∏—Ö –ø–æ–∫–∞–∑–∞—Ç–µ–ª–µ–π ({len(good_indicators)}/5)")
        else:
            self.logger.info(f"‚úÖ –ü–†–û–î–û–õ–ñ–ê–ï–ú –û–ë–£–ß–ï–ù–ò–ï: –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —Ö–æ—Ä–æ—à–∏—Ö –ø–æ–∫–∞–∑–∞—Ç–µ–ª–µ–π ({len(good_indicators)}/5)")
            for indicator in good_indicators:
                self.logger.info(f"  ‚Ä¢ {indicator}")
        
        # üìä –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
        if not should_restart:
            self.logger.info("üìà –¢–µ–∫—É—â–∏–µ –º–µ—Ç—Ä–∏–∫–∏ TTS:")
            self.logger.info(f"  ‚Ä¢ val_loss: {val_loss:.3f}")
            self.logger.info(f"  ‚Ä¢ attention_score: {attention_score:.3f}")
            self.logger.info(f"  ‚Ä¢ gate_accuracy: {gate_accuracy:.3f}")
            self.logger.info(f"  ‚Ä¢ mel_quality: {mel_quality:.3f}")
            progress_pct = (initial_loss - training_loss) / initial_loss * 100 if initial_loss > 0 else float('nan')
            self.logger.info(f"  ‚Ä¢ –ø—Ä–æ–≥—Ä–µ—Å—Å: {progress_pct:.1f}%")
            
        return should_restart
    
    def _get_default_hyperparams(self) -> Dict[str, Any]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ TTS –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –∏–∑ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏"""
        search_space = self.config.get('hyperparameter_search_space', {})
        default_params = {}
        
        for param_name, param_config in search_space.items():
            default_value = param_config.get('default')
            if default_value is not None:
                default_params[param_name] = default_value
            elif param_config.get('type') == 'categorical':
                choices = param_config.get('choices', [])
                if choices:
                    default_params[param_name] = choices[0]
                    
        return default_params
    
    def _save_tts_optimization_results(self, results: Dict[str, Any]):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ TTS –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏"""
        try:
            results_dir = Path("smart_tuner/optimization_results")
            results_dir.mkdir(parents=True, exist_ok=True)
            
            from datetime import datetime
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            results_file = results_dir / f"tts_optimization_{timestamp}.yaml"
            
            # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è
            save_data = {
                'timestamp': timestamp,
                'best_parameters': results.get('best_params', {}),
                'best_value': results.get('best_value', float('inf')),
                'n_trials': results.get('n_trials', 0),
                'study_name': results.get('study_name', 'unknown'),
                'tts_analysis': results.get('tts_analysis', {}),
                'metadata': {
                    'config_path': self.config_path,
                    'tts_version': 'Smart Tuner V2 TTS',
                    'optimization_type': 'composite_tts_objective'
                }
            }
            
            with open(results_file, 'w', encoding='utf-8') as f:
                yaml.dump(save_data, f, default_flow_style=False, allow_unicode=True)
            
            self.logger.info(f"üíæ TTS —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã: {results_file}")
            
        except Exception as e:
            self.logger.error(f"–û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤: {e}")
    
    def run_monitoring_mode(self):
        """–†–µ–∂–∏–º –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ TTS –æ–±—É—á–µ–Ω–∏—è"""
        self.logger.info("üëÅÔ∏è –ó–∞–ø—É—Å–∫ —Ä–µ–∂–∏–º–∞ TTS –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞...")
        
        try:
            # –°–æ–∑–¥–∞–µ–º —Ñ–∞–π–ª—ã –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ –µ—Å–ª–∏ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É—é—Ç
            monitoring_dir = Path("smart_tuner/monitoring") 
            monitoring_dir.mkdir(parents=True, exist_ok=True)
            
            status_file = monitoring_dir / "tts_status.yaml"
            
            while True:
                try:
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ç–∞—Ç—É—Å TTS –æ–±—É—á–µ–Ω–∏—è
                    tts_status = self._get_tts_training_status()
                    
                    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å—Ç–∞—Ç—É—Å
                    with open(status_file, 'w', encoding='utf-8') as f:
                        yaml.dump(tts_status, f, default_flow_style=False)
                    
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∞–ª–µ—Ä—Ç—ã
                    if self.alert_manager:
                        self.alert_manager.check_training_status(tts_status)
                    
                    time.sleep(30)  # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–∞–∂–¥—ã–µ 30 —Å–µ–∫—É–Ω–¥
                    
                except KeyboardInterrupt:
                    self.logger.info("üõë –û—Å—Ç–∞–Ω–æ–≤–∫–∞ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ –ø–æ –∑–∞–ø—Ä–æ—Å—É –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è")
                    break
                except Exception as e:
                    self.logger.error(f"–û—à–∏–±–∫–∞ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞: {e}")
                    time.sleep(60)  # –ñ–¥–µ–º –º–∏–Ω—É—Ç—É –ø—Ä–∏ –æ—à–∏–±–∫–µ
                    
        except Exception as e:
            self.logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Ä–µ–∂–∏–º–∞ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞: {e}")
    
    def _get_tts_training_status(self) -> Dict[str, Any]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç–∞—Ç—É—Å–∞ TTS –æ–±—É—á–µ–Ω–∏—è"""
        status = {
            'timestamp': datetime.now().isoformat(),
            'mode': 'monitoring',
            'tts_version': 'Smart Tuner V2 TTS'
        }
        
        try:
            # –°—Ç–∞—Ç—É—Å –æ—Ç early stop controller
            if self.early_stop_controller:
                tts_summary = self.early_stop_controller.get_tts_training_summary()
                status.update(tts_summary)
            
            # –°—Ç–∞—Ç—É—Å –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏
            if self.optimization_engine:
                opt_stats = self.optimization_engine.get_study_statistics()
                status['optimization'] = opt_stats
                
        except Exception as e:
            status['error'] = str(e)
            
        return status
    
    def cleanup(self):
        """–û—á–∏—Å—Ç–∫–∞ —Ä–µ—Å—É—Ä—Å–æ–≤ TTS —Å–∏—Å—Ç–µ–º—ã"""
        self.logger.info("üßπ –û—á–∏—Å—Ç–∫–∞ TTS —Ä–µ—Å—É—Ä—Å–æ–≤...")
        
        try:
            if self.optimization_engine:
                self.optimization_engine.cleanup_study()
                
            if self.early_stop_controller:
                self.early_stop_controller.reset()
                
            if self.alert_manager and hasattr(self.alert_manager, 'cleanup'):
                self.alert_manager.cleanup()
                
            self.logger.info("‚úÖ TTS —Ä–µ—Å—É—Ä—Å—ã –æ—á–∏—â–µ–Ω—ã")
            
        except Exception as e:
            self.logger.error(f"–û—à–∏–±–∫–∞ –æ—á–∏—Å—Ç–∫–∏: {e}")
    
    def run_automatic_mode(self, n_trials: int = 15) -> Dict[str, Any]:
        """
        ü§ñ –ü–û–õ–ù–û–°–¢–¨–Æ –ê–í–¢–û–ú–ê–¢–ò–ß–ï–°–ö–ò–ô –†–ï–ñ–ò–ú
        –°–Ω–∞—á–∞–ª–∞ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤, –∑–∞—Ç–µ–º –æ–±—É—á–µ–Ω–∏–µ —Å –ª—É—á—à–∏–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏
        """
        self.logger.info("ü§ñ –ó–∞–ø—É—Å–∫ –ø–æ–ª–Ω–æ—Å—Ç—å—é –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ —Ä–µ–∂–∏–º–∞ TTS –æ–±—É—á–µ–Ω–∏—è")
        self.logger.info("=" * 80)
        
        from datetime import datetime
        total_start_time = datetime.now()
        final_results = {}
        
        try:
            # –≠–¢–ê–ü 1: –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
            self.logger.info("üéØ –≠–¢–ê–ü 1/2: –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤")
            self.logger.info("=" * 50)
            
            optimization_results = self.run_optimization()
            
            if optimization_results and optimization_results.get('best_parameters'):
                best_params = optimization_results['best_parameters']
                best_score = optimization_results.get('best_value', float('inf'))
                
                self.logger.info(f"‚úÖ –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ!")
                self.logger.info(f"üèÜ –õ—É—á—à–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã: {best_params}")
                self.logger.info(f"üìä –õ—É—á—à–∞—è –æ—Ü–µ–Ω–∫–∞: {best_score:.4f}")
                
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏
                self._save_tts_optimization_results(optimization_results)
                final_results['optimization'] = optimization_results
                
                # –ü–∞—É–∑–∞ –º–µ–∂–¥—É —ç—Ç–∞–ø–∞–º–∏
                self.logger.info("‚è≥ –ü–∞—É–∑–∞ –º–µ–∂–¥—É —ç—Ç–∞–ø–∞–º–∏ (30 —Å–µ–∫)...")
                time.sleep(30)
                
                # –≠–¢–ê–ü 2: –û–±—É—á–µ–Ω–∏–µ —Å –ª—É—á—à–∏–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏
                self.logger.info("üöÄ –≠–¢–ê–ü 2/2: –û–±—É—á–µ–Ω–∏–µ —Å –ª—É—á—à–∏–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏")
                self.logger.info("=" * 50)
                
                training_results = self.run_single_training(best_params)
                
                if training_results:
                    final_results['training'] = training_results
                    self.logger.info("‚úÖ –û–±—É—á–µ–Ω–∏–µ —Å –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏ –∑–∞–≤–µ—Ä—à–µ–Ω–æ!")
                    
                    # –ê–Ω–∞–ª–∏–∑ —Ñ–∏–Ω–∞–ª—å–Ω–æ–≥–æ –∫–∞—á–µ—Å—Ç–≤–∞
                    final_score = self.optimization_engine.calculate_composite_tts_objective(training_results)
                    improvement = ((best_score - final_score) / best_score * 100) if best_score > 0 else 0
                    
                    self.logger.info(f"üìà –£–ª—É—á—à–µ–Ω–∏–µ –∫–∞—á–µ—Å—Ç–≤–∞: {improvement:.1f}%")
                    self.logger.info(f"üéØ –§–∏–Ω–∞–ª—å–Ω–∞—è –æ—Ü–µ–Ω–∫–∞: {final_score:.4f}")
                    
                    final_results['improvement_percent'] = improvement
                    final_results['final_score'] = final_score
                else:
                    self.logger.error("‚ùå –û–±—É—á–µ–Ω–∏–µ —Å –ª—É—á—à–∏–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏ –Ω–µ —É–¥–∞–ª–æ—Å—å")
                    final_results['training_error'] = True
            else:
                self.logger.error("‚ùå –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –Ω–µ –¥–∞–ª–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤")
                final_results['optimization_error'] = True
                
                # –ó–∞–ø—É—Å–∫–∞–µ–º –æ–±—É—á–µ–Ω–∏–µ —Å –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
                self.logger.info("üîÑ –ó–∞–ø—É—Å–∫ –æ–±—É—á–µ–Ω–∏—è —Å –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é...")
                default_params = self._get_default_hyperparams()
                training_results = self.run_single_training(default_params)
                final_results['training'] = training_results
            
            # –û–±—â–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
            from datetime import datetime
            total_duration = datetime.now() - total_start_time
            final_results['total_duration'] = str(total_duration)
            
            self.logger.info("=" * 80)
            self.logger.info("üéâ –ê–í–¢–û–ú–ê–¢–ò–ß–ï–°–ö–ò–ô –†–ï–ñ–ò–ú –ó–ê–í–ï–†–®–ï–ù!")
            self.logger.info("=" * 80)
            self.logger.info(f"‚è±Ô∏è –û–±—â–µ–µ –≤—Ä–µ–º—è: {total_duration}")
            
            if 'improvement_percent' in final_results:
                self.logger.info(f"üìà –£–ª—É—á—à–µ–Ω–∏–µ: {final_results['improvement_percent']:.1f}%")
            
            # –°–æ–∑–¥–∞–µ–º —ç–∫—Å–ø–æ—Ä—Ç –∏—Ç–æ–≥–æ–≤–æ–≥–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
            try:
                export_path = export_current_training()
                self.logger.info(f"üì§ –ò—Ç–æ–≥–æ–≤—ã–π —ç–∫—Å–ø–æ—Ä—Ç —Å–æ–∑–¥–∞–Ω: {export_path}")
                final_results['export_path'] = export_path
            except Exception as e:
                self.logger.warning(f"–û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è —ç–∫—Å–ø–æ—Ä—Ç–∞: {e}")
                
            return final_results
            
        except Exception as e:
            self.logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≤ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–º —Ä–µ–∂–∏–º–µ: {e}")
            final_results['error'] = str(e)
            return final_results
    
    def _get_restart_reason(self, results: Dict[str, Any]) -> str:
        """
        üîç –û–ø—Ä–µ–¥–µ–ª—è–µ—Ç –ø—Ä–∏—á–∏–Ω—É –ø–µ—Ä–µ–∑–∞–ø—É—Å–∫–∞ –æ–±—É—á–µ–Ω–∏—è –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        
        Args:
            results: –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ–±—É—á–µ–Ω–∏—è
            
        Returns:
            –ß–µ–ª–æ–≤–µ–∫–æ–ø–æ–Ω—è—Ç–Ω–∞—è –ø—Ä–∏—á–∏–Ω–∞ –ø–µ—Ä–µ–∑–∞–ø—É—Å–∫–∞
        """
        if not results:
            return "–ü—É—Å—Ç—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ–±—É—á–µ–Ω–∏—è"
            
        reasons = []
        
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –º–µ—Ç—Ä–∏–∫–∏
        val_loss = results.get('validation_loss', float('inf'))
        attention_score = results.get('attention_alignment_score', 0.0)
        gate_accuracy = results.get('gate_accuracy', 0.0)
        mel_quality = results.get('mel_quality_score', 0.0)
        training_loss = results.get('training_loss', float('inf'))
        
        # –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ –ø—Ä–æ–±–ª–µ–º—ã
        if val_loss > 100.0:
            reasons.append(f"Validation loss –∫—Ä–∏—Ç–∏—á–Ω–æ –≤—ã—Å–æ–∫–∏–π ({val_loss:.2f})")
        if attention_score < 0.05:
            reasons.append(f"Attention –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏ –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç ({attention_score:.3f})")
        if gate_accuracy < 0.1:
            reasons.append(f"Gate accuracy –∫—Ä–∏—Ç–∏—á–Ω–æ –Ω–∏–∑–∫–∏–π ({gate_accuracy:.3f})")
        if mel_quality < 0.3:
            reasons.append(f"–ö–∞—á–µ—Å—Ç–≤–æ –º–µ–ª-—Å–ø–µ–∫—Ç—Ä–æ–≥—Ä–∞–º–º –Ω–∏–∑–∫–æ–µ ({mel_quality:.3f})")
        if training_loss == float('inf') or val_loss == float('inf'):
            reasons.append("NaN –∏–ª–∏ –±–µ—Å–∫–æ–Ω–µ—á–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –≤ loss")
        
        # –ü—Ä–æ–±–ª–µ–º—ã —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏
        validation_step = results.get('validation.step', 0)
        if validation_step < 3:
            reasons.append(f"–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ validation —à–∞–≥–æ–≤ ({validation_step})")
            
        # –ï—Å–ª–∏ –Ω–µ—Ç –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã—Ö –ø—Ä–∏—á–∏–Ω, –æ–±—â–∞—è —Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∫–∞
        if not reasons:
            reasons.append("–û–±—â–∞—è –æ—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ –Ω–∏–∂–µ –ø–æ—Ä–æ–≥–æ–≤—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π")
            
        return "; ".join(reasons)
    
    def _create_improvement_plan(self, results: Dict[str, Any], restart_number: int) -> Dict[str, Any]:
        """
        üõ†Ô∏è –°–æ–∑–¥–∞–µ—Ç –ø–ª–∞–Ω —É–ª—É—á—à–µ–Ω–∏–π –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø—Ä–æ–±–ª–µ–º –≤ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞—Ö
        
        Args:
            results: –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ–±—É—á–µ–Ω–∏—è
            restart_number: –ù–æ–º–µ—Ä –ø–µ—Ä–µ–∑–∞–ø—É—Å–∫–∞
            
        Returns:
            –ü–ª–∞–Ω —É–ª—É—á—à–µ–Ω–∏–π –¥–ª—è —Å–ª–µ–¥—É—é—â–µ–≥–æ –ø–µ—Ä–µ–∑–∞–ø—É—Å–∫–∞
        """
        plan = {
            'hyperparameter_changes': {},
            'strategy_changes': [],
            'expected_improvements': []
        }
        
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –ø—Ä–æ–±–ª–µ–º—ã –∏ –ø—Ä–µ–¥–ª–∞–≥–∞–µ–º —Ä–µ—à–µ–Ω–∏—è
        val_loss = results.get('validation_loss', float('inf'))
        attention_score = results.get('attention_alignment_score', 0.0)
        gate_accuracy = results.get('gate_accuracy', 0.0)
        mel_quality = results.get('mel_quality_score', 0.0)
        
        # –°—Ç—Ä–∞—Ç–µ–≥–∏–∏ —É–ª—É—á—à–µ–Ω–∏—è –Ω–∞ –æ—Å–Ω–æ–≤–µ –Ω–æ–º–µ—Ä–∞ –ø–µ—Ä–µ–∑–∞–ø—É—Å–∫–∞
        if restart_number == 0:  # –ü–µ—Ä–≤—ã–π –ø–µ—Ä–µ–∑–∞–ø—É—Å–∫ - –∫–æ–Ω—Å–µ—Ä–≤–∞—Ç–∏–≤–Ω—ã–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è
            if val_loss > 100.0:
                plan['hyperparameter_changes']['learning_rate'] = "—Å–Ω–∏–∂–µ–Ω –Ω–∞ 50%"
                plan['hyperparameter_changes']['batch_size'] = "—É–≤–µ–ª–∏—á–µ–Ω –¥–ª—è —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏"
                plan['expected_improvements'].append("–°—Ç–∞–±–∏–ª–∏–∑–∞—Ü–∏—è training loss")
                
            if attention_score < 0.05:
                plan['hyperparameter_changes']['guided_attention_weight'] = "—É–≤–µ–ª–∏—á–µ–Ω –≤ 2 —Ä–∞–∑–∞"
                plan['strategy_changes'].append("–£—Å–∏–ª–µ–Ω–∏–µ guided attention")
                plan['expected_improvements'].append("–£–ª—É—á—à–µ–Ω–∏–µ attention alignment")
                
        elif restart_number == 1:  # –í—Ç–æ—Ä–æ–π –ø–µ—Ä–µ–∑–∞–ø—É—Å–∫ - –±–æ–ª–µ–µ –∞–≥—Ä–µ—Å—Å–∏–≤–Ω—ã–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è
            plan['strategy_changes'].append("–ó–∞–ø—É—Å–∫ –º–∏–Ω–∏-–æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ (8 trials)")
            plan['hyperparameter_changes']['epochs'] = "—É–≤–µ–ª–∏—á–µ–Ω–æ –¥–ª—è –ª—É—á—à–µ–π —Å—Ö–æ–¥–∏–º–æ—Å—Ç–∏"
            plan['expected_improvements'].append("–ü–æ–¥–±–æ—Ä –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã—Ö –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤")
            
            if gate_accuracy < 0.1:
                plan['hyperparameter_changes']['gate_threshold'] = "–∞–¥–∞–ø—Ç–∏–≤–Ω–æ –Ω–∞—Å—Ç—Ä–æ–µ–Ω"
                plan['expected_improvements'].append("–£–ª—É—á—à–µ–Ω–∏–µ gate –∫–∞—á–µ—Å—Ç–≤–∞")
                
        else:  # –ü–æ—Å–ª–µ–¥—É—é—â–∏–µ –ø–µ—Ä–µ–∑–∞–ø—É—Å–∫–∏ - —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞–ª—å–Ω—ã–µ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏
            plan['strategy_changes'].append("–ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –ø—Ä–æ–¥–≤–∏–Ω—É—Ç—ã—Ö TTS —Ç–µ—Ö–Ω–∏–∫")
            plan['strategy_changes'].append("–§–∞–∑–æ–≤–æ–µ –æ–±—É—á–µ–Ω–∏–µ —Å –∞–¥–∞–ø—Ç–∏–≤–Ω—ã–º–∏ –ø–æ—Ä–æ–≥–∞–º–∏")
            plan['expected_improvements'].append("–ö–∞—Ä–¥–∏–Ω–∞–ª—å–Ω–æ–µ —É–ª—É—á—à–µ–Ω–∏–µ –∫–∞—á–µ—Å—Ç–≤–∞")
            
        # –û–±—â–∏–µ —É–ª—É—á—à–µ–Ω–∏—è
        if mel_quality < 0.3:
            plan['strategy_changes'].append("–£–ª—É—á—à–µ–Ω–∏–µ mel-—Å–ø–µ–∫—Ç—Ä–æ–≥—Ä–∞–º–º preprocessing")
            plan['expected_improvements'].append("–ü–æ–≤—ã—à–µ–Ω–∏–µ –∫–∞—á–µ—Å—Ç–≤–∞ –º–µ–ª-—Å–ø–µ–∫—Ç—Ä–æ–≥—Ä–∞–º–º")
            
        # –î–æ–±–∞–≤–ª—è–µ–º –º–∏–Ω–∏-–æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—é –¥–ª—è –ø–æ–∏—Å–∫–∞ –ª—É—á—à–∏—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
        if restart_number > 0:
            plan['strategy_changes'].append("–ú–∏–Ω–∏-–æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –¥–ª—è —Ç–æ—á–Ω–æ–π –Ω–∞—Å—Ç—Ä–æ–π–∫–∏")
            
        return plan

def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –∑–∞–ø—É—Å–∫–∞ Smart Tuner V2 TTS"""
    parser = argparse.ArgumentParser(description='Smart Tuner V2 - TTS –ê–≤—Ç–æ–º–∞—Ç–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞ –æ–±—É—á–µ–Ω–∏—è')
    parser.add_argument('--config', '-c', 
                       default='smart_tuner/config.yaml',
                       help='–ü—É—Ç—å –∫ —Ñ–∞–π–ª—É –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏')
    parser.add_argument('--mode', '-m',
                       choices=['optimize', 'train', 'monitor', 'auto'],
                       default='train',
                       help='–†–µ–∂–∏–º —Ä–∞–±–æ—Ç—ã: optimize - –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤, train - –æ–±—É—á–µ–Ω–∏–µ, monitor - –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥, auto - –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π —Ä–µ–∂–∏–º')
    parser.add_argument('--trials', '-t',
                       type=int,
                       help='–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ trials –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ (–ø–µ—Ä–µ–∫—Ä—ã–≤–∞–µ—Ç –Ω–∞—Å—Ç—Ä–æ–π–∫—É –≤ –∫–æ–Ω—Ñ–∏–≥–µ)')
    parser.add_argument('--epochs', type=int, default=None,
                       help='–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —ç–ø–æ—Ö (–µ—Å–ª–∏ –Ω–µ —É–∫–∞–∑–∞–Ω–æ, –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω–∞—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è)')
    parser.add_argument('--batch_size', type=int, default=None,
                       help='–†–∞–∑–º–µ—Ä batch')
    parser.add_argument('--learning_rate', type=float, default=None,
                       help='–°–∫–æ—Ä–æ—Å—Ç—å –æ–±—É—á–µ–Ω–∏—è')
    parser.add_argument('--dataset_path', type=str, default='training_data',
                       help='–ü—É—Ç—å –∫ –¥–∞—Ç–∞—Å–µ—Ç—É')
    parser.add_argument('--output_directory', type=str, default='output',
                       help='–î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤')
    
    args = parser.parse_args()
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
    if not os.path.exists(args.config):
        print(f"‚ùå –§–∞–π–ª –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ {args.config} –Ω–µ –Ω–∞–π–¥–µ–Ω")
        return 1
    
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º Smart Tuner
    smart_tuner = None
    
    try:
        print("üöÄ –ó–∞–ø—É—Å–∫ Smart Tuner V2 TTS...")
        smart_tuner = SmartTunerMain(args.config)
        smart_tuner.initialize_components()
        
        # –û–±–Ω–æ–≤–ª—è–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é –∏–∑ –∞—Ä–≥—É–º–µ–Ω—Ç–æ–≤
        if args.trials:
            smart_tuner.config.setdefault('optimization', {})['n_trials'] = args.trials
        
        # –í—ã–ø–æ–ª–Ω—è–µ–º –¥–µ–π—Å—Ç–≤–∏–µ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Ä–µ–∂–∏–º–∞
        if args.mode == 'optimize':
            print("üéØ –†–µ–∂–∏–º: TTS –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤")
            results = smart_tuner.run_optimization()
            print(f"üéâ –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞! –õ—É—á—à–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã: {results.get('best_parameters', {})}")
            
        elif args.mode == 'train':
            print("üöÇ –†–µ–∂–∏–º: TTS –û–±—É—á–µ–Ω–∏–µ")
            hyperparams = None
            if args.epochs is None:
                dataset_analysis = analyze_dataset(args.dataset_path)
                recommended_epochs = dataset_analysis.get('optimal_epochs', 1000)
                print(f"üéØ –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ä–µ–∫–æ–º–µ–Ω–¥–æ–≤–∞–Ω–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —ç–ø–æ—Ö: {recommended_epochs}")
            else:
                recommended_epochs = args.epochs
                print(f"üéØ –ò—Å–ø–æ–ª—å–∑—É–µ–º –∑–∞–¥–∞–Ω–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —ç–ø–æ—Ö: {recommended_epochs}")
            
            results = smart_tuner.run_single_training(hyperparams)
            print(f"üéâ TTS –û–±—É—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ! –§–∏–Ω–∞–ª—å–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏: {results}")
            
        elif args.mode == 'monitor':
            print("üëÅÔ∏è –†–µ–∂–∏–º: TTS –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥")
            smart_tuner.run_monitoring_mode()
            
        elif args.mode == 'auto':
            print("ü§ñ –†–µ–∂–∏–º: TTS –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π —Ä–µ–∂–∏–º")
            n_trials = args.trials or 15  # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø–µ—Ä–µ–¥–∞–Ω–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –∏–ª–∏ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 15
            results = smart_tuner.run_automatic_mode(n_trials)
            print(f"üéâ –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π —Ä–µ–∂–∏–º –∑–∞–≤–µ—Ä—à–µ–Ω! –†–µ–∑—É–ª—å—Ç–∞—Ç—ã: {results}")
            
        return 0
        
    except KeyboardInterrupt:
        print("\nüõë –û—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º")
        return 0
        
    except Exception as e:
        print(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {e}")
        return 1
        
    finally:
        if smart_tuner:
            smart_tuner.cleanup()

def analyze_dataset(dataset_path: str) -> dict:
    """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –¥–∞—Ç–∞—Å–µ—Ç –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –µ–≥–æ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫."""
    import os
    import librosa
    import numpy as np
    from pathlib import Path
    
    try:
        # –ü–æ–∏—Å–∫ –∞—É–¥–∏–æ—Ñ–∞–π–ª–æ–≤
        audio_files = []
        for ext in ['.wav', '.mp3', '.flac']:
            audio_files.extend(Path(dataset_path).glob(f'**/*{ext}'))
        
        if not audio_files:
            # –ï—Å–ª–∏ –∞—É–¥–∏–æ—Ñ–∞–π–ª—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã, –∏—Å–ø–æ–ª—å–∑—É–µ–º –∑–Ω–∞—á–µ–Ω–∏—è –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
            return {
                'total_duration_hours': 1.0,
                'num_samples': 1000,
                'quality_metrics': {
                    'background_noise_level': 0.3,
                    'voice_consistency': 0.8,
                    'speech_clarity': 0.7
                },
                'voice_features': {
                    'has_accent': False,
                    'emotional_range': 'neutral',
                    'speaking_style': 'normal',
                    'pitch_range_semitones': 12
                }
            }
        
        # –ê–Ω–∞–ª–∏–∑ —Å–ª—É—á–∞–π–Ω–æ–π –≤—ã–±–æ—Ä–∫–∏ —Ñ–∞–π–ª–æ–≤ (–º–∞–∫—Å–∏–º—É–º 50 –¥–ª—è —Å–∫–æ—Ä–æ—Å—Ç–∏)
        sample_files = np.random.choice(audio_files, min(50, len(audio_files)), replace=False)
        
        total_duration = 0
        pitch_values = []
        noise_levels = []
        
        for audio_file in sample_files:
            try:
                y, sr = librosa.load(str(audio_file), duration=30)  # –ú–∞–∫—Å–∏–º—É–º 30 —Å–µ–∫—É–Ω–¥ –Ω–∞ —Ñ–∞–π–ª
                duration = len(y) / sr
                total_duration += duration
                
                # –ê–Ω–∞–ª–∏–∑ pitch
                pitches, magnitudes = librosa.core.piptrack(y=y, sr=sr)
                pitch_values.extend(pitches[pitches > 0])
                
                # –û—Ü–µ–Ω–∫–∞ —É—Ä–æ–≤–Ω—è —à—É–º–∞ (—ç–Ω–µ—Ä–≥–∏—è –≤ —Ç–∏—Ö–∏—Ö —É—á–∞—Å—Ç–∫–∞—Ö)
                rms = librosa.feature.rms(y=y)[0]
                noise_level = np.percentile(rms, 10)  # 10-–π –ø—Ä–æ—Ü–µ–Ω—Ç–∏–ª—å –∫–∞–∫ –æ—Ü–µ–Ω–∫–∞ —à—É–º–∞
                noise_levels.append(noise_level)
                
            except Exception as e:
                print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ —Ñ–∞–π–ª–∞ {audio_file}: {e}")
                continue
        
        # –≠–∫—Å—Ç—Ä–∞–ø–æ–ª—è—Ü–∏—è –Ω–∞ –≤–µ—Å—å –¥–∞—Ç–∞—Å–µ—Ç
        total_duration_hours = (total_duration / len(sample_files)) * len(audio_files) / 3600
        
        # –ê–Ω–∞–ª–∏–∑ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫
        avg_noise = np.mean(noise_levels) if noise_levels else 0.3
        pitch_range = np.ptp(pitch_values) if len(pitch_values) > 0 else 12
        
        # –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è pitch range –≤ –ø–æ–ª—É—Ç–æ–Ω—ã (–ø—Ä–∏–±–ª–∏–∑–∏—Ç–µ–ª—å–Ω–æ)
        pitch_range_semitones = min(24, max(6, pitch_range / 10))
        
        # –í—ã—á–∏—Å–ª—è–µ–º –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —ç–ø–æ—Ö –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ä–∞–∑–º–µ—Ä–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞
        base_epochs = 1000
        if total_duration_hours < 0.5:
            optimal_epochs = 2000  # –ú–∞–ª–µ–Ω—å–∫–∏–π –¥–∞—Ç–∞—Å–µ—Ç - –±–æ–ª—å—à–µ —ç–ø–æ—Ö
        elif total_duration_hours < 2:
            optimal_epochs = 1500  # –°—Ä–µ–¥–Ω–∏–π –¥–∞—Ç–∞—Å–µ—Ç
        elif total_duration_hours < 10:
            optimal_epochs = 1000  # –ë–æ–ª—å—à–æ–π –¥–∞—Ç–∞—Å–µ—Ç
        else:
            optimal_epochs = 800   # –û—á–µ–Ω—å –±–æ–ª—å—à–æ–π –¥–∞—Ç–∞—Å–µ—Ç - –º–µ–Ω—å—à–µ —ç–ø–æ—Ö
        
        return {
            'total_duration_hours': total_duration_hours,
            'num_samples': len(audio_files),
            'optimal_epochs': optimal_epochs,
            'recommended_epochs_range': [max(500, optimal_epochs // 2), optimal_epochs * 2],
            'confidence': 0.8,  # –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –≤ –æ—Ü–µ–Ω–∫–µ
            'quality_metrics': {
                'background_noise_level': min(1.0, avg_noise * 2),  # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è
                'voice_consistency': 0.8,  # –ü–æ–∫–∞ —Å—Ç–∞—Ç–∏—á–µ—Å–∫–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ
                'speech_clarity': max(0.3, 1.0 - avg_noise)  # –û–±—Ä–∞—Ç–Ω–∞—è –∫–æ—Ä—Ä–µ–ª—è—Ü–∏—è —Å —à—É–º–æ–º
            },
            'voice_features': {
                'has_accent': False,  # –¢—Ä–µ–±—É–µ—Ç –±–æ–ª–µ–µ —Å–ª–æ–∂–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞
                'emotional_range': 'neutral',  # –¢—Ä–µ–±—É–µ—Ç –∞–Ω–∞–ª–∏–∑–∞ —ç–º–æ—Ü–∏–π
                'speaking_style': 'normal',  # –¢—Ä–µ–±—É–µ—Ç –∞–Ω–∞–ª–∏–∑–∞ —Ç–µ–º–ø–∞
                'pitch_range_semitones': pitch_range_semitones
            }
        }
        
    except Exception as e:
        print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞: {e}")
        # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –∑–Ω–∞—á–µ–Ω–∏—è –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
        return {
            'total_duration_hours': 1.0,
            'num_samples': 1000,
            'optimal_epochs': 1000,
            'recommended_epochs_range': [500, 2000],
            'confidence': 0.5,  # –ù–∏–∑–∫–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –ø—Ä–∏ –æ—à–∏–±–∫–µ
            'quality_metrics': {
                'background_noise_level': 0.3,
                'voice_consistency': 0.8,
                'speech_clarity': 0.7
            },
            'voice_features': {
                'has_accent': False,
                'emotional_range': 'neutral',
                'speaking_style': 'normal',
                'pitch_range_semitones': 12
            }
        }

if __name__ == "__main__":
    sys.exit(main())

 