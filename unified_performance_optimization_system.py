#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
üöÄ UNIFIED PERFORMANCE OPTIMIZATION SYSTEM
–ï–¥–∏–Ω–∞—è –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏

–û–±—ä–µ–¥–∏–Ω—è–µ—Ç –∏ –∫–æ–æ—Ä–¥–∏–Ω–∏—Ä—É–µ—Ç –≤—Å–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã:
‚úÖ System Performance Monitoring (CPU, GPU, Memory)
‚úÖ Training Performance Optimization (Batch Size, LR, Gradients)
‚úÖ Model Performance Tuning (Architecture, Attention, Loss)
‚úÖ Hardware Adaptation (GPU utilization, Memory efficiency)
‚úÖ Real-time Bottleneck Detection & Resolution
‚úÖ Automated Parameter Tuning

–ó–∞–º–µ–Ω—è–µ—Ç:
‚ùå –†–∞–∑—Ä–æ–∑–Ω–µ–Ω–Ω—ã–µ —Å–∏—Å—Ç–µ–º—ã –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏
‚ùå –û—Ç—Å—É—Ç—Å—Ç–≤–∏–µ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ü–∏–∏ –º–µ–∂–¥—É –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞–º–∏
‚ùå –†—É—á–Ω–∞—è –Ω–∞—Å—Ç—Ä–æ–π–∫–∞ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
"""

import os
import time
import torch
import torch.nn as nn
import psutil
import threading
import logging
from datetime import datetime
from typing import Dict, List, Optional, Tuple, Any, Union
from dataclasses import dataclass, asdict
from enum import Enum
from collections import deque
import numpy as np
import json
from pathlib import Path

# –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–º–∏ —Å–∏—Å—Ç–µ–º–∞–º–∏
try:
    from production_monitoring import ProductionMonitor, MetricsCollector
    PRODUCTION_MONITORING_AVAILABLE = True
except ImportError:
    PRODUCTION_MONITORING_AVAILABLE = False

try:
    from enhanced_mlflow_logger import EnhancedMLflowLogger
    MLFLOW_LOGGER_AVAILABLE = True
except ImportError:
    MLFLOW_LOGGER_AVAILABLE = False

try:
    from context_aware_training_manager import ContextAwareTrainingManager
    CONTEXT_AWARE_AVAILABLE = True
except ImportError:
    CONTEXT_AWARE_AVAILABLE = False

try:
    from training_stabilization_system import TrainingStabilizationSystem
    STABILIZATION_AVAILABLE = True
except ImportError:
    STABILIZATION_AVAILABLE = False

try:
    from unified_logging_system import UnifiedLoggingSystem
    UNIFIED_LOGGING_AVAILABLE = True
except ImportError:
    UNIFIED_LOGGING_AVAILABLE = False

# GPU –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥
try:
    import pynvml
    pynvml.nvmlInit()
    GPU_MONITORING_AVAILABLE = True
except ImportError:
    GPU_MONITORING_AVAILABLE = False


class OptimizationPriority(Enum):
    """–ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç—ã –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏"""
    CRITICAL = "critical"      # –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ bottleneck'–∏
    HIGH = "high"             # –í–∞–∂–Ω—ã–µ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏
    MEDIUM = "medium"         # –£–º–µ—Ä–µ–Ω–Ω—ã–µ —É–ª—É—á—à–µ–Ω–∏—è
    LOW = "low"              # –ú–∏–Ω–æ—Ä–Ω—ã–µ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏


class PerformanceMetricType(Enum):
    """–¢–∏–ø—ã –º–µ—Ç—Ä–∏–∫ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏"""
    SYSTEM = "system"         # –°–∏—Å—Ç–µ–º–Ω—ã–µ —Ä–µ—Å—É—Ä—Å—ã
    TRAINING = "training"     # –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏
    THROUGHPUT = "throughput" # –ü—Ä–æ–ø—É—Å–∫–Ω–∞—è —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç—å
    EFFICIENCY = "efficiency" # –≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å
    LATENCY = "latency"      # –ó–∞–¥–µ—Ä–∂–∫–∏


@dataclass
class PerformanceMetrics:
    """–ö–æ–º–ø–ª–µ–∫—Å–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏"""
    timestamp: float
    
    # –°–∏—Å—Ç–µ–º–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏
    cpu_usage: float = 0.0
    memory_usage: float = 0.0
    memory_available_gb: float = 0.0
    
    # GPU –º–µ—Ç—Ä–∏–∫–∏
    gpu_usage: float = 0.0
    gpu_memory_usage: float = 0.0
    gpu_temperature: float = 0.0
    gpu_power_usage: float = 0.0
    
    # –û–±—É—á–µ–Ω–∏–µ
    loss: float = 0.0
    learning_rate: float = 0.0
    gradient_norm: float = 0.0
    attention_quality: float = 0.0
    batch_processing_time: float = 0.0
    
    # –ü—Ä–æ–ø—É—Å–∫–Ω–∞—è —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç—å
    samples_per_second: float = 0.0
    batches_per_second: float = 0.0
    steps_per_minute: float = 0.0
    
    # –≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å
    gpu_utilization_efficiency: float = 0.0
    memory_efficiency: float = 0.0
    compute_efficiency: float = 0.0
    
    # –î–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞
    bottleneck_detected: bool = False
    bottleneck_type: Optional[str] = None
    optimization_opportunities: List[str] = None
    
    def __post_init__(self):
        if self.optimization_opportunities is None:
            self.optimization_opportunities = []


@dataclass
class OptimizationRecommendation:
    """–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è –ø–æ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏"""
    priority: OptimizationPriority
    metric_type: PerformanceMetricType
    description: str
    suggested_action: str
    expected_improvement: float  # –û–∂–∏–¥–∞–µ–º–æ–µ —É–ª—É—á—à–µ–Ω–∏–µ –≤ %
    estimated_risk: float       # –û—Ü–µ–Ω–∫–∞ —Ä–∏—Å–∫–∞ (0.0-1.0)
    parameters_to_change: Dict[str, Any]
    confidence: float          # –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –≤ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ (0.0-1.0)


class SystemProfiler:
    """üîç –°–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ—Ñ–∏–ª–∏—Ä–æ–≤—â–∏–∫ - –¥–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏"""
    
    def __init__(self):
        self.profiling_history = deque(maxlen=1000)
        self.bottleneck_history = deque(maxlen=100)
        self.optimization_history = []
        
        # GPU handles
        self.gpu_handles = []
        if GPU_MONITORING_AVAILABLE:
            try:
                device_count = pynvml.nvmlDeviceGetCount()
                self.gpu_handles = [pynvml.nvmlDeviceGetHandleByIndex(i) 
                                  for i in range(device_count)]
            except Exception:
                pass
        
        self.logger = logging.getLogger(__name__)
    
    def profile_system_performance(self) -> PerformanceMetrics:
        """–ö–æ–º–ø–ª–µ–∫—Å–Ω–æ–µ –ø—Ä–æ—Ñ–∏–ª–∏—Ä–æ–≤–∞–Ω–∏–µ —Å–∏—Å—Ç–µ–º—ã"""
        timestamp = time.time()
        
        # –°–∏—Å—Ç–µ–º–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏
        cpu_usage = psutil.cpu_percent(interval=0.1)
        memory = psutil.virtual_memory()
        
        metrics = PerformanceMetrics(
            timestamp=timestamp,
            cpu_usage=cpu_usage,
            memory_usage=memory.percent,
            memory_available_gb=memory.available / (1024**3)
        )
        
        # GPU –º–µ—Ç—Ä–∏–∫–∏
        if self.gpu_handles:
            try:
                handle = self.gpu_handles[0]  # –û—Å–Ω–æ–≤–Ω–∞—è GPU
                
                # –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ GPU
                util = pynvml.nvmlDeviceGetUtilizationRates(handle)
                metrics.gpu_usage = util.gpu
                
                # –ü–∞–º—è—Ç—å GPU
                mem_info = pynvml.nvmlDeviceGetMemoryInfo(handle)
                metrics.gpu_memory_usage = (mem_info.used / mem_info.total) * 100
                
                # –¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞
                try:
                    metrics.gpu_temperature = pynvml.nvmlDeviceGetTemperature(
                        handle, pynvml.NVML_TEMPERATURE_GPU
                    )
                except:
                    pass
                
                # –ü–æ—Ç—Ä–µ–±–ª–µ–Ω–∏–µ —ç–Ω–µ—Ä–≥–∏–∏
                try:
                    power = pynvml.nvmlDeviceGetPowerUsage(handle) / 1000.0
                    metrics.gpu_power_usage = power
                except:
                    pass
                    
            except Exception as e:
                self.logger.warning(f"–û—à–∏–±–∫–∞ —Å–±–æ—Ä–∞ GPU –º–µ—Ç—Ä–∏–∫: {e}")
        
        # –í—ã—á–∏—Å–ª–µ–Ω–∏–µ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏
        self._calculate_efficiency_metrics(metrics)
        
        # –û–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ bottleneck'–æ–≤
        self._detect_bottlenecks(metrics)
        
        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ –∏—Å—Ç–æ—Ä–∏—é
        self.profiling_history.append(metrics)
        
        return metrics
    
    def _calculate_efficiency_metrics(self, metrics: PerformanceMetrics):
        """–í—ã—á–∏—Å–ª–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏"""
        # GPU utilization efficiency
        if metrics.gpu_usage > 0:
            # –ò–¥–µ–∞–ª—å–Ω–∞—è GPU utilization 80-95%
            target_gpu_usage = 85.0
            efficiency = 1.0 - abs(metrics.gpu_usage - target_gpu_usage) / target_gpu_usage
            metrics.gpu_utilization_efficiency = max(0.0, efficiency) * 100
        
        # Memory efficiency
        if metrics.memory_usage > 0:
            # –ò–¥–µ–∞–ª—å–Ω–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –ø–∞–º—è—Ç–∏ 60-80%
            if 60 <= metrics.memory_usage <= 80:
                metrics.memory_efficiency = 100.0
            else:
                target = 70.0
                efficiency = 1.0 - abs(metrics.memory_usage - target) / target
                metrics.memory_efficiency = max(0.0, efficiency) * 100
        
        # Compute efficiency (–∫–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –º–µ—Ç—Ä–∏–∫–∞)
        metrics.compute_efficiency = (
            metrics.gpu_utilization_efficiency * 0.6 +
            metrics.memory_efficiency * 0.4
        )
    
    def _detect_bottlenecks(self, metrics: PerformanceMetrics):
        """–û–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ bottleneck'–æ–≤"""
        bottlenecks = []
        
        # CPU bottleneck
        if metrics.cpu_usage > 90:
            bottlenecks.append("cpu_overload")
            
        # Memory bottleneck
        if metrics.memory_usage > 95:
            bottlenecks.append("memory_exhaustion")
        elif metrics.memory_usage < 20:
            bottlenecks.append("memory_underutilization")
            
        # GPU bottlenecks
        if metrics.gpu_usage > 0:
            if metrics.gpu_usage < 30:
                bottlenecks.append("gpu_underutilization")
            elif metrics.gpu_usage > 98:
                bottlenecks.append("gpu_saturation")
                
            if metrics.gpu_memory_usage > 95:
                bottlenecks.append("gpu_memory_exhaustion")
            elif metrics.gpu_memory_usage < 20:
                bottlenecks.append("gpu_memory_underutilization")
                
            if metrics.gpu_temperature > 80:
                bottlenecks.append("gpu_thermal_throttling")
        
        if bottlenecks:
            metrics.bottleneck_detected = True
            metrics.bottleneck_type = "; ".join(bottlenecks)
            self.bottleneck_history.append({
                'timestamp': metrics.timestamp,
                'bottlenecks': bottlenecks
            })


class PerformanceOptimizer:
    """‚ö° –ò–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω—ã–π –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏"""
    
    def __init__(self, target_performance_goals: Dict[str, float] = None):
        self.target_goals = target_performance_goals or {
            'gpu_utilization': 85.0,
            'memory_efficiency': 75.0,
            'samples_per_second': 100.0,
            'gradient_stability': 0.8
        }
        
        # –ê–¥–∞–ø—Ç–∏–≤–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
        self.optimization_strategies = {
            'batch_size': {'min': 4, 'max': 64, 'current': 16},
            'learning_rate': {'min': 1e-6, 'max': 1e-2, 'current': 1e-3},
            'gradient_accumulation': {'min': 1, 'max': 8, 'current': 1},
            'attention_chunk_size': {'min': 32, 'max': 512, 'current': None}
        }
        
        self.optimization_history = []
        self.performance_trend = deque(maxlen=50)
        
        self.logger = logging.getLogger(__name__)
    
    def generate_optimization_recommendations(self, 
                                            metrics: PerformanceMetrics,
                                            training_context: Dict = None) -> List[OptimizationRecommendation]:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π –ø–æ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏"""
        recommendations = []
        
        # –ê–Ω–∞–ª–∏–∑ GPU utilization
        if metrics.gpu_usage < 50:
            recommendations.append(OptimizationRecommendation(
                priority=OptimizationPriority.HIGH,
                metric_type=PerformanceMetricType.EFFICIENCY,
                description="–ù–∏–∑–∫–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ GPU - –º–æ–∂–Ω–æ —É–≤–µ–ª–∏—á–∏—Ç—å batch size",
                suggested_action="–£–≤–µ–ª–∏—á–∏—Ç—å batch_size –≤ 1.5-2x —Ä–∞–∑–∞",
                expected_improvement=25.0,
                estimated_risk=0.2,
                parameters_to_change={'batch_size': self._suggest_batch_size_increase()},
                confidence=0.8
            ))
        
        # –ê–Ω–∞–ª–∏–∑ –ø–∞–º—è—Ç–∏ GPU
        if metrics.gpu_memory_usage < 60:
            recommendations.append(OptimizationRecommendation(
                priority=OptimizationPriority.MEDIUM,
                metric_type=PerformanceMetricType.EFFICIENCY,
                description="–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ GPU –ø–∞–º—è—Ç–∏",
                suggested_action="–£–≤–µ–ª–∏—á–∏—Ç—å —Ä–∞–∑–º–µ—Ä –º–æ–¥–µ–ª–∏ –∏–ª–∏ batch size",
                expected_improvement=15.0,
                estimated_risk=0.3,
                parameters_to_change={'mixed_precision': True, 'larger_model': True},
                confidence=0.7
            ))
        
        # –ê–Ω–∞–ª–∏–∑ —Å–∏—Å—Ç–µ–º–Ω–æ–π –ø–∞–º—è—Ç–∏
        if metrics.memory_usage > 90:
            recommendations.append(OptimizationRecommendation(
                priority=OptimizationPriority.CRITICAL,
                metric_type=PerformanceMetricType.SYSTEM,
                description="–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏ –≤—ã—Å–æ–∫–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ RAM",
                suggested_action="–£–º–µ–Ω—å—à–∏—Ç—å batch size –∏–ª–∏ –≤–∫–ª—é—á–∏—Ç—å gradient accumulation",
                expected_improvement=30.0,
                estimated_risk=0.1,
                parameters_to_change={'batch_size': self._suggest_batch_size_decrease(),
                                    'gradient_accumulation_steps': 2},
                confidence=0.9
            ))
        
        # –ê–Ω–∞–ª–∏–∑ –æ–±—É—á–µ–Ω–∏—è
        if training_context:
            loss = training_context.get('loss', 0)
            gradient_norm = training_context.get('gradient_norm', 0)
            
            if gradient_norm > 10.0:
                recommendations.append(OptimizationRecommendation(
                    priority=OptimizationPriority.HIGH,
                    metric_type=PerformanceMetricType.TRAINING,
                    description="–í—ã—Å–æ–∫–∞—è –Ω–æ—Ä–º–∞ –≥—Ä–∞–¥–∏–µ–Ω—Ç–æ–≤ - —Ä–∏—Å–∫ –Ω–µ—Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏",
                    suggested_action="–£–º–µ–Ω—å—à–∏—Ç—å learning rate –∏–ª–∏ —É—Å–∏–ª–∏—Ç—å gradient clipping",
                    expected_improvement=20.0,
                    estimated_risk=0.2,
                    parameters_to_change={'learning_rate': training_context.get('learning_rate', 1e-3) * 0.7,
                                        'gradient_clip_thresh': min(gradient_norm * 0.5, 5.0)},
                    confidence=0.8
                ))
        
        # –°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ –ø–æ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç—É
        priority_order = {
            OptimizationPriority.CRITICAL: 0,
            OptimizationPriority.HIGH: 1,
            OptimizationPriority.MEDIUM: 2,
            OptimizationPriority.LOW: 3
        }
        recommendations.sort(key=lambda x: priority_order[x.priority])
        
        return recommendations
    
    def _suggest_batch_size_increase(self) -> int:
        """–ü—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ —É–≤–µ–ª–∏—á–µ–Ω–∏—è batch size"""
        current = self.optimization_strategies['batch_size']['current']
        max_batch = self.optimization_strategies['batch_size']['max']
        return min(int(current * 1.5), max_batch)
    
    def _suggest_batch_size_decrease(self) -> int:
        """–ü—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ —É–º–µ–Ω—å—à–µ–Ω–∏—è batch size"""
        current = self.optimization_strategies['batch_size']['current']
        min_batch = self.optimization_strategies['batch_size']['min']
        return max(int(current * 0.7), min_batch)


class AdaptiveParameterController:
    """üéõÔ∏è –ö–æ–Ω—Ç—Ä–æ–ª–ª–µ—Ä –∞–¥–∞–ø—Ç–∏–≤–Ω—ã—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤"""
    
    def __init__(self, hparams):
        self.hparams = hparams
        self.parameter_history = {}
        self.performance_correlation = {}
        
        # –ë–µ–∑–æ–ø–∞—Å–Ω—ã–µ –¥–∏–∞–ø–∞–∑–æ–Ω—ã –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
        self.safe_ranges = {
            'learning_rate': (1e-6, 1e-2),
            'batch_size': (1, 128),
            'gradient_accumulation_steps': (1, 16),
            'attention_dropout': (0.0, 0.5),
            'decoder_dropout': (0.0, 0.5)
        }
        
        self.logger = logging.getLogger(__name__)
    
    def apply_optimization_recommendations(self, 
                                         recommendations: List[OptimizationRecommendation],
                                         max_changes: int = 3) -> Dict[str, Any]:
        """–ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π –ø–æ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏"""
        applied_changes = {}
        changes_count = 0
        
        for rec in recommendations:
            if changes_count >= max_changes:
                break
                
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏ –∏–∑–º–µ–Ω–µ–Ω–∏–π
            if self._is_safe_to_apply(rec):
                try:
                    # –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –∏–∑–º–µ–Ω–µ–Ω–∏–π –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
                    for param_name, new_value in rec.parameters_to_change.items():
                        if hasattr(self.hparams, param_name):
                            old_value = getattr(self.hparams, param_name)
                            
                            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–∏–∞–ø–∞–∑–æ–Ω–∞
                            if param_name in self.safe_ranges:
                                min_val, max_val = self.safe_ranges[param_name]
                                new_value = np.clip(new_value, min_val, max_val)
                            
                            # –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è
                            setattr(self.hparams, param_name, new_value)
                            applied_changes[param_name] = {
                                'old_value': old_value,
                                'new_value': new_value,
                                'recommendation': rec.description
                            }
                            
                            self.logger.info(f"üéõÔ∏è –ò–∑–º–µ–Ω–µ–Ω {param_name}: {old_value} ‚Üí {new_value}")
                            changes_count += 1
                            
                except Exception as e:
                    self.logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏: {e}")
        
        return applied_changes
    
    def _is_safe_to_apply(self, recommendation: OptimizationRecommendation) -> bool:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏"""
        # –ù–µ –ø—Ä–∏–º–µ–Ω—è–µ–º —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ —Å –≤—ã—Å–æ–∫–∏–º —Ä–∏—Å–∫–æ–º
        if recommendation.estimated_risk > 0.7:
            return False
            
        # –ù–µ –ø—Ä–∏–º–µ–Ω—è–µ–º —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ —Å –Ω–∏–∑–∫–æ–π —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å—é
        if recommendation.confidence < 0.5:
            return False
            
        return True


class UnifiedPerformanceOptimizationSystem:
    """üöÄ –ì–ª–∞–≤–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞ —É–Ω–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω–æ–π –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏"""
    
    def __init__(self, hparams, enable_auto_optimization: bool = True):
        # –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ - –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –ø–µ—Ä–≤—ã–º
        try:
            if UNIFIED_LOGGING_AVAILABLE:
                self.logger = UnifiedLoggingSystem().get_logger("PerformanceOptimizer")
            else:
                self.logger = logging.getLogger(__name__)
        except Exception:
            # Fallback –∫ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–º—É –ª–æ–≥–≥–µ—Ä—É
            self.logger = logging.getLogger(__name__)
            logging.basicConfig(level=logging.INFO)
        
        self.hparams = hparams
        self.enable_auto_optimization = enable_auto_optimization
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤
        self.profiler = SystemProfiler()
        self.optimizer = PerformanceOptimizer()
        self.parameter_controller = AdaptiveParameterController(hparams)
        
        # –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–º–∏ —Å–∏—Å—Ç–µ–º–∞–º–∏
        self.production_monitor = None
        self.mlflow_logger = None
        self.context_manager = None
        self.stabilization_system = None
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–π
        self._initialize_integrations()
        
        # –°–æ—Å—Ç–æ—è–Ω–∏–µ —Å–∏—Å—Ç–µ–º—ã
        self.optimization_active = False
        self.last_optimization = 0
        self.optimization_interval = 300  # 5 –º–∏–Ω—É—Ç –º–µ–∂–¥—É –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è–º–∏
        
        # –ò—Å—Ç–æ—Ä–∏—è –∏ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        self.optimization_results = []
        self.performance_improvements = []
        
        self.logger.info("üöÄ Unified Performance Optimization System –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞")
    
    def _initialize_integrations(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–π —Å —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–º–∏ —Å–∏—Å—Ç–µ–º–∞–º–∏"""
        if PRODUCTION_MONITORING_AVAILABLE:
            try:
                self.production_monitor = ProductionMonitor()
                self.logger.info("‚úÖ –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å Production Monitor")
            except Exception as e:
                self.logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –∏–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞—Ç—å Production Monitor: {e}")
        
        if MLFLOW_LOGGER_AVAILABLE:
            try:
                self.mlflow_logger = EnhancedMLflowLogger()
                self.logger.info("‚úÖ –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å MLflow Logger")
            except Exception as e:
                self.logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –∏–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞—Ç—å MLflow Logger: {e}")
    
    def optimize_performance_step(self, 
                                training_metrics: Dict = None,
                                force_optimization: bool = False) -> Dict[str, Any]:
        """–û–¥–∏–Ω —à–∞–≥ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏"""
        current_time = time.time()
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∏–Ω—Ç–µ—Ä–≤–∞–ª–∞ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏
        if not force_optimization and (current_time - self.last_optimization) < self.optimization_interval:
            return {'status': 'skipped', 'reason': 'interval_not_reached'}
        
        # –ü—Ä–æ—Ñ–∏–ª–∏—Ä–æ–≤–∞–Ω–∏–µ —Å–∏—Å—Ç–µ–º—ã
        performance_metrics = self.profiler.profile_system_performance()
        
        # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫ –æ–±—É—á–µ–Ω–∏—è
        if training_metrics:
            performance_metrics.loss = training_metrics.get('loss', 0.0)
            performance_metrics.learning_rate = training_metrics.get('learning_rate', 0.0)
            performance_metrics.gradient_norm = training_metrics.get('gradient_norm', 0.0)
            performance_metrics.attention_quality = training_metrics.get('attention_quality', 0.0)
        
        # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π
        recommendations = self.optimizer.generate_optimization_recommendations(
            performance_metrics, training_metrics
        )
        
        optimization_result = {
            'timestamp': current_time,
            'performance_metrics': asdict(performance_metrics),
            'recommendations_count': len(recommendations),
            'applied_changes': {},
            'status': 'completed'
        }
        
        # –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ (–µ—Å–ª–∏ –≤–∫–ª—é—á–µ–Ω–æ)
        if self.enable_auto_optimization and recommendations:
            applied_changes = self.parameter_controller.apply_optimization_recommendations(
                recommendations, max_changes=2  # –ù–µ –±–æ–ª–µ–µ 2 –∏–∑–º–µ–Ω–µ–Ω–∏–π –∑–∞ —Ä–∞–∑
            )
            optimization_result['applied_changes'] = applied_changes
            
            if applied_changes:
                self.logger.info(f"üéØ –ü—Ä–∏–º–µ–Ω–µ–Ω–æ {len(applied_changes)} –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–π")
        
        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        self.optimization_results.append(optimization_result)
        self.last_optimization = current_time
        
        # –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –≤ MLflow
        if self.mlflow_logger:
            try:
                self.mlflow_logger.log_metrics({
                    'optimization/gpu_utilization_efficiency': performance_metrics.gpu_utilization_efficiency,
                    'optimization/memory_efficiency': performance_metrics.memory_efficiency,
                    'optimization/compute_efficiency': performance_metrics.compute_efficiency,
                    'optimization/recommendations_count': len(recommendations),
                    'optimization/changes_applied': len(optimization_result['applied_changes'])
                }, step=int(current_time))
            except Exception as e:
                self.logger.warning(f"–û—à–∏–±–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è –≤ MLflow: {e}")
        
        return optimization_result
    
    def get_performance_report(self) -> Dict[str, Any]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –æ—Ç—á–µ—Ç–∞ –æ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏"""
        if not self.profiler.profiling_history:
            return {'status': 'no_data', 'message': '–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –ø—Ä–æ—Ñ–∏–ª–∏—Ä–æ–≤–∞–Ω–∏—è'}
        
        # –ü–æ—Å–ª–µ–¥–Ω–∏–µ –º–µ—Ç—Ä–∏–∫–∏
        latest_metrics = self.profiler.profiling_history[-1]
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–π —á–∞—Å
        hour_ago = time.time() - 3600
        recent_metrics = [m for m in self.profiler.profiling_history 
                         if m.timestamp > hour_ago]
        
        if recent_metrics:
            avg_gpu_usage = np.mean([m.gpu_usage for m in recent_metrics])
            avg_memory_usage = np.mean([m.memory_usage for m in recent_metrics])
            avg_compute_efficiency = np.mean([m.compute_efficiency for m in recent_metrics])
        else:
            avg_gpu_usage = avg_memory_usage = avg_compute_efficiency = 0.0
        
        return {
            'current_performance': {
                'gpu_usage': latest_metrics.gpu_usage,
                'gpu_memory_usage': latest_metrics.gpu_memory_usage,
                'memory_usage': latest_metrics.memory_usage,
                'compute_efficiency': latest_metrics.compute_efficiency,
                'bottleneck_detected': latest_metrics.bottleneck_detected,
                'bottleneck_type': latest_metrics.bottleneck_type
            },
            'hourly_averages': {
                'avg_gpu_usage': avg_gpu_usage,
                'avg_memory_usage': avg_memory_usage,
                'avg_compute_efficiency': avg_compute_efficiency
            },
            'optimization_stats': {
                'total_optimizations': len(self.optimization_results),
                'recent_changes': len([r for r in self.optimization_results 
                                     if r['timestamp'] > hour_ago and r['applied_changes']]),
                'bottlenecks_detected': len(self.profiler.bottleneck_history)
            },
            'status': 'healthy' if latest_metrics.compute_efficiency > 60 else 'needs_attention'
        }
    
    def activate_emergency_optimization(self, critical_metrics: Dict) -> Dict[str, Any]:
        """–≠–∫—Å—Ç—Ä–µ–Ω–Ω–∞—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –ø—Ä–∏ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏—Ö –ø—Ä–æ–±–ª–µ–º–∞—Ö"""
        self.logger.warning("üö® –ê–∫—Ç–∏–≤–∞—Ü–∏—è —ç–∫—Å—Ç—Ä–µ–Ω–Ω–æ–π –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏")
        
        # –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–∞—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è
        result = self.optimize_performance_step(
            training_metrics=critical_metrics,
            force_optimization=True
        )
        
        # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ —ç–∫—Å—Ç—Ä–µ–Ω–Ω—ã–µ –º–µ—Ä—ã
        emergency_changes = {}
        
        # –ï—Å–ª–∏ GPU memory –ø–µ—Ä–µ–ø–æ–ª–Ω–µ–Ω–∞
        if critical_metrics.get('gpu_memory_usage', 0) > 95:
            emergency_changes['emergency_batch_size_reduction'] = True
            if hasattr(self.hparams, 'batch_size'):
                old_batch = self.hparams.batch_size
                self.hparams.batch_size = max(1, old_batch // 2)
                emergency_changes['batch_size'] = {
                    'old': old_batch, 
                    'new': self.hparams.batch_size
                }
        
        # –ï—Å–ª–∏ —Å–∏—Å—Ç–µ–º–∞ memory –ø–µ—Ä–µ–ø–æ–ª–Ω–µ–Ω–∞
        if critical_metrics.get('memory_usage', 0) > 95:
            emergency_changes['emergency_memory_cleanup'] = True
            # –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–∞—è –æ—á–∏—Å—Ç–∫–∞ –∫—ç—à–µ–π
            if torch.cuda.is_available():
                torch.cuda.empty_cache()
        
        result['emergency_changes'] = emergency_changes
        result['emergency_activation'] = True
        
        return result
    
    def enable_continuous_optimization(self):
        """–í–∫–ª—é—á–µ–Ω–∏–µ –Ω–µ–ø—Ä–µ—Ä—ã–≤–Ω–æ–π –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏"""
        self.optimization_active = True
        self.logger.info("üîÑ –í–∫–ª—é—á–µ–Ω–∞ –Ω–µ–ø—Ä–µ—Ä—ã–≤–Ω–∞—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏")
    
    def disable_continuous_optimization(self):
        """–û—Ç–∫–ª—é—á–µ–Ω–∏–µ –Ω–µ–ø—Ä–µ—Ä—ã–≤–Ω–æ–π –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏"""
        self.optimization_active = False
        self.logger.info("‚è∏Ô∏è –û—Ç–∫–ª—é—á–µ–Ω–∞ –Ω–µ–ø—Ä–µ—Ä—ã–≤–Ω–∞—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏")


def create_performance_optimization_system(hparams, 
                                         enable_auto_optimization: bool = True) -> UnifiedPerformanceOptimizationSystem:
    """
    –§–∞–±—Ä–∏–∫–∞ –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è —Å–∏—Å—Ç–µ–º—ã –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
    
    Args:
        hparams: –ì–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä—ã –º–æ–¥–µ–ª–∏
        enable_auto_optimization: –í–∫–ª—é—á–∏—Ç—å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫—É—é –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—é
        
    Returns:
        UnifiedPerformanceOptimizationSystem: –ù–∞—Å—Ç—Ä–æ–µ–Ω–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏
    """
    return UnifiedPerformanceOptimizationSystem(
        hparams=hparams,
        enable_auto_optimization=enable_auto_optimization
    )


if __name__ == "__main__":
    # –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
    from hparams import create_hparams
    
    hparams = create_hparams()
    
    # –°–æ–∑–¥–∞–Ω–∏–µ —Å–∏—Å—Ç–µ–º—ã –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏
    optimization_system = create_performance_optimization_system(
        hparams=hparams,
        enable_auto_optimization=True
    )
    
    # –ü—Ä–∏–º–µ—Ä –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏
    training_metrics = {
        'loss': 5.2,
        'learning_rate': 1e-3,
        'gradient_norm': 2.1,
        'attention_quality': 0.65
    }
    
    result = optimization_system.optimize_performance_step(training_metrics)
    print("üöÄ –†–µ–∑—É–ª—å—Ç–∞—Ç –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏:", result)
    
    # –û—Ç—á–µ—Ç –æ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
    report = optimization_system.get_performance_report()
    print("üìä –û—Ç—á–µ—Ç –æ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏:", report) 