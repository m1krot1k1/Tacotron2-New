# Smart Tuner V2 –¥–ª—è Tacotron2

–ò–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ —Ç—é–Ω–∏–Ω–≥–∞ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –¥–ª—è –º–æ–¥–µ–ª–∏ Tacotron2.

## üöÄ –í–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏

- **–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤** —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º Optuna
- **–ò–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω—ã–π —Ä–∞–Ω–Ω–∏–π –æ—Å—Ç–∞–Ω–æ–≤** —Å –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–º–∏ –∫—Ä–∏—Ç–µ—Ä–∏—è–º–∏
- **–î–∏–Ω–∞–º–∏—á–µ—Å–∫–æ–µ –ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤** –≤–æ –≤—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è
- **–ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏** —á–µ—Ä–µ–∑ MLflow
- **–£–≤–µ–¥–æ–º–ª–µ–Ω–∏—è —á–µ—Ä–µ–∑ Telegram** –æ —Ö–æ–¥–µ –æ–±—É—á–µ–Ω–∏—è
- **–†–µ–µ—Å—Ç—Ä –º–æ–¥–µ–ª–µ–π** –¥–ª—è —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –ª—É—á—à–∏–º–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏
- **–î–µ—Ç–µ–∫—Ü–∏—è –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è** –∏ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –∫–æ—Ä—Ä–µ–∫—Ü–∏—è

## üìÅ –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –ø—Ä–æ–µ–∫—Ç–∞

```
smart_tuner/
‚îú‚îÄ‚îÄ __init__.py                 # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø–∞–∫–µ—Ç–∞
‚îú‚îÄ‚îÄ config.yaml                 # –ì–ª–∞–≤–Ω–∞—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è
‚îú‚îÄ‚îÄ trainer_wrapper.py          # –£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –ø—Ä–æ—Ü–µ—Å—Å–æ–º –æ–±—É—á–µ–Ω–∏—è
‚îú‚îÄ‚îÄ metrics_store.py            # –•—Ä–∞–Ω–µ–Ω–∏–µ –∏ –∞–Ω–∞–ª–∏–∑ –º–µ—Ç—Ä–∏–∫
‚îú‚îÄ‚îÄ log_watcher.py              # –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ MLflow –ª–æ–≥–æ–≤
‚îú‚îÄ‚îÄ optimization_engine.py      # –î–≤–∏–∂–æ–∫ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ Optuna
‚îú‚îÄ‚îÄ param_scheduler.py          # –ü–ª–∞–Ω–∏—Ä–æ–≤—â–∏–∫ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
‚îú‚îÄ‚îÄ early_stop_controller.py    # –ö–æ–Ω—Ç—Ä–æ–ª–ª–µ—Ä —Ä–∞–Ω–Ω–µ–≥–æ –æ—Å—Ç–∞–Ω–æ–≤–∞
‚îú‚îÄ‚îÄ alert_manager.py            # –ú–µ–Ω–µ–¥–∂–µ—Ä —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–π
‚îú‚îÄ‚îÄ model_registry.py           # –†–µ–µ—Å—Ç—Ä –º–æ–¥–µ–ª–µ–π
‚îî‚îÄ‚îÄ README.md                   # –î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è
```

## üîß –£—Å—Ç–∞–Ω–æ–≤–∫–∞

1. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏:
```bash
pip install -r requirements.txt
```

2. –ù–∞—Å—Ç—Ä–æ–π—Ç–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é –≤ `smart_tuner/config.yaml`

3. (–û–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ) –ù–∞—Å—Ç—Ä–æ–π—Ç–µ Telegram –±–æ—Ç–∞ –¥–ª—è —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–π

## ‚öôÔ∏è –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è

### –û—Å–Ω–æ–≤–Ω—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏

```yaml
# –≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç
experiment_name: "tacotron2_smart_tuning"
dataset_path: "data/dataset"
checkpoint_dir: "data/checkpoint"

# –ü—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–æ –ø–æ–∏—Å–∫–∞ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
hyperparameter_search_space:
  learning_rate:
    type: "float"
    min: 0.0001
    max: 0.01
    log: true
    
  batch_size:
    type: "categorical"
    choices: [16, 32, 64]
```

### –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏

```yaml
optimization:
  direction: "minimize"
  objective_metric: "val_loss"
  n_trials: 20
  overfitting_penalty: 0.1
```

### –†–∞–Ω–Ω–∏–π –æ—Å—Ç–∞–Ω–æ–≤

```yaml
early_stopping:
  patience_criterion:
    enabled: true
    type: "patience"
    metric: "val_loss"
    patience: 10
    
  overfitting_criterion:
    enabled: true
    type: "overfitting"
    overfitting_threshold: 0.2
```

### Telegram —É–≤–µ–¥–æ–º–ª–µ–Ω–∏—è

```yaml
telegram:
  enabled: true
  bot_token: "YOUR_BOT_TOKEN"
  chat_id: "YOUR_CHAT_ID"
```

## üöÄ –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ

### –ó–∞–ø—É—Å–∫ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏

```bash
# –ü–æ–ª–Ω–∞—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è —Å 20 trials
python smart_tuner.py

# –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è —Å –∫–∞—Å—Ç–æ–º–Ω—ã–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ–º trials
python smart_tuner.py --trials 50

# –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –∫–∞—Å—Ç–æ–º–Ω–æ–π –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
python smart_tuner.py --config my_config.yaml
```

### –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤

```bash
# –¢–µ—Å—Ç –≤—Å–µ—Ö –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤
python smart_tuner.py --test

# –î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–µ–π
python smart_tuner.py --demo

# –°—Ç–∞—Ç—É—Å —Å–∏—Å—Ç–µ–º—ã
python smart_tuner.py --status
```

### –ü—Ä–æ–≥—Ä–∞–º–º–Ω–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ

```python
from smart_tuner import SmartTunerV2

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è
tuner = SmartTunerV2("smart_tuner/config.yaml")

# –ó–∞–ø—É—Å–∫ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏
results = tuner.run_optimization(n_trials=20)

# –ü–æ–ª—É—á–µ–Ω–∏–µ –ª—É—á—à–∏—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
best_params = results['best_parameters']
print(f"–õ—É—á—à–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã: {best_params}")
```

## üß© –ö–æ–º–ø–æ–Ω–µ–Ω—Ç—ã —Å–∏—Å—Ç–µ–º—ã

### 1. TrainerWrapper
–£–ø—Ä–∞–≤–ª—è–µ—Ç –∂–∏–∑–Ω–µ–Ω–Ω—ã–º —Ü–∏–∫–ª–æ–º –ø—Ä–æ—Ü–µ—Å—Å–∞ –æ–±—É—á–µ–Ω–∏—è:
- –ó–∞–ø—É—Å–∫/–æ—Å—Ç–∞–Ω–æ–≤ train.py
- –ü–æ–∏—Å–∫ –ª—É—á—à–∏—Ö —á–µ–∫–ø–æ–∏–Ω—Ç–æ–≤
- –§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–æ–º–∞–Ω–¥ —Å –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏

### 2. OptimizationEngine
–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –ø–æ–¥–±–æ—Ä –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤:
- –ò—Å–ø–æ–ª—å–∑—É–µ—Ç Optuna TPE sampler
- –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç pruning —Å–ª–∞–±—ã—Ö trials
- –®—Ç—Ä–∞—Ñ—ã –∑–∞ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ

### 3. EarlyStopController
–ò–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω—ã–π —Ä–∞–Ω–Ω–∏–π –æ—Å—Ç–∞–Ω–æ–≤:
- –ö—Ä–∏—Ç–µ—Ä–∏–π —Ç–µ—Ä–ø–µ–Ω–∏—è (patience)
- –î–µ—Ç–µ–∫—Ü–∏—è –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è
- –ö–æ–Ω—Ç—Ä–æ–ª—å —Ä–∞—Å—Ö–æ–∂–¥–µ–Ω–∏—è loss
- –ê–Ω–∞–ª–∏–∑ –ø–ª–∞—Ç–æ –º–µ—Ç—Ä–∏–∫

### 4. ParamScheduler
–î–∏–Ω–∞–º–∏—á–µ—Å–∫–æ–µ –∏–∑–º–µ–Ω–µ–Ω–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤:
- Linear, exponential, cosine –ø–ª–∞–Ω–∏—Ä–æ–≤—â–∏–∫–∏
- Warmup —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏
- –ê–¥–∞–ø—Ç–∞—Ü–∏—è –∫ –ø–ª–∞—Ç–æ

### 5. AlertManager
–°–∏—Å—Ç–µ–º–∞ —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–π:
- Telegram –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è
- –£–≤–µ–¥–æ–º–ª–µ–Ω–∏—è –æ –Ω–∞—á–∞–ª–µ/–∑–∞–≤–µ—Ä—à–µ–Ω–∏–∏
- –ê–ª–µ—Ä—Ç—ã –æ–± –æ—à–∏–±–∫–∞—Ö
- –°–≤–æ–¥–∫–∏ –ø–æ –º–µ—Ç—Ä–∏–∫–∞–º

### 6. ModelRegistry
–£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –º–æ–¥–µ–ª—è–º–∏:
- –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –ª—É—á—à–∏—Ö –º–æ–¥–µ–ª–µ–π
- –í–µ—Ä—Å–∏–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ
- –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤
- –≠–∫—Å–ø–æ—Ä—Ç –º–æ–¥–µ–ª–µ–π

### 7. LogWatcher
–ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –æ–±—É—á–µ–Ω–∏—è:
- –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å MLflow
- –û—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏–µ –º–µ—Ç—Ä–∏–∫ –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏
- –ü–æ–¥–¥–µ—Ä–∂–∫–∞ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤

### 8. MetricsStore
–•—Ä–∞–Ω–µ–Ω–∏–µ –∏ –∞–Ω–∞–ª–∏–∑ –º–µ—Ç—Ä–∏–∫:
- –í—Ä–µ–º–µ–Ω–Ω—ã–µ —Ä—è–¥—ã –º–µ—Ç—Ä–∏–∫
- –°—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑
- –î–µ—Ç–µ–∫—Ü–∏—è –∞–Ω–æ–º–∞–ª–∏–π

## üìä –ü—Ä–∏–º–µ—Ä—ã —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤

### –†–µ–∑—É–ª—å—Ç–∞—Ç –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏
```
=== –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ ===
–õ—É—á—à–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã: {
  'learning_rate': 0.0023,
  'batch_size': 32,
  'epochs': 150,
  'warmup_steps': 1200
}
–õ—É—á—à–µ–µ –∑–Ω–∞—á–µ–Ω–∏–µ: 1.234
–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ trials: 20
```

### –£–≤–µ–¥–æ–º–ª–µ–Ω–∏—è –≤ Telegram
- üöÄ **–û–±—É—á–µ–Ω–∏–µ –Ω–∞—á–∞–ª–æ—Å—å** - –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ–± —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–µ
- üî¨ **Trial –∑–∞–≤–µ—Ä—à–µ–Ω** - —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∫–∞–∂–¥–æ–≥–æ trial
- ‚èπÔ∏è **–†–∞–Ω–Ω–∏–π –æ—Å—Ç–∞–Ω–æ–≤** - –ø—Ä–∏—á–∏–Ω—ã –¥–æ—Å—Ä–æ—á–Ω–æ–≥–æ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è
- üéâ **–û–±—É—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ** - —Ñ–∏–Ω–∞–ª—å–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
- ‚ùå **–û—à–∏–±–∫–∞** - —É–≤–µ–¥–æ–º–ª–µ–Ω–∏—è –æ–± –æ—à–∏–±–∫–∞—Ö

## üîç –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥

### MLflow Dashboard
```bash
mlflow ui --backend-store-uri mlruns
```

### –õ–æ–≥–∏ —Å–∏—Å—Ç–µ–º—ã
```
smart_tuner/logs/smart_tuner.log
```

### –°–æ—Å—Ç–æ—è–Ω–∏–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤
```bash
python smart_tuner.py --status
```

## üõ†Ô∏è –†–∞—Å—à–∏—Ä–µ–Ω–∏–µ —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏

### –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –Ω–æ–≤–æ–≥–æ –∫—Ä–∏—Ç–µ—Ä–∏—è –æ—Å—Ç–∞–Ω–æ–≤–∞

```python
# –í early_stop_controller.py
def _check_custom_criterion(self, config, metrics):
    # –í–∞—à–∞ –ª–æ–≥–∏–∫–∞
    return should_stop
```

### –ö–∞—Å—Ç–æ–º–Ω—ã–π –ø–ª–∞–Ω–∏—Ä–æ–≤—â–∏–∫ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤

```python
# –í param_scheduler.py
def _create_custom_scheduler(self, config):
    def scheduler(step):
        # –í–∞—à–∞ –ª–æ–≥–∏–∫–∞
        return value
    return scheduler
```

### –ù–æ–≤—ã–π —Ç–∏–ø —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–π

```python
# –í alert_manager.py
def send_custom_notification(self, data):
    # –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å –¥—Ä—É–≥–∏–º–∏ —Å–µ—Ä–≤–∏—Å–∞–º–∏
    pass
```

## üêõ –£—Å—Ç—Ä–∞–Ω–µ–Ω–∏–µ –Ω–µ–ø–æ–ª–∞–¥–æ–∫

### –ü—Ä–æ–±–ª–µ–º—ã —Å Optuna
- –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ø—Ä–∞–≤–∞ –Ω–∞ –∑–∞–ø–∏—Å—å –≤ `smart_tuner/optuna_studies.db`
- –£–±–µ–¥–∏—Ç–µ—Å—å –≤ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ—Å—Ç–∏ –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–∞ –ø–æ–∏—Å–∫–∞

### –û—à–∏–±–∫–∏ MLflow
- –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ø—É—Ç—å –∫ `mlruns`
- –£–±–µ–¥–∏—Ç–µ—Å—å —á—Ç–æ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç —Å—É—â–µ—Å—Ç–≤—É–µ—Ç

### –ü—Ä–æ–±–ª–µ–º—ã —Å Telegram
- –ü—Ä–æ–≤–µ—Ä—å—Ç–µ —Ç–æ–∫–µ–Ω –±–æ—Ç–∞ –∏ chat_id
- –£–±–µ–¥–∏—Ç–µ—Å—å –≤ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ api.telegram.org

### –û—à–∏–±–∫–∏ –æ–±—É—á–µ–Ω–∏—è
- –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ø—É—Ç—å –∫ train.py
- –£–±–µ–¥–∏—Ç–µ—Å—å –≤ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ—Å—Ç–∏ –∞—Ä–≥—É–º–µ–Ω—Ç–æ–≤ –∫–æ–º–∞–Ω–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–∏

## üìà –ü—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å

### –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ –Ω–∞—Å—Ç—Ä–æ–π–∫–µ
- –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ pruning –¥–ª—è —É—Å–∫–æ—Ä–µ–Ω–∏—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏
- –ù–∞—Å—Ç—Ä–æ–π—Ç–µ —Ä–∞–∑—É–º–Ω—ã–µ –≥—Ä–∞–Ω–∏—Ü—ã –ø–æ–∏—Å–∫–∞
- –í–∫–ª—é—á–∏—Ç–µ —Ä–∞–Ω–Ω–π –æ—Å—Ç–∞–Ω–æ–≤ –¥–ª—è —ç–∫–æ–Ω–æ–º–∏–∏ –≤—Ä–µ–º–µ–Ω–∏
- –û–≥—Ä–∞–Ω–∏—á—å—Ç–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–æ—Ö—Ä–∞–Ω—è–µ–º—ã—Ö –º–æ–¥–µ–ª–µ–π

### –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ —Ä–µ—Å—É—Ä—Å–æ–≤
```bash
# –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ GPU
nvidia-smi

# –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –¥–∏—Å–∫–∞
du -sh smart_tuner/models/
```

## ü§ù –í–∫–ª–∞–¥ –≤ –ø—Ä–æ–µ–∫—Ç

1. Fork —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è
2. –°–æ–∑–¥–∞–π—Ç–µ feature branch
3. –í–Ω–µ—Å–∏—Ç–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è
4. –î–æ–±–∞–≤—å—Ç–µ —Ç–µ—Å—Ç—ã
5. –°–æ–∑–¥–∞–π—Ç–µ Pull Request

## üìÑ –õ–∏—Ü–µ–Ω–∑–∏—è

MIT License - —Å–º. —Ñ–∞–π–ª LICENSE

## üÜò –ü–æ–¥–¥–µ—Ä–∂–∫–∞

- GitHub Issues –¥–ª—è –±–∞–≥–æ–≤ –∏ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π
- Telegram —á–∞—Ç –¥–ª—è –±—ã—Å—Ç—Ä—ã—Ö –≤–æ–ø—Ä–æ—Å–æ–≤
- Email –¥–ª—è –∫–æ–º–º–µ—Ä—á–µ—Å–∫–æ–π –ø–æ–¥–¥–µ—Ä–∂–∫–∏

---

**Smart Tuner V2** - –¥–µ–ª–∞–µ—Ç –æ–±—É—á–µ–Ω–∏–µ Tacotron2 —É–º–Ω–µ–µ –∏ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–µ–µ! üéØ 