#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Smart Tuner Integration Module
–ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è Smart Tuner —Å –æ—Å–Ω–æ–≤–Ω—ã–º –ø—Ä–æ—Ü–µ—Å—Å–æ–º –æ–±—É—á–µ–Ω–∏—è Tacotron2.

–≠—Ç–æ—Ç –º–æ–¥—É–ª—å –æ–±–µ—Å–ø–µ—á–∏–≤–∞–µ—Ç:
1. –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ —É–ª—É—á—à–µ–Ω–∏–µ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –≤ –ø—Ä–æ—Ü–µ—Å—Å–µ –æ–±—É—á–µ–Ω–∏—è
2. –ò–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω–æ–µ —É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –∫–∞—á–µ—Å—Ç–≤–æ–º TTS
3. –ê–¥–∞–ø—Ç–∏–≤–Ω–æ–µ —É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –ø—Ä–æ—Ü–µ—Å—Å–æ–º –æ–±—É—á–µ–Ω–∏—è
4. –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—é –≤—Å–µ—Ö –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤ Smart Tuner
"""

import torch
import numpy as np
import yaml
import logging
import os
from typing import Dict, Any, Optional, Tuple
from pathlib import Path

# –ò–º–ø–æ—Ä—Ç –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤ Smart Tuner
try:
    from .optimization_engine import OptimizationEngine
    from .early_stop_controller import EarlyStopController
    from .intelligent_epoch_optimizer import IntelligentEpochOptimizer
    from .advanced_quality_controller import AdvancedQualityController
except ImportError:
    # Fallback –¥–ª—è —Å–ª—É—á–∞–µ–≤, –∫–æ–≥–¥–∞ –º–æ–¥—É–ª–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã
    OptimizationEngine = None
    EarlyStopController = None
    IntelligentEpochOptimizer = None
    AdvancedQualityController = None

class SmartTunerIntegration:
    """
    –ì–ª–∞–≤–Ω—ã–π –∫–ª–∞—Å—Å –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ Smart Tuner —Å –æ–±—É—á–µ–Ω–∏–µ–º Tacotron2.
    
    –û–±–µ—Å–ø–µ—á–∏–≤–∞–µ—Ç:
    - –£–º–Ω–æ–µ —É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏
    - –ö–æ–Ω—Ç—Ä–æ–ª—å –∫–∞—á–µ—Å—Ç–≤–∞ –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏  
    - –ê–¥–∞–ø—Ç–∏–≤–Ω–æ–µ –ø—Ä–∏–Ω—è—Ç–∏–µ —Ä–µ—à–µ–Ω–∏–π
    - –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—é —ç–ø–æ—Ö –æ–±—É—á–µ–Ω–∏—è
    """
    
    def __init__(self, config_path: str = "smart_tuner/config.yaml", enable_all_features: bool = True):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ—Ç Smart Tuner Integration —Å –ø–æ–ª–Ω—ã–º –Ω–∞–±–æ—Ä–æ–º –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–µ–π.
        
        Args:
            config_path: –ü—É—Ç—å –∫ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–æ–Ω–Ω–æ–º—É —Ñ–∞–π–ª—É
            enable_all_features: –í–∫–ª—é—á–∏—Ç—å –≤—Å–µ —Ñ—É–Ω–∫—Ü–∏–∏ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é True)
        """
        self.config_path = config_path
        self.enable_all_features = enable_all_features
        self.is_initialized = False
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –±–∞–∑–æ–≤—ã—Ö –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤
        self.config = self._load_config()
        self.logger = self._setup_logger()
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è Telegram –º–æ–Ω–∏—Ç–æ—Ä–∞
        self.telegram_monitor = None
        
        # –ò—Å—Ç–æ—Ä–∏—è –º–µ—Ç—Ä–∏–∫ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
        self.training_metrics_history = []
        self.current_epoch = 0
        self.hyperparameter_adjustments = []
        
        # –ö–æ–º–ø–æ–Ω–µ–Ω—Ç—ã Smart Tuner
        self.early_stop_controller = None
        self.quality_controller = None
        self.epoch_optimizer = None
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –≤—Å–µ—Ö –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤
        if enable_all_features:
            self._initialize_components()
            
        self.logger.info("Smart Tuner Integration –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è _recent_losses –¥–ª—è milestone –ø—Ä–æ–≤–µ—Ä–æ–∫
        self._recent_losses = []
        
    def _load_config(self) -> Dict[str, Any]:
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é Smart Tuner."""
        try:
            with open(self.config_path, 'r', encoding='utf-8') as f:
                return yaml.safe_load(f)
        except FileNotFoundError:
            self.logger.warning(f"–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è Smart Tuner –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: {self.config_path}")
            return self._get_default_config()
        except Exception as e:
            self.logger.error(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏: {e}")
            return self._get_default_config()
    
    def _get_default_config(self) -> Dict[str, Any]:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é."""
        return {
            'smart_tuner_enabled': True,
            'optimization_enabled': True,
            'quality_control_enabled': True,
            'early_stopping_enabled': True,
            'adaptive_learning_enabled': True
        }
    
    def _setup_logger(self) -> logging.Logger:
        """–ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ—Ç –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–ª—è Smart Tuner."""
        logger = logging.getLogger('SmartTunerIntegration')
        logger.setLevel(logging.INFO)
        
        if not logger.handlers:
            handler = logging.StreamHandler()
            formatter = logging.Formatter(
                '%(asctime)s - [SmartTuner] - %(levelname)s - %(message)s'
            )
            handler.setFormatter(formatter)
            logger.addHandler(handler)
        
        return logger
    
    def _initialize_components(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ—Ç –≤—Å–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã Smart Tuner"""
        try:
            # –ò–º–ø–æ—Ä—Ç –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤
            from smart_tuner.early_stop_controller import EarlyStopController
            from smart_tuner.advanced_quality_controller import AdvancedQualityController
            from smart_tuner.intelligent_epoch_optimizer import IntelligentEpochOptimizer
            from smart_tuner.telegram_monitor_enhanced import TelegramMonitorEnhanced
            
            # Early Stop Controller
            if EarlyStopController and self.config.get('early_stopping_enabled', True):
                self.early_stop_controller = EarlyStopController(self.config_path)
                self.logger.info("‚úÖ Early Stop Controller –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
            
            # Telegram Monitor Enhanced
            try:
                self.telegram_monitor = TelegramMonitorEnhanced()
                if self.telegram_monitor.enabled:
                    self.logger.info("‚úÖ Telegram Monitor Enhanced –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
                else:
                    self.logger.info("üì± Telegram Monitor –æ—Ç–∫–ª—é—á–µ–Ω –≤ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏")
            except Exception as e:
                self.logger.warning(f"Telegram Monitor –Ω–µ —É–¥–∞–ª–æ—Å—å –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å: {e}")
                self.telegram_monitor = None
            
            # Intelligent Epoch Optimizer
            if IntelligentEpochOptimizer and self.config.get('epoch_optimization_enabled', True):
                self.epoch_optimizer = IntelligentEpochOptimizer(self.config_path)
                self.logger.info("‚úÖ Intelligent Epoch Optimizer –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
            
            # –ö–æ–Ω—Ç—Ä–æ–ª–ª–µ—Ä –∫–∞—á–µ—Å—Ç–≤–∞
            if AdvancedQualityController and self.config.get('quality_control_enabled', True):
                self.quality_controller = AdvancedQualityController(self.config_path)
                self.logger.info("‚úÖ Advanced Quality Controller –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
            
            self.is_initialized = True
            self.logger.info("üöÄ Smart Tuner Integration —É—Å–ø–µ—à–Ω–æ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
            
        except Exception as e:
            self.logger.error(f"–û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ Smart Tuner: {e}")
            self.is_initialized = False
    
    def analyze_dataset_for_training(self, dataset_info: Dict[str, Any]) -> Dict[str, Any]:
        """
        –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –¥–∞—Ç–∞—Å–µ—Ç –∏ —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –æ–±—É—á–µ–Ω–∏—è.
        
        Args:
            dataset_info: –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –¥–∞—Ç–∞—Å–µ—Ç–µ (—Ä–∞–∑–º–µ—Ä, –∫–∞—á–µ—Å—Ç–≤–æ, —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏)
            
        Returns:
            –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ –æ–±—É—á–µ–Ω–∏—é
        """
        recommendations = {
            'optimal_epochs': 3000,
            'recommended_batch_size': 12,
            'learning_rate_range': (1e-6, 5e-5),
            'quality_expectations': 'good',
            'estimated_training_time_hours': 8.0
        }
        
        if self.epoch_optimizer:
            try:
                analysis = self.epoch_optimizer.analyze_dataset(dataset_info)
                recommendations.update(analysis)
                self.logger.info(f"üìä –ê–Ω–∞–ª–∏–∑ –¥–∞—Ç–∞—Å–µ—Ç–∞ –∑–∞–≤–µ—Ä—à–µ–Ω: {analysis.get('recommended_epochs_range')}")
            except Exception as e:
                self.logger.error(f"–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞: {e}")
        
        return recommendations
    
    def on_training_start(self, initial_hyperparams: Dict[str, Any], dataset_info: Optional[Dict] = None) -> Dict[str, Any]:
        """
        –í—ã–∑—ã–≤–∞–µ—Ç—Å—è –≤ –Ω–∞—á–∞–ª–µ –æ–±—É—á–µ–Ω–∏—è –¥–ª—è –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤.
        
        Args:
            initial_hyperparams: –ù–∞—á–∞–ª—å–Ω—ã–µ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä—ã
            dataset_info: –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –¥–∞—Ç–∞—Å–µ—Ç–µ
            
        Returns:
            –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è —Å—Ç–∞—Ä—Ç–∞
        """
        if not self.is_initialized:
            self.logger.warning("Smart Tuner –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω, –∏—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è –∏—Å—Ö–æ–¥–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã")
            return initial_hyperparams
        
        optimized_params = initial_hyperparams.copy()
        
        # –ê–Ω–∞–ª–∏–∑ –¥–∞—Ç–∞—Å–µ—Ç–∞ –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏
        if dataset_info and self.epoch_optimizer:
            dataset_recommendations = self.analyze_dataset_for_training(dataset_info)
            
            # –ü—Ä–∏–º–µ–Ω—è–µ–º —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –∫ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º
            if 'optimal_epochs' in dataset_recommendations:
                optimized_params['epochs'] = dataset_recommendations['optimal_epochs']
            
            if 'recommended_batch_size' in dataset_recommendations:
                optimized_params['batch_size'] = dataset_recommendations['recommended_batch_size']
        
        # –õ–æ–≥–∏—Ä—É–µ–º –∏–∑–º–µ–Ω–µ–Ω–∏—è
        changes = []
        for key in optimized_params:
            if key in initial_hyperparams and optimized_params[key] != initial_hyperparams[key]:
                changes.append(f"{key}: {initial_hyperparams[key]} ‚Üí {optimized_params[key]}")
        
        if changes:
            self.logger.info(f"üîß –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω—ã –ø–∞—Ä–∞–º–µ—Ç—Ä—ã: {', '.join(changes)}")
        
        return optimized_params
    
    def on_epoch_start(self, epoch: int, current_hyperparams: Dict[str, Any]) -> Dict[str, Any]:
        """
        –í—ã–∑—ã–≤–∞–µ—Ç—Å—è –≤ –Ω–∞—á–∞–ª–µ –∫–∞–∂–¥–æ–π —ç–ø–æ—Ö–∏.
        
        Args:
            epoch: –ù–æ–º–µ—Ä —ç–ø–æ—Ö–∏
            current_hyperparams: –¢–µ–∫—É—â–∏–µ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä—ã
            
        Returns:
            –í–æ–∑–º–æ–∂–Ω–æ –æ–±–Ω–æ–≤–ª–µ–Ω–Ω—ã–µ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä—ã
        """
        self.current_epoch = epoch
        
        if not self.is_initialized:
            return current_hyperparams
        
        # –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –ø—Ä–æ–≥—Ä–µ—Å—Å–∞ —ç–ø–æ—Ö
        if self.epoch_optimizer:
            try:
                # –°–æ–∑–¥–∞–µ–º –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏ –¥–ª—è –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞
                basic_metrics = {
                    'epoch': epoch,
                    'learning_rate': current_hyperparams.get('learning_rate', 1e-4)
                }
                
                progress_analysis = self.epoch_optimizer.monitor_training_progress(epoch, basic_metrics)
                
                if progress_analysis.get('recommendations'):
                    recommendations = progress_analysis['recommendations']
                    self.logger.info(f"üìà –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –¥–ª—è —ç–ø–æ—Ö–∏ {epoch}: {recommendations.get('action', 'continue')}")
                
            except Exception as e:
                self.logger.error(f"–û—à–∏–±–∫–∞ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ —ç–ø–æ—Ö–∏: {e}")
        
        return current_hyperparams
    
    def on_batch_end(self, epoch: int, batch: int, metrics: Dict[str, float], 
                     model_outputs: Optional[Tuple] = None) -> Dict[str, Any]:
        """
        –í—ã–∑—ã–≤–∞–µ—Ç—Å—è –ø–æ—Å–ª–µ –∫–∞–∂–¥–æ–≥–æ batch –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –∫–∞—á–µ—Å—Ç–≤–∞.
        
        Args:
            epoch: –ù–æ–º–µ—Ä —ç–ø–æ—Ö–∏
            batch: –ù–æ–º–µ—Ä batch
            metrics: –ú–µ—Ç—Ä–∏–∫–∏ –æ–±—É—á–µ–Ω–∏—è
            model_outputs: –í—ã—Ö–æ–¥—ã –º–æ–¥–µ–ª–∏ (mel, gate, attention)
            
        Returns:
            –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –∏ –∞–Ω–∞–ª–∏–∑ –∫–∞—á–µ—Å—Ç–≤–∞
        """
        analysis_result = {
            'continue_training': True,
            'quality_issues': [],
            'recommended_actions': []
        }
        
        if not self.is_initialized:
            return analysis_result
        
        # –ê–Ω–∞–ª–∏–∑ –∫–∞—á–µ—Å—Ç–≤–∞ —á–µ—Ä–µ–∑ Quality Controller
        if self.quality_controller and model_outputs:
            try:
                mel_outputs, gate_outputs, attention_weights = model_outputs[:3]
                
                quality_analysis = self.quality_controller.analyze_training_quality(
                    epoch=epoch,
                    metrics=metrics,
                    attention_weights=attention_weights,
                    gate_outputs=gate_outputs,
                    mel_outputs=mel_outputs
                )
                
                analysis_result['quality_score'] = quality_analysis.get('overall_quality_score', 0.5)
                analysis_result['quality_issues'] = quality_analysis.get('quality_issues', [])
                analysis_result['recommended_actions'] = quality_analysis.get('recommended_interventions', [])
                
                # –õ–æ–≥–∏—Ä—É–µ–º —Å–µ—Ä—å–µ–∑–Ω—ã–µ –ø—Ä–æ–±–ª–µ–º—ã –∫–∞—á–µ—Å—Ç–≤–∞
                high_severity_issues = [
                    issue for issue in analysis_result['quality_issues'] 
                    if issue.get('severity') == 'high'
                ]
                
                if high_severity_issues:
                    self.logger.warning(f"‚ö†Ô∏è –û–±–Ω–∞—Ä—É–∂–µ–Ω—ã —Å–µ—Ä—å–µ–∑–Ω—ã–µ –ø—Ä–æ–±–ª–µ–º—ã –∫–∞—á–µ—Å—Ç–≤–∞ –≤ —ç–ø–æ—Ö–µ {epoch}")
                    for issue in high_severity_issues:
                        self.logger.warning(f"   - {issue.get('description', 'Unknown issue')}")
                
            except Exception as e:
                self.logger.error(f"–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ –∫–∞—á–µ—Å—Ç–≤–∞: {e}")
        
        return analysis_result
    
    def on_epoch_end(self, epoch: int, metrics: Dict[str, float], 
                     current_hyperparams: Dict[str, Any]) -> Dict[str, Any]:
        """
        –í—ã–∑—ã–≤–∞–µ—Ç—Å—è –≤ –∫–æ–Ω—Ü–µ —ç–ø–æ—Ö–∏ –¥–ª—è –ø—Ä–∏–Ω—è—Ç–∏—è —Ä–µ—à–µ–Ω–∏–π.
        
        Args:
            epoch: –ù–æ–º–µ—Ä —ç–ø–æ—Ö–∏
            metrics: –ú–µ—Ç—Ä–∏–∫–∏ —ç–ø–æ—Ö–∏
            current_hyperparams: –¢–µ–∫—É—â–∏–µ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä—ã
            
        Returns:
            –†–µ—à–µ–Ω–∏—è –∏ –æ–±–Ω–æ–≤–ª–µ–Ω–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
        """
        decision_result = {
            'continue_training': True,
            'hyperparameter_updates': {},
            'early_stop': False,
            'reason': 'normal_progress'
        }
        
        if not self.is_initialized:
            return decision_result
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–µ—Ç—Ä–∏–∫–∏ –≤ –∏—Å—Ç–æ—Ä–∏—é
        self.training_metrics_history.append({
            'epoch': epoch,
            'metrics': metrics.copy(),
            'hyperparams': current_hyperparams.copy()
        })
        
        # –ê–Ω–∞–ª–∏–∑ —á–µ—Ä–µ–∑ Early Stop Controller
        if self.early_stop_controller:
            try:
                # –î–æ–±–∞–≤–ª—è–µ–º –º–µ—Ç—Ä–∏–∫–∏ –≤ –∫–æ–Ω—Ç—Ä–æ–ª–ª–µ—Ä
                self.early_stop_controller.add_metrics(metrics)
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–Ω–Ω—é—é –æ—Å—Ç–∞–Ω–æ–≤–∫—É
                should_stop, stop_reason = self.early_stop_controller.should_stop_early(metrics)
                
                if should_stop:
                    decision_result['early_stop'] = True
                    decision_result['reason'] = stop_reason
                    decision_result['continue_training'] = False
                    self.logger.info(f"üõë –†–µ–∫–æ–º–µ–Ω–¥–æ–≤–∞–Ω–∞ —Ä–∞–Ω–Ω—è—è –æ—Å—Ç–∞–Ω–æ–≤–∫–∞: {stop_reason}")
                    return decision_result
                
                # –ü–æ–ª—É—á–∞–µ–º —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ —É–ª—É—á—à–µ–Ω–∏—é
                recommendations = self.early_stop_controller.decide_next_step(current_hyperparams)
                
                if recommendations.get('action') != 'continue':
                    action = recommendations.get('action')
                    reason = recommendations.get('reason', 'Unknown')
                    
                    self.logger.info(f"üîß –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è: {action} - {reason}")
                    
                    # –ü—Ä–∏–º–µ–Ω—è–µ–º –∏–∑–º–µ–Ω–µ–Ω–∏—è –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
                    if 'hyperparameter_updates' in recommendations:
                        decision_result['hyperparameter_updates'] = recommendations['hyperparameter_updates']
                        
                        # –õ–æ–≥–∏—Ä—É–µ–º –∏–∑–º–µ–Ω–µ–Ω–∏—è
                        updates = recommendations['hyperparameter_updates']
                        changes = [f"{k}: {current_hyperparams.get(k, 'N/A')} ‚Üí {v}" for k, v in updates.items()]
                        self.logger.info(f"   –ò–∑–º–µ–Ω–µ–Ω–∏—è: {', '.join(changes)}")
                
            except Exception as e:
                self.logger.error(f"–û—à–∏–±–∫–∞ –≤ Early Stop Controller: {e}")
        
        # –£–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ –≤ Telegram –æ –¥–µ–π—Å—Ç–≤–∏–∏ Smart Tuner
        if hasattr(self, 'telegram_monitor') and self.telegram_monitor and decision_result.get('hyperparameter_updates'):
            try:
                reasoning = self._get_human_readable_reasoning('hyperparameter_update', metrics, {'epoch': epoch})
                action_details = {
                    'changes': decision_result['hyperparameter_updates'],
                    'trigger_metrics': metrics,
                    'context': {'epoch': epoch}
                }
                
                self.telegram_monitor.send_smart_tuner_action(
                    action_type='hyperparameter_update',
                    action_details=action_details,
                    reasoning=reasoning,
                    step=epoch
                )
            except Exception as e:
                self.logger.warning(f"–û—à–∏–±–∫–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏ Telegram —É–≤–µ–¥–æ–º–ª–µ–Ω–∏—è: {e}")
        
        return decision_result
    
    def apply_quality_interventions(self, interventions: list, 
                                   current_hyperparams: Dict[str, Any]) -> Dict[str, Any]:
        """
        –ü—Ä–∏–º–µ–Ω—è–µ—Ç –≤–º–µ—à–∞—Ç–µ–ª—å—Å—Ç–≤–∞ –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è –∫–∞—á–µ—Å—Ç–≤–∞.
        
        Args:
            interventions: –°–ø–∏—Å–æ–∫ –≤–º–µ—à–∞—Ç–µ–ª—å—Å—Ç–≤
            current_hyperparams: –¢–µ–∫—É—â–∏–µ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä—ã
            
        Returns:
            –û–±–Ω–æ–≤–ª–µ–Ω–Ω—ã–µ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä—ã
        """
        updated_params = current_hyperparams.copy()
        
        if not self.quality_controller or not interventions:
            return updated_params
        
        for intervention in interventions:
            try:
                # –ü—Ä–∏–º–µ–Ω—è–µ–º –≤–º–µ—à–∞—Ç–µ–ª—å—Å—Ç–≤–æ —á–µ—Ä–µ–∑ Quality Controller
                updated_params = self.quality_controller.apply_quality_intervention(
                    intervention, updated_params
                )
                
                self.logger.info(f"‚ú® –ü—Ä–∏–º–µ–Ω–µ–Ω–æ –≤–º–µ—à–∞—Ç–µ–ª—å—Å—Ç–≤–æ: {intervention.get('description', 'Unknown')}")
                
            except Exception as e:
                self.logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è –≤–º–µ—à–∞—Ç–µ–ª—å—Å—Ç–≤–∞: {e}")
        
        return updated_params
    
    def on_training_complete(self, final_metrics: Dict[str, float], 
                           total_epochs: int, training_time_hours: float) -> Dict[str, Any]:
        """
        –í—ã–∑—ã–≤–∞–µ—Ç—Å—è –ø–æ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—é –æ–±—É—á–µ–Ω–∏—è –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤.
        
        Args:
            final_metrics: –§–∏–Ω–∞–ª—å–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏
            total_epochs: –û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —ç–ø–æ—Ö
            training_time_hours: –í—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è –≤ —á–∞—Å–∞—Ö
            
        Returns:
            –ê–Ω–∞–ª–∏–∑ –∏ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
        """
        training_summary = {
            'training_success': True,
            'quality_assessment': 'good',
            'efficiency_score': 0.8,
            'recommendations_for_future': [],
            'smart_tuner_interventions': len(self.hyperparameter_adjustments)
        }
        
        if not self.is_initialized:
            return training_summary
        
        try:
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏
            if self.epoch_optimizer:
                self.epoch_optimizer.save_optimization_result(
                    final_metrics, total_epochs, training_time_hours * 60
                )
            
            # –û—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ –æ–±—É—á–µ–Ω–∏—è
            if final_metrics.get('val_loss', float('inf')) < 3.0:
                training_summary['quality_assessment'] = 'excellent'
            elif final_metrics.get('val_loss', float('inf')) < 5.0:
                training_summary['quality_assessment'] = 'good'
            else:
                training_summary['quality_assessment'] = 'needs_improvement'
            
            # –û—Ü–µ–Ω–∫–∞ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏
            expected_time = total_epochs * 0.1  # –ü—Ä–∏–º–µ—Ä–Ω–æ 0.1 —á–∞—Å–∞ –Ω–∞ —ç–ø–æ—Ö—É
            efficiency = min(expected_time / training_time_hours, 1.0) if training_time_hours > 0 else 0.5
            training_summary['efficiency_score'] = efficiency
            
            # –ü–æ–ª—É—á–∞–µ–º —Å–≤–æ–¥–∫—É –∫–∞—á–µ—Å—Ç–≤–∞
            if self.quality_controller:
                quality_summary = self.quality_controller.get_quality_summary()
                training_summary['quality_details'] = quality_summary
            
            self.logger.info(f"üéØ –û–±—É—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ: –∫–∞—á–µ—Å—Ç–≤–æ={training_summary['quality_assessment']}, "
                           f"—ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å={efficiency:.2f}, –≤–º–µ—à–∞—Ç–µ–ª—å—Å—Ç–≤={len(self.hyperparameter_adjustments)}")
            
        except Exception as e:
            self.logger.error(f"–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –æ–±—É—á–µ–Ω–∏—è: {e}")
        
        return training_summary
    
    def get_training_recommendations(self) -> Dict[str, Any]:
        """
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ –Ω–∞–∫–æ–ø–ª–µ–Ω–Ω–æ–≥–æ –æ–ø—ã—Ç–∞.
        
        Returns:
            –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –¥–ª—è –±—É–¥—É—â–∏—Ö –æ–±—É—á–µ–Ω–∏–π
        """
        recommendations = {
            'hyperparameter_suggestions': {},
            'training_strategy': 'standard',
            'expected_quality': 'good',
            'confidence': 0.7
        }
        
        if not self.is_initialized or not self.training_metrics_history:
            return recommendations
        
        try:
            # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –∏—Å—Ç–æ—Ä–∏—é –º–µ—Ç—Ä–∏–∫
            recent_metrics = self.training_metrics_history[-10:]  # –ü–æ—Å–ª–µ–¥–Ω–∏–µ 10 —ç–ø–æ—Ö
            
            # –°—Ä–µ–¥–Ω–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è
            avg_train_loss = np.mean([m['metrics'].get('train_loss', 0) for m in recent_metrics])
            avg_val_loss = np.mean([m['metrics'].get('val_loss', 0) for m in recent_metrics])
            
            # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
            if avg_val_loss < 3.0:
                recommendations['training_strategy'] = 'high_quality_focused'
                recommendations['expected_quality'] = 'excellent'
            elif avg_val_loss > 8.0:
                recommendations['training_strategy'] = 'stability_focused'
                recommendations['expected_quality'] = 'needs_improvement'
            
            # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º
            if len(self.hyperparameter_adjustments) > 0:
                last_adjustment = self.hyperparameter_adjustments[-1]
                recommendations['hyperparameter_suggestions'] = last_adjustment.get('successful_params', {})
            
            self.logger.info(f"üìã –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω—ã —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏: —Å—Ç—Ä–∞—Ç–µ–≥–∏—è={recommendations['training_strategy']}")
            
        except Exception as e:
            self.logger.error(f"–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π: {e}")
        
        return recommendations
    
    def is_available(self) -> bool:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å Smart Tuner."""
        return self.is_initialized
    
    def get_status(self) -> Dict[str, Any]:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å—Ç–∞—Ç—É—Å Smart Tuner."""
        return {
            'initialized': self.is_initialized,
            'optimization_engine': self.optimization_engine is not None,
            'early_stop_controller': self.early_stop_controller is not None,
            'epoch_optimizer': self.epoch_optimizer is not None,
            'quality_controller': self.quality_controller is not None,
            'current_epoch': self.current_epoch,
            'interventions_count': len(self.hyperparameter_adjustments)
        }
    
    def _get_human_readable_reasoning(self, decision_type: str, metrics: Dict[str, float], 
                                    context: Dict[str, Any]) -> str:
        """
        üß† –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –ø–æ–Ω—è—Ç–Ω–æ–µ —á–µ–ª–æ–≤–µ–∫—É –æ–±—ä—è—Å–Ω–µ–Ω–∏–µ —Ä–µ—à–µ–Ω–∏—è Smart Tuner.
        
        Args:
            decision_type: –¢–∏–ø –ø—Ä–∏–Ω—è—Ç–æ–≥–æ —Ä–µ—à–µ–Ω–∏—è
            metrics: –¢–µ–∫—É—â–∏–µ –º–µ—Ç—Ä–∏–∫–∏
            context: –ö–æ–Ω—Ç–µ–∫—Å—Ç –æ–±—É—á–µ–Ω–∏—è
            
        Returns:
            –ß–µ–ª–æ–≤–µ–∫–æ–ø–æ–Ω—è—Ç–Ω–æ–µ –æ–±—ä—è—Å–Ω–µ–Ω–∏–µ –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ
        """
        
        attention_diag = metrics.get('attention_diagonality', 0)
        val_loss = metrics.get('val_loss', float('inf'))
        quality_score = metrics.get('quality_score', 0)
        phase = context.get('phase', 'unknown')
        
        # –ê–Ω–∞–ª–∏–∑ —Å–∏—Ç—É–∞—Ü–∏–∏ –∏ —Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ –æ–±—ä—è—Å–Ω–µ–Ω–∏—è
        if decision_type == 'learning_rate_reduction':
            if attention_diag < 0.3:
                return (f"üéØ –û–±–Ω–∞—Ä—É–∂–µ–Ω–∞ –≥–æ—Ä–∏–∑–æ–Ω—Ç–∞–ª—å–Ω–∞—è –ø–æ–ª–æ—Å–∞ –≤–º–µ—Å—Ç–æ –¥–∏–∞–≥–æ–Ω–∞–ª–∏ –≤ attention (–¥–∏–∞–≥–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å {attention_diag:.3f}). "
                       f"–≠—Ç–æ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –ø—Ä–æ–±–ª–µ–º–∞! –°–Ω–∏–∂–∞—é learning rate –¥–ª—è –±–æ–ª–µ–µ –∞–∫–∫—É—Ä–∞—Ç–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è attention –º–µ—Ö–∞–Ω–∏–∑–º–∞. "
                       f"–¶–µ–ª—å: –ø–æ–ª—É—á–∏—Ç—å —á–µ—Ç–∫—É—é –¥–∏–∞–≥–æ–Ω–∞–ª—å –¥–ª—è –ø—Ä–∞–≤–∏–ª—å–Ω–æ–≥–æ –≤—ã—Ä–∞–≤–Ω–∏–≤–∞–Ω–∏—è —Ç–µ–∫—Å—Ç-–∞—É–¥–∏–æ.")
            elif attention_diag < 0.6:
                return (f"üìä Attention –¥–∏–∞–≥–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å {attention_diag:.3f} –Ω–∏–∂–µ –Ω–æ—Ä–º—ã. "
                       f"–ú–æ–¥–µ–ª—å –ø–ª–æ—Ö–æ –≤—ã—Ä–∞–≤–Ω–∏–≤–∞–µ—Ç —Ç–µ–∫—Å—Ç –∏ –∞—É–¥–∏–æ. –°–Ω–∏–∂–∞—é learning rate –¥–ª—è –±–æ–ª–µ–µ —Å—Ç–∞–±–∏–ª—å–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è. "
                       f"–û–∂–∏–¥–∞—é —É–ª—É—á—à–µ–Ω–∏—è –∫–∞—á–µ—Å—Ç–≤–∞ –≥–æ–ª–æ—Å–∞.")
            else:
                return (f"‚ö° –û–±—É—á–µ–Ω–∏–µ –∏–¥–µ—Ç —Å–ª–∏—à–∫–æ–º –±—ã—Å—Ç—Ä–æ (loss {val_loss:.4f}). "
                       f"–°–Ω–∏–∂–∞—é learning rate –¥–ª—è –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–µ–Ω–∏—è –ø—Ä–æ–ø—É—Å–∫–∞ –æ–ø—Ç–∏–º—É–º–∞ –∏ –ø–æ–ª—É—á–µ–Ω–∏—è –ª—É—á—à–µ–≥–æ –∫–∞—á–µ—Å—Ç–≤–∞.")
        
        elif decision_type == 'dropout_adjustment':
            if quality_score < 0.5:
                return (f"üéµ –ö–∞—á–µ—Å—Ç–≤–æ –≥–æ–ª–æ—Å–∞ –Ω–∏–∑–∫–æ–µ ({quality_score:.1%}). "
                       f"–í–æ–∑–º–æ–∂–Ω–æ, –≤—ã—Å–æ–∫–∏–π dropout —Å–æ–∑–¥–∞–µ—Ç –∞—Ä—Ç–µ—Ñ–∞–∫—Ç—ã. –°–Ω–∏–∂–∞—é dropout –¥–ª—è –±–æ–ª–µ–µ —á–µ—Ç–∫–æ–π –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏. "
                       f"–¶–µ–ª—å: —É–±—Ä–∞—Ç—å –ø–æ—Å—Ç–æ—Ä–æ–Ω–Ω–∏–µ —à—É–º—ã –∏ —É–ª—É—á—à–∏—Ç—å –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç—å.")
            else:
                return (f"üõ°Ô∏è –ó–∞—â–∏—â–∞—é –º–æ–¥–µ–ª—å –æ—Ç –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è. "
                       f"–ö–∞—á–µ—Å—Ç–≤–æ —Ö–æ—Ä–æ—à–µ–µ ({quality_score:.1%}), –Ω–æ –Ω—É–∂–Ω–æ —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å. "
                       f"–ö–æ—Ä—Ä–µ–∫—Ç–∏—Ä—É—é dropout –¥–ª—è –±–∞–ª–∞–Ω—Å–∞ –∫–∞—á–µ—Å—Ç–≤–∞ –∏ –Ω–∞–¥–µ–∂–Ω–æ—Å—Ç–∏.")
        
        elif decision_type == 'batch_size_optimization':
            if attention_diag < 0.5:
                return (f"üîç Attention –ø–ª–æ—Ö–æ —Ñ–æ–∫—É—Å–∏—Ä—É–µ—Ç—Å—è (–¥–∏–∞–≥–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å {attention_diag:.3f}). "
                       f"–ë–æ–ª—å—à–∏–µ –±–∞—Ç—á–∏ –º–µ—à–∞—é—Ç –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω–æ–º—É –æ–±—É—á–µ–Ω–∏—é attention. "
                       f"–£–º–µ–Ω—å—à–∞—é batch size –¥–ª—è –ª—É—á—à–µ–≥–æ –≥—Ä–∞–¥–∏–µ–Ω—Ç–Ω–æ–≥–æ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è. "
                       f"–û–∂–∏–¥–∞—é –±–æ–ª–µ–µ —á–µ—Ç–∫–æ–≥–æ –≤—ã—Ä–∞–≤–Ω–∏–≤–∞–Ω–∏—è.")
            else:
                return (f"‚ö° –û–ø—Ç–∏–º–∏–∑–∏—Ä—É—é —Å–∫–æ—Ä–æ—Å—Ç—å –æ–±—É—á–µ–Ω–∏—è. "
                       f"Attention —Ä–∞–±–æ—Ç–∞–µ—Ç —Ö–æ—Ä–æ—à–æ, –º–æ–∂–Ω–æ —É–≤–µ–ª–∏—á–∏—Ç—å batch size –¥–ª—è —É—Å–∫–æ—Ä–µ–Ω–∏—è –±–µ–∑ –ø–æ—Ç–µ—Ä–∏ –∫–∞—á–µ—Å—Ç–≤–∞.")
        
        elif decision_type == 'guided_attention_boost':
            return (f"üéØ –ö–†–ò–¢–ò–ß–ù–û! –î–∏–∞–≥–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å {attention_diag:.3f} –æ–∑–Ω–∞—á–∞–µ—Ç, —á—Ç–æ –º–æ–¥–µ–ª—å –Ω–µ —É—á–∏—Ç—Å—è –ø—Ä–∞–≤–∏–ª—å–Ω–æ –≤—ã—Ä–∞–≤–Ω–∏–≤–∞—Ç—å —Ç–µ–∫—Å—Ç –∏ –∞—É–¥–∏–æ. "
                   f"–≠—Ç–æ –ø—Ä–∏–≤–µ–¥–µ—Ç –∫ –Ω–µ—Ä–∞–∑–±–æ—Ä—á–∏–≤–æ–º—É –≥–æ–ª–æ—Å—É —Å –∞—Ä—Ç–µ—Ñ–∞–∫—Ç–∞–º–∏. "
                   f"–£—Å–∏–ª–∏–≤–∞—é guided attention loss –¥–ª—è –ø—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è –ø—Ä–∞–≤–∏–ª—å–Ω–æ–º—É alignment. "
                   f"–¶–µ–ª—å: –∑–∞—Å—Ç–∞–≤–∏—Ç—å –º–æ–¥–µ–ª—å —Å–æ–∑–¥–∞—Ç—å —á–µ—Ç–∫—É—é –¥–∏–∞–≥–æ–Ω–∞–ª—å.")
        
        elif decision_type == 'phase_transition':
            new_phase = context.get('new_phase', 'unknown')
            if new_phase == 'quality_optimization':
                return (f"üé≠ –ë–∞–∑–æ–≤–æ–µ –æ–±—É—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ. –î–∏–∞–≥–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å {attention_diag:.3f} –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–∞ –¥–ª—è –ø–µ—Ä–µ—Ö–æ–¥–∞. "
                       f"–ü–µ—Ä–µ–∫–ª—é—á–∞—é—Å—å –Ω–∞ —Ñ–∞–∑—É –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω–æ–π –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏. "
                       f"–¢–µ–ø–µ—Ä—å —Ñ–æ–∫—É—Å –Ω–∞ –ø–æ–ª—É—á–µ–Ω–∏–∏ –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ —á–µ–ª–æ–≤–µ—á–µ—Å–∫–æ–≥–æ –≥–æ–ª–æ—Å–∞ –±–µ–∑ –∞—Ä—Ç–µ—Ñ–∞–∫—Ç–æ–≤.")
            elif new_phase == 'fine_tuning':
                return (f"üèÜ –û—Å–Ω–æ–≤–Ω—ã–µ –ø—Ä–æ–±–ª–µ–º—ã —Ä–µ—à–µ–Ω—ã! –ö–∞—á–µ—Å—Ç–≤–æ {quality_score:.1%}. "
                       f"–ü–µ—Ä–µ—Ö–æ–¥–∂—É –∫ —Ç–æ–Ω–∫–æ–π –Ω–∞—Å—Ç—Ä–æ–π–∫–µ –¥–ª—è –¥–æ—Å—Ç–∏–∂–µ–Ω–∏—è —Å—Ç—É–¥–∏–π–Ω–æ–≥–æ –∫–∞—á–µ—Å—Ç–≤–∞ –≥–æ–ª–æ—Å–∞. "
                       f"–¶–µ–ª—å: –∏–¥–µ–∞–ª—å–Ω–∞—è –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç—å –∏ –æ—Ç—Å—É—Ç—Å—Ç–≤–∏–µ –ª—é–±—ã—Ö –∞—Ä—Ç–µ—Ñ–∞–∫—Ç–æ–≤.")
            else:
                return (f"üîÑ –ò–∑–º–µ–Ω–µ–Ω–∏–µ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ –æ–±—É—á–µ–Ω–∏—è. –ü–µ—Ä–µ—Ö–æ–¥ –≤ —Ñ–∞–∑—É '{new_phase}' –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –ø—Ä–æ—Ü–µ—Å—Å–∞.")
        
        elif decision_type == 'early_stop':
            if val_loss == float('inf') or val_loss > 10:
                return (f"üö® –ö–†–ò–¢–ò–ß–ï–°–ö–ê–Ø –û–®–ò–ë–ö–ê! Loss –≤–∑–æ—Ä–≤–∞–ª—Å—è ({val_loss}). "
                       f"–ú–æ–¥–µ–ª—å –ø–æ–ª–Ω–æ—Å—Ç—å—é —Ä–∞–∑—Ä—É—à–µ–Ω–∞ –∏ –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Ç–æ–ª—å–∫–æ —à—É–º. "
                       f"–û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞—é –æ–±—É—á–µ–Ω–∏–µ –¥–ª—è –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–µ–Ω–∏—è –¥–∞–ª—å–Ω–µ–π—à–µ–≥–æ —É—â–µ—Ä–±–∞. "
                       f"–ù—É–∂–Ω–æ –ø–µ—Ä–µ–∑–∞–ø—É—Å—Ç–∏—Ç—å —Å –º–µ–Ω—å—à–∏–º learning rate.")
            elif attention_diag < 0.1:
                return (f"üõë Attention –ø–æ–ª–Ω–æ—Å—Ç—å—é —Å–ª–æ–º–∞–Ω (–¥–∏–∞–≥–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å {attention_diag:.3f}). "
                       f"–ú–æ–¥–µ–ª—å –Ω–µ —Å–ø–æ—Å–æ–±–Ω–∞ –≤—ã—Ä–∞–≤–Ω–∏–≤–∞—Ç—å —Ç–µ–∫—Å—Ç –∏ –∞—É–¥–∏–æ. "
                       f"–î–∞–ª—å–Ω–µ–π—à–µ–µ –æ–±—É—á–µ–Ω–∏–µ –±–µ—Å–ø–æ–ª–µ–∑–Ω–æ. –ù—É–∂–Ω–∞ –∫–æ—Ä—Ä–µ–∫—Ü–∏—è –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤.")
            else:
                return (f"üìâ –û–±—É—á–µ–Ω–∏–µ –∑–∞—Å—Ç–æ–ø–æ—Ä–∏–ª–æ—Å—å. Val loss {val_loss:.4f} –Ω–µ —É–ª—É—á—à–∞–µ—Ç—Å—è. "
                       f"–û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞—é –¥–ª—è —ç–∫–æ–Ω–æ–º–∏–∏ —Ä–µ—Å—É—Ä—Å–æ–≤ –∏ –∞–Ω–∞–ª–∏–∑–∞ –ø—Ä–æ–±–ª–µ–º—ã.")
        
        # –û–±—â–∏–π —Å–ª—É—á–∞–π
        return (f"üß† Smart Tuner –æ–±–Ω–∞—Ä—É–∂–∏–ª —Å–∏—Ç—É–∞—Ü–∏—é, —Ç—Ä–µ–±—É—é—â—É—é –≤–º–µ—à–∞—Ç–µ–ª—å—Å—Ç–≤–∞. "
               f"–¢–µ–∫—É—â–∏–µ –º–µ—Ç—Ä–∏–∫–∏: –¥–∏–∞–≥–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å {attention_diag:.3f}, –∫–∞—á–µ—Å—Ç–≤–æ {quality_score:.1%}. "
               f"–ü—Ä–∏–º–µ–Ω—è—é –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—é –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è –æ–±—É—á–µ–Ω–∏—è.")
    
    def send_critical_alert_if_needed(self, metrics: Dict[str, float], step: int) -> None:
        """
        üö® –û—Ç–ø—Ä–∞–≤–ª—è–µ—Ç –∫—Ä–∏—Ç–∏—á–µ—Å–∫–æ–µ –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ –µ—Å–ª–∏ –æ–±–Ω–∞—Ä—É–∂–µ–Ω—ã —Å–µ—Ä—å–µ–∑–Ω—ã–µ –ø—Ä–æ–±–ª–µ–º—ã.
        """
        if not hasattr(self, 'telegram_monitor') or not self.telegram_monitor:
            return
            
        try:
            critical_issues = []
            recommendations = []
            
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏—Ö –ø—Ä–æ–±–ª–µ–º
            attention_diag = metrics.get('attention_diagonality', 0)
            if attention_diag < 0.1:
                critical_issues.append("–ü–æ–ª–Ω–æ–µ —Ä–∞–∑—Ä—É—à–µ–Ω–∏–µ attention –º–µ—Ö–∞–Ω–∏–∑–º–∞")
                recommendations.extend([
                    "–ù–µ–º–µ–¥–ª–µ–Ω–Ω–æ —Å–Ω–∏–∑–∏—Ç—å learning rate –≤ 10 —Ä–∞–∑",
                    "–£–≤–µ–ª–∏—á–∏—Ç—å guided attention weight –¥–æ 20.0",
                    "–ü—Ä–æ–≤–µ—Ä–∏—Ç—å guided attention —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—é"
                ])
            
            val_loss = metrics.get('val_loss', 0)
            if val_loss > 50:
                critical_issues.append("–í–∑—Ä—ã–≤–Ω–æ–π —Ä–æ—Å—Ç validation loss")
                recommendations.extend([
                    "–û—Ç–∫–∞—Ç–∏—Ç—å—Å—è –∫ –ø—Ä–µ–¥—ã–¥—É—â–µ–º—É checkpoint",
                    "–°–Ω–∏–∑–∏—Ç—å learning rate –≤ 5 —Ä–∞–∑",
                    "–ü—Ä–æ–≤–µ—Ä–∏—Ç—å gradient clipping"
                ])
            
            quality_score = metrics.get('quality_score', 1)
            if quality_score < 0.1:
                critical_issues.append("–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏ –Ω–∏–∑–∫–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏")
                recommendations.extend([
                    "–ü—Ä–æ–≤–µ—Ä–∏—Ç—å dropout –ø–∞—Ä–∞–º–µ—Ç—Ä—ã",
                    "–£–±–µ–¥–∏—Ç—å—Å—è –≤ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ—Å—Ç–∏ loss —Ñ—É–Ω–∫—Ü–∏–π",
                    "–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –¥–∞–Ω–Ω—ã–µ –æ–±—É—á–µ–Ω–∏—è"
                ])
            
            # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ –µ—Å–ª–∏ –µ—Å—Ç—å –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ –ø—Ä–æ–±–ª–µ–º—ã
            if critical_issues:
                alert_details = {
                    'description': f"–û–±–Ω–∞—Ä—É–∂–µ–Ω–æ {len(critical_issues)} –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏—Ö –ø—Ä–æ–±–ª–µ–º –Ω–∞ —à–∞–≥–µ {step}",
                    'metrics': {
                        'attention_diagonality': f"{attention_diag:.4f}",
                        'val_loss': f"{val_loss:.4f}",
                        'quality_score': f"{quality_score:.1%}"
                    },
                    'issues': critical_issues
                }
                
                self.telegram_monitor.send_critical_alert(
                    alert_type="–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ –ø—Ä–æ–±–ª–µ–º—ã –æ–±—É—á–µ–Ω–∏—è",
                    details=alert_details,
                    recommendations=recommendations
                )
                
        except Exception as e:
            self.logger.error(f"–û—à–∏–±–∫–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–æ–≥–æ –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è: {e}")
    
    def send_milestone_achievement(self, metrics: Dict[str, float], step: int) -> None:
        """
        üèÜ –û—Ç–ø—Ä–∞–≤–ª—è–µ—Ç —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ –æ –¥–æ—Å—Ç–∏–∂–µ–Ω–∏–∏ –≤–∞–∂–Ω—ã—Ö —Ü–µ–ª–µ–π.
        """
        if not hasattr(self, 'telegram_monitor') or not self.telegram_monitor:
            return
            
        try:
            attention_diag = metrics.get('attention_diagonality', 0)
            quality_score = metrics.get('quality_score', 0)
            
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–æ—Å—Ç–∏–∂–µ–Ω–∏–π
            if attention_diag >= 0.8 and not getattr(self, '_attention_milestone_sent', False):
                achievement = {'diagonality': attention_diag}
                self.telegram_monitor.send_success_milestone(
                    milestone_type='attention_quality',
                    achievement=achievement,
                    step=step
                )
                self._attention_milestone_sent = True
            
            if quality_score >= 0.8 and not getattr(self, '_quality_milestone_sent', False):
                achievement = {'quality_score': quality_score}
                self.telegram_monitor.send_success_milestone(
                    milestone_type='quality_threshold',
                    achievement=achievement,
                    step=step
                )
                self._quality_milestone_sent = True
            
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏ –æ–±—É—á–µ–Ω–∏—è
            if len(self._recent_losses) >= 10:
                recent_std = np.std(self._recent_losses[-10:])
                if recent_std < 0.01 and not getattr(self, '_stability_milestone_sent', False):
                    achievement = {'stability_metric': recent_std}
                    self.telegram_monitor.send_success_milestone(
                        milestone_type='stable_training', 
                        achievement=achievement,
                        step=step
                    )
                    self._stability_milestone_sent = True
                    
        except Exception as e:
            self.logger.error(f"–û—à–∏–±–∫–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏ —É–≤–µ–¥–æ–º–ª–µ–Ω–∏—è –æ –¥–æ—Å—Ç–∏–∂–µ–Ω–∏–∏: {e}") 