#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Advanced Telegram Monitor –¥–ª—è Smart Tuner TTS
–°–∏—Å—Ç–µ–º–∞ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ –æ–±—É—á–µ–Ω–∏—è —Å –æ—Ç–ø—Ä–∞–≤–∫–æ–π –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π alignment –∫–∞–∂–¥—ã–µ 1000 —à–∞–≥–æ–≤
–ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å —Å–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–º–∏ —Ç–µ—Ö–Ω–∏–∫–∞–º–∏ –∫–∞—á–µ—Å—Ç–≤–∞ –∏–∑ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–π 2024-2025
"""

import os
import sys
import numpy as np
import matplotlib.pyplot as plt
import matplotlib
matplotlib.use('Agg')  # –î–ª—è —Å–µ—Ä–≤–µ—Ä–Ω–æ–π —Å—Ä–µ–¥—ã –±–µ–∑ GUI
import torch
import requests
import yaml
import logging
import io
import base64
from datetime import datetime
from typing import Dict, Any, Optional, List, Tuple
from pathlib import Path
import seaborn as sns

class AdvancedTelegramMonitor:
    """
    –ü—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–π Telegram –º–æ–Ω–∏—Ç–æ—Ä –¥–ª—è TTS –æ–±—É—á–µ–Ω–∏—è —Å attachment –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º–∏.
    
    –í–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏:
    1. –û—Ç–ø—Ä–∞–≤–∫–∞ alignment –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –∫–∞–∂–¥—ã–µ 1000 —à–∞–≥–æ–≤  
    2. –ê–Ω–∞–ª–∏–∑ –∫–∞—á–µ—Å—Ç–≤–∞ –æ–±—É—á–µ–Ω–∏—è –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏
    3. –£–≤–µ–¥–æ–º–ª–µ–Ω–∏—è –æ –ø—Ä–æ–±–ª–µ–º–∞—Ö –∫–∞—á–µ—Å—Ç–≤–∞ –Ω–∞ –ø–æ–Ω—è—Ç–Ω–æ–º —è–∑—ã–∫–µ
    4. –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ —Ñ–∞–∑–∞–º –æ–±—É—á–µ–Ω–∏—è
    5. –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –≤—Ä–µ–º–µ–Ω–∏ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è
    """
    
    def __init__(self, config_path: str = "smart_tuner/config.yaml"):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è Telegram –º–æ–Ω–∏—Ç–æ—Ä–∞."""
        with open(config_path, 'r', encoding='utf-8') as f:
            self.config = yaml.safe_load(f)
            
        self.logger = logging.getLogger(__name__)
        
        # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ Telegram –∏–∑ –∫–æ–Ω—Ñ–∏–≥–∞
        telegram_config = self.config.get('telegram', {})
        self.bot_token = telegram_config.get('bot_token')
        self.chat_id = telegram_config.get('chat_id')
        self.enabled = telegram_config.get('enabled', False)
        
        # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞
        self.notification_interval = 1000  # –ö–∞–∂–¥—ã–µ 1000 —à–∞–≥–æ–≤
        self.last_notification_step = 0
        
        # –ò—Å—Ç–æ—Ä–∏—è –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
        self.training_history = []
        self.quality_history = []
        self.phase_history = []
        
        # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
        plt.style.use('seaborn-v0_8-darkgrid')
        self.figure_size = (12, 8)
        self.dpi = 150
        
        self.logger.info(f"üöÄ Advanced Telegram Monitor –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
        
    def should_send_notification(self, current_step: int) -> bool:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, –Ω—É–∂–Ω–æ –ª–∏ –æ—Ç–ø—Ä–∞–≤–ª—è—Ç—å —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ."""
        if not self.enabled:
            return False
            
        return (current_step - self.last_notification_step) >= self.notification_interval
    
    def analyze_training_progress(self, step: int, metrics: Dict[str, Any],
                                attention_weights: Optional[torch.Tensor] = None,
                                gate_outputs: Optional[torch.Tensor] = None) -> Dict[str, Any]:
        """
        –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –ø—Ä–æ–≥—Ä–µ—Å—Å –æ–±—É—á–µ–Ω–∏—è –∏ –≥–æ—Ç–æ–≤–∏—Ç –æ—Ç—á–µ—Ç.
        """
        analysis = {
            'step': step,
            'timestamp': datetime.now(),
            'metrics': metrics,
            'quality_score': 0.0,
            'phase': self._determine_training_phase(step, metrics),
            'issues': [],
            'improvements': [],
            'time_estimate': None
        }
        
        # –ê–Ω–∞–ª–∏–∑ attention –∫–∞—á–µ—Å—Ç–≤–∞
        if attention_weights is not None:
            attention_analysis = self._analyze_attention_quality(attention_weights)
            analysis['attention_quality'] = attention_analysis
            analysis['quality_score'] += attention_analysis.get('overall_score', 0) * 0.4
        
        # –ê–Ω–∞–ª–∏–∑ gate –∫–∞—á–µ—Å—Ç–≤–∞
        if gate_outputs is not None:
            gate_analysis = self._analyze_gate_quality(gate_outputs)
            analysis['gate_quality'] = gate_analysis  
            analysis['quality_score'] += gate_analysis.get('accuracy', 0) * 0.3
        
        # –ê–Ω–∞–ª–∏–∑ loss —Ç—Ä–µ–Ω–¥–∞
        loss_analysis = self._analyze_loss_trend(metrics)
        analysis['loss_trend'] = loss_analysis
        analysis['quality_score'] += (1.0 - min(loss_analysis.get('instability', 1.0), 1.0)) * 0.3
        
        # –û–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ –ø—Ä–æ–±–ª–µ–º
        issues = self._detect_training_issues(analysis)
        analysis['issues'] = issues
        
        # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ —É–ª—É—á—à–µ–Ω–∏—é
        improvements = self._suggest_improvements(analysis)
        analysis['improvements'] = improvements
        
        # –û—Ü–µ–Ω–∫–∞ –≤—Ä–µ–º–µ–Ω–∏ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è
        time_estimate = self._estimate_completion_time(step, metrics)
        analysis['time_estimate'] = time_estimate
        
        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ –∏—Å—Ç–æ—Ä–∏—é
        self.training_history.append(analysis)
        
        return analysis
    
    def send_training_update(self, step: int, analysis: Dict[str, Any],
                           attention_weights: Optional[torch.Tensor] = None,
                           mel_outputs: Optional[torch.Tensor] = None) -> bool:
        """
        –û—Ç–ø—Ä–∞–≤–ª—è–µ—Ç –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ –æ–±—É—á–µ–Ω–∏—è –≤ Telegram —Å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º–∏.
        """
        if not self.should_send_notification(step):
            return False
        
        try:
            # –°–æ–∑–¥–∞–Ω–∏–µ –∏ –æ—Ç–ø—Ä–∞–≤–∫–∞ —Ç–µ–∫—Å—Ç–æ–≤–æ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è
            message = self._create_training_message(analysis)
            self._send_text_message(message)
            
            # –°–æ–∑–¥–∞–Ω–∏–µ –∏ –æ—Ç–ø—Ä–∞–≤–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
            if attention_weights is not None:
                attention_image = self._create_attention_plot(attention_weights, step)
                if attention_image:
                    self._send_image(attention_image, f"attention_step_{step}.png",
                                   caption=f"üéØ Attention Matrix - –®–∞–≥ {step}")
            
            # –ì—Ä–∞—Ñ–∏–∫ –º–µ—Ç—Ä–∏–∫ –æ–±—É—á–µ–Ω–∏—è
            metrics_image = self._create_metrics_plot(step)
            if metrics_image:
                self._send_image(metrics_image, f"metrics_step_{step}.png",
                               caption=f"üìä –ú–µ—Ç—Ä–∏–∫–∏ –æ–±—É—á–µ–Ω–∏—è - –®–∞–≥ {step}")
            
            # –ì—Ä–∞—Ñ–∏–∫ –∫–∞—á–µ—Å—Ç–≤–∞ –ø–æ —Ñ–∞–∑–∞–º
            if len(self.training_history) > 10:
                quality_image = self._create_quality_trend_plot(step)
                if quality_image:
                    self._send_image(quality_image, f"quality_step_{step}.png",
                                   caption=f"üìà –¢—Ä–µ–Ω–¥ –∫–∞—á–µ—Å—Ç–≤–∞ - –®–∞–≥ {step}")
            
            self.last_notification_step = step
            self.logger.info(f"‚úÖ Telegram —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–æ –¥–ª—è —à–∞–≥–∞ {step}")
            return True
            
        except Exception as e:
            self.logger.error(f"‚ùå –û—à–∏–±–∫–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏ Telegram —É–≤–µ–¥–æ–º–ª–µ–Ω–∏—è: {e}")
            return False
    
    def _create_training_message(self, analysis: Dict[str, Any]) -> str:
        """–°–æ–∑–¥–∞–µ—Ç —Ç–µ–∫—Å—Ç–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –æ —Å–æ—Å—Ç–æ—è–Ω–∏–∏ –æ–±—É—á–µ–Ω–∏—è."""
        step = analysis['step']
        phase = analysis['phase']
        quality_score = analysis['quality_score']
        
        # Emoji –¥–ª—è –∫–∞—á–µ—Å—Ç–≤–∞
        quality_emoji = "üî•" if quality_score > 0.8 else "‚úÖ" if quality_score > 0.6 else "‚ö†Ô∏è" if quality_score > 0.4 else "‚ùå"
        
        message = f"üß† *Smart Tuner V2 - –û—Ç—á–µ—Ç –æ –û–±—É—á–µ–Ω–∏–∏*\n\n"
        message += f"üìç **–®–∞–≥:** `{step:,}`\n"
        message += f"üé≠ **–§–∞–∑–∞:** `{phase}`\n"
        message += f"{quality_emoji} **–ö–∞—á–µ—Å—Ç–≤–æ:** `{quality_score:.1%}`\n\n"
        
        # –û—Å–Ω–æ–≤–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏
        metrics = analysis.get('metrics', {})
        if 'loss' in metrics:
            message += f"üìâ **Loss:** `{metrics['loss']:.4f}`\n"
        if 'attention_loss' in metrics:
            message += f"üéØ **Attention Loss:** `{metrics['attention_loss']:.4f}`\n"
        if 'gate_loss' in metrics:
            message += f"üö™ **Gate Loss:** `{metrics['gate_loss']:.4f}`\n"
        
        # –ê–Ω–∞–ª–∏–∑ attention
        attention_quality = analysis.get('attention_quality', {})
        if attention_quality:
            diagonality = attention_quality.get('diagonality_score', 0)
            message += f"\nüîç **–ê–Ω–∞–ª–∏–∑ Attention:**\n"
            message += f"  ‚Ä¢ –î–∏–∞–≥–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å: `{diagonality:.1%}`\n"
            if diagonality < 0.3:
                message += f"  ‚ö†Ô∏è *–ù–∏–∑–∫–∞—è –¥–∏–∞–≥–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å! –ù—É–∂–Ω–æ —É–ª—É—á—à–µ–Ω–∏–µ guided attention*\n"
            elif diagonality > 0.7:
                message += f"  ‚úÖ *–û—Ç–ª–∏—á–Ω–∞—è –¥–∏–∞–≥–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å!*\n"
        
        # –ü—Ä–æ–±–ª–µ–º—ã –∏ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
        issues = analysis.get('issues', [])
        if issues:
            message += f"\n‚ö†Ô∏è **–û–±–Ω–∞—Ä—É–∂–µ–Ω–Ω—ã–µ –ø—Ä–æ–±–ª–µ–º—ã:**\n"
            for issue in issues[:3]:  # –¢–æ–ø 3 –ø—Ä–æ–±–ª–µ–º—ã
                message += f"  ‚Ä¢ {issue}\n"
        
        improvements = analysis.get('improvements', [])
        if improvements:
            message += f"\nüí° **–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏:**\n"
            for improvement in improvements[:2]:  # –¢–æ–ø 2 —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
                message += f"  ‚Ä¢ {improvement}\n"
        
        # –û—Ü–µ–Ω–∫–∞ –≤—Ä–µ–º–µ–Ω–∏
        time_estimate = analysis.get('time_estimate')
        if time_estimate:
            message += f"\n‚è∞ **–û—Å—Ç–∞–ª–æ—Å—å:** `~{time_estimate}`\n"
        
        message += f"\nüïê {datetime.now().strftime('%H:%M:%S')}"
        
        return message
    
    def _create_attention_plot(self, attention_weights: torch.Tensor, step: int) -> Optional[bytes]:
        """–°–æ–∑–¥–∞–µ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ attention matrix."""
        try:
            # –ë–µ—Ä–µ–º –ø–µ—Ä–≤—ã–π —ç–ª–µ–º–µ–Ω—Ç –∏–∑ –±–∞—Ç—á–∞
            if attention_weights.dim() == 4:  # [B, heads, T_out, T_in]
                attention = attention_weights[0, 0].detach().cpu().numpy()
            elif attention_weights.dim() == 3:  # [B, T_out, T_in]
                attention = attention_weights[0].detach().cpu().numpy()
            else:
                attention = attention_weights.detach().cpu().numpy()
            
            fig, axes = plt.subplots(1, 2, figsize=(16, 6))
            
            # –û—Å–Ω–æ–≤–Ω–æ–π attention plot
            im1 = axes[0].imshow(attention.T, aspect='auto', origin='lower', 
                               cmap='Blues', interpolation='nearest')
            axes[0].set_title(f'Attention Matrix - –®–∞–≥ {step}', fontsize=14, fontweight='bold')
            axes[0].set_xlabel('Decoder Steps')
            axes[0].set_ylabel('Encoder Steps') 
            plt.colorbar(im1, ax=axes[0])
            
            # –î–∏–∞–≥–æ–Ω–∞–ª—å–Ω–∞—è –ª–∏–Ω–∏—è –¥–ª—è —Ä–µ—Ñ–µ—Ä–µ–Ω—Å–∞
            min_dim = min(attention.shape[0], attention.shape[1])
            diag_x = np.linspace(0, attention.shape[1]-1, min_dim)
            diag_y = np.linspace(0, attention.shape[0]-1, min_dim)
            axes[0].plot(diag_x, diag_y, 'r--', alpha=0.7, linewidth=2, label='Ideal Diagonal')
            axes[0].legend()
            
            # –ê–Ω–∞–ª–∏–∑ –∫–∞—á–µ—Å—Ç–≤–∞
            diagonality = self._calculate_attention_diagonality(attention)
            monotonicity = self._calculate_attention_monotonicity(attention)
            
            # –ì–∏—Å—Ç–æ–≥—Ä–∞–º–º–∞ attention values
            axes[1].hist(attention.flatten(), bins=50, alpha=0.7, color='skyblue', edgecolor='black')
            axes[1].set_title(f'Attention Values Distribution', fontsize=14, fontweight='bold')
            axes[1].set_xlabel('Attention Weight')
            axes[1].set_ylabel('Frequency')
            
            # –î–æ–±–∞–≤–ª—è–µ–º –º–µ—Ç—Ä–∏–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞
            textstr = f'–î–∏–∞–≥–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å: {diagonality:.1%}\n–ú–æ–Ω–æ—Ç–æ–Ω–Ω–æ—Å—Ç—å: {monotonicity:.1%}'
            axes[1].text(0.05, 0.95, textstr, transform=axes[1].transAxes, fontsize=12,
                        verticalalignment='top', bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.8))
            
            plt.tight_layout()
            
            # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ –±–∞–π—Ç—ã
            buffer = io.BytesIO()
            plt.savefig(buffer, format='png', dpi=self.dpi, bbox_inches='tight')
            buffer.seek(0)
            image_data = buffer.getvalue()
            plt.close(fig)
            
            return image_data
            
        except Exception as e:
            self.logger.error(f"–û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è attention plot: {e}")
            return None
    
    def _create_metrics_plot(self, step: int) -> Optional[bytes]:
        """–°–æ–∑–¥–∞–µ—Ç –≥—Ä–∞—Ñ–∏–∫ –º–µ—Ç—Ä–∏–∫ –æ–±—É—á–µ–Ω–∏—è."""
        try:
            if len(self.training_history) < 5:
                return None
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º –¥–∞–Ω–Ω—ã–µ
            steps = [h['step'] for h in self.training_history[-20:]]  # –ü–æ—Å–ª–µ–¥–Ω–∏–µ 20 —Ç–æ—á–µ–∫
            losses = [h['metrics'].get('loss', 0) for h in self.training_history[-20:]]
            quality_scores = [h['quality_score'] for h in self.training_history[-20:]]
            
            fig, (ax1, ax2) = plt.subplots(2, 1, figsize=self.figure_size, sharex=True)
            
            # –ì—Ä–∞—Ñ–∏–∫ loss
            ax1.plot(steps, losses, 'b-', linewidth=2, marker='o', markersize=4, label='Training Loss')
            ax1.set_ylabel('Loss', fontsize=12)
            ax1.set_title(f'–ü—Ä–æ–≥—Ä–µ—Å—Å –û–±—É—á–µ–Ω–∏—è - –®–∞–≥ {step}', fontsize=14, fontweight='bold')
            ax1.grid(True, alpha=0.3)
            ax1.legend()
            
            # –¢—Ä–µ–Ω–¥ loss
            if len(losses) > 3:
                z = np.polyfit(range(len(losses)), losses, 1)
                p = np.poly1d(z)
                ax1.plot(steps, p(range(len(losses))), "r--", alpha=0.8, label='Trend')
                ax1.legend()
            
            # –ì—Ä–∞—Ñ–∏–∫ –∫–∞—á–µ—Å—Ç–≤–∞
            ax2.plot(steps, quality_scores, 'g-', linewidth=2, marker='s', markersize=4, label='Quality Score')
            ax2.set_ylabel('Quality Score', fontsize=12)
            ax2.set_xlabel('Training Step', fontsize=12)
            ax2.set_ylim(0, 1)
            ax2.grid(True, alpha=0.3)
            ax2.legend()
            
            # –¶–≤–µ—Ç–æ–≤–∞—è –∑–æ–Ω–∞ –∫–∞—á–µ—Å—Ç–≤–∞
            ax2.axhspan(0.8, 1.0, alpha=0.2, color='green', label='Excellent')
            ax2.axhspan(0.6, 0.8, alpha=0.2, color='yellow', label='Good')
            ax2.axhspan(0.4, 0.6, alpha=0.2, color='orange', label='Fair')
            ax2.axhspan(0.0, 0.4, alpha=0.2, color='red', label='Poor')
            
            plt.tight_layout()
            
            # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ –±–∞–π—Ç—ã
            buffer = io.BytesIO()
            plt.savefig(buffer, format='png', dpi=self.dpi, bbox_inches='tight')
            buffer.seek(0)
            image_data = buffer.getvalue()
            plt.close(fig)
            
            return image_data
            
        except Exception as e:
            self.logger.error(f"–û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è metrics plot: {e}")
            return None
    
    def _create_quality_trend_plot(self, step: int) -> Optional[bytes]:
        """–°–æ–∑–¥–∞–µ—Ç –≥—Ä–∞—Ñ–∏–∫ —Ç—Ä–µ–Ω–¥–∞ –∫–∞—á–µ—Å—Ç–≤–∞ –ø–æ —Ñ–∞–∑–∞–º."""
        try:
            if len(self.training_history) < 10:
                return None
            
            # –ì—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∞ –ø–æ —Ñ–∞–∑–∞–º
            phases_data = {}
            for h in self.training_history:
                phase = h['phase']
                if phase not in phases_data:
                    phases_data[phase] = {'steps': [], 'quality': [], 'attention': []}
                
                phases_data[phase]['steps'].append(h['step'])
                phases_data[phase]['quality'].append(h['quality_score'])
                
                # Attention quality
                attention_quality = h.get('attention_quality', {})
                diagonality = attention_quality.get('diagonality_score', 0)
                phases_data[phase]['attention'].append(diagonality)
            
            fig, (ax1, ax2) = plt.subplots(2, 1, figsize=self.figure_size)
            
            # –ì—Ä–∞—Ñ–∏–∫ –∫–∞—á–µ—Å—Ç–≤–∞ –ø–æ —Ñ–∞–∑–∞–º
            colors = ['blue', 'green', 'orange', 'red', 'purple']
            for i, (phase, data) in enumerate(phases_data.items()):
                color = colors[i % len(colors)]
                ax1.plot(data['steps'], data['quality'], 
                        color=color, linewidth=2, marker='o', label=f'{phase}')
            
            ax1.set_ylabel('Overall Quality Score', fontsize=12)
            ax1.set_title(f'–ö–∞—á–µ—Å—Ç–≤–æ –ø–æ –§–∞–∑–∞–º –û–±—É—á–µ–Ω–∏—è - –®–∞–≥ {step}', fontsize=14, fontweight='bold')
            ax1.grid(True, alpha=0.3)
            ax1.legend()
            ax1.set_ylim(0, 1)
            
            # –ì—Ä–∞—Ñ–∏–∫ attention quality
            for i, (phase, data) in enumerate(phases_data.items()):
                color = colors[i % len(colors)]
                ax2.plot(data['steps'], data['attention'], 
                        color=color, linewidth=2, marker='s', label=f'{phase}')
            
            ax2.set_ylabel('Attention Diagonality', fontsize=12)
            ax2.set_xlabel('Training Step', fontsize=12)
            ax2.grid(True, alpha=0.3)
            ax2.legend()
            ax2.set_ylim(0, 1)
            
            # –ü–æ—Ä–æ–≥–æ–≤—ã–µ –ª–∏–Ω–∏–∏
            ax2.axhline(y=0.7, color='green', linestyle='--', alpha=0.7, label='Good Threshold')
            ax2.axhline(y=0.3, color='red', linestyle='--', alpha=0.7, label='Poor Threshold')
            
            plt.tight_layout()
            
            # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ –±–∞–π—Ç—ã
            buffer = io.BytesIO()
            plt.savefig(buffer, format='png', dpi=self.dpi, bbox_inches='tight')
            buffer.seek(0)
            image_data = buffer.getvalue()
            plt.close(fig)
            
            return image_data
            
        except Exception as e:
            self.logger.error(f"–û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è quality trend plot: {e}")
            return None
    
    def _send_text_message(self, message: str) -> bool:
        """–û—Ç–ø—Ä–∞–≤–ª—è–µ—Ç —Ç–µ–∫—Å—Ç–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –≤ Telegram."""
        url = f"https://api.telegram.org/bot{self.bot_token}/sendMessage"
        
        payload = {
            'chat_id': self.chat_id,
            'text': message,
            'parse_mode': 'Markdown',
            'disable_web_page_preview': True
        }
        
        try:
            response = requests.post(url, json=payload, timeout=10)
            response.raise_for_status()
            return True
        except Exception as e:
            self.logger.error(f"–û—à–∏–±–∫–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏ —Ç–µ–∫—Å—Ç–∞ –≤ Telegram: {e}")
            return False
    
    def _send_image(self, image_data: bytes, filename: str, caption: str = "") -> bool:
        """–û—Ç–ø—Ä–∞–≤–ª—è–µ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –≤ Telegram."""
        url = f"https://api.telegram.org/bot{self.bot_token}/sendPhoto"
        
        files = {
            'photo': (filename, image_data, 'image/png')
        }
        
        data = {
            'chat_id': self.chat_id,
            'caption': caption
        }
        
        try:
            response = requests.post(url, files=files, data=data, timeout=30)
            response.raise_for_status()
            return True
        except Exception as e:
            self.logger.error(f"–û—à–∏–±–∫–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –≤ Telegram: {e}")
            return False
    
    def _analyze_attention_quality(self, attention_weights: torch.Tensor) -> Dict[str, float]:
        """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –∫–∞—á–µ—Å—Ç–≤–æ attention."""
        # –ë–µ—Ä–µ–º –ø–µ—Ä–≤—ã–π —ç–ª–µ–º–µ–Ω—Ç –±–∞—Ç—á–∞
        if attention_weights.dim() == 4:  # [B, heads, T_out, T_in]
            attention = attention_weights[0, 0].detach().cpu().numpy()
        elif attention_weights.dim() == 3:  # [B, T_out, T_in]
            attention = attention_weights[0].detach().cpu().numpy()
        else:
            attention = attention_weights.detach().cpu().numpy()
        
        return {
            'diagonality_score': self._calculate_attention_diagonality(attention),
            'monotonicity_score': self._calculate_attention_monotonicity(attention),
            'focus_score': self._calculate_attention_focus(attention),
            'overall_score': self._calculate_overall_attention_score(attention)
        }
    
    def _calculate_attention_diagonality(self, attention_matrix: np.ndarray) -> float:
        """–í—ã—á–∏—Å–ª—è–µ—Ç –¥–∏–∞–≥–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å attention matrix."""
        try:
            T_out, T_in = attention_matrix.shape
            if T_out == 0 or T_in == 0:
                return 0.0
            
            # –°–æ–∑–¥–∞–µ–º –∏–¥–µ–∞–ª—å–Ω—É—é –¥–∏–∞–≥–æ–Ω–∞–ª—å–Ω—É—é –º–∞—Ç—Ä–∏—Ü—É
            ideal_diagonal = np.zeros_like(attention_matrix)
            min_dim = min(T_out, T_in)
            
            for i in range(min_dim):
                # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º –ø–æ–∑–∏—Ü–∏—é –Ω–∞ –¥–∏–∞–≥–æ–Ω–∞–ª–∏
                diagonal_pos = int(i * T_in / T_out) if T_out > 0 else i
                if diagonal_pos < T_in:
                    ideal_diagonal[i, diagonal_pos] = 1.0
            
            # –í—ã—á–∏—Å–ª—è–µ–º –∫–æ—Ä—Ä–µ–ª—è—Ü–∏—é —Å –∏–¥–µ–∞–ª—å–Ω–æ–π –¥–∏–∞–≥–æ–Ω–∞–ª—å—é
            attention_flat = attention_matrix.flatten()
            ideal_flat = ideal_diagonal.flatten()
            
            if np.std(attention_flat) == 0 or np.std(ideal_flat) == 0:
                return 0.0
            
            correlation = np.corrcoef(attention_flat, ideal_flat)[0, 1]
            return max(0.0, correlation) if not np.isnan(correlation) else 0.0
            
        except Exception:
            return 0.0
    
    def _calculate_attention_monotonicity(self, attention_matrix: np.ndarray) -> float:
        """–í—ã—á–∏—Å–ª—è–µ—Ç –º–æ–Ω–æ—Ç–æ–Ω–Ω–æ—Å—Ç—å attention matrix."""
        try:
            T_out, T_in = attention_matrix.shape
            if T_out <= 1:
                return 1.0
            
            # –ù–∞—Ö–æ–¥–∏–º –ø–∏–∫ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ decoder step
            peak_positions = np.argmax(attention_matrix, axis=1)
            
            # –°—á–∏—Ç–∞–µ–º –º–æ–Ω–æ—Ç–æ–Ω–Ω—ã–µ –ø–µ—Ä–µ—Ö–æ–¥—ã
            monotonic_transitions = 0
            for i in range(1, len(peak_positions)):
                if peak_positions[i] >= peak_positions[i-1]:
                    monotonic_transitions += 1
            
            return monotonic_transitions / (len(peak_positions) - 1) if len(peak_positions) > 1 else 1.0
            
        except Exception:
            return 0.0
    
    def _calculate_attention_focus(self, attention_matrix: np.ndarray) -> float:
        """–í—ã—á–∏—Å–ª—è–µ—Ç —Ñ–æ–∫—É—Å–∏—Ä–æ–≤–∫—É attention matrix."""
        try:
            # –°—Ä–µ–¥–Ω—è—è —ç–Ω—Ç—Ä–æ–ø–∏—è –ø–æ decoder steps
            entropies = []
            for i in range(attention_matrix.shape[0]):
                attention_step = attention_matrix[i]
                attention_step = attention_step + 1e-8  # –ò–∑–±–µ–≥–∞–µ–º log(0)
                entropy = -np.sum(attention_step * np.log(attention_step + 1e-8))
                entropies.append(entropy)
            
            # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º - –º–µ–Ω—å—à–µ —ç–Ω—Ç—Ä–æ–ø–∏—è = –±–æ–ª—å—à–µ —Ñ–æ–∫—É—Å
            max_entropy = np.log(attention_matrix.shape[1])
            avg_entropy = np.mean(entropies)
            focus = 1.0 - (avg_entropy / max_entropy)
            
            return max(0.0, min(1.0, focus))
            
        except Exception:
            return 0.0
    
    def _calculate_overall_attention_score(self, attention_matrix: np.ndarray) -> float:
        """–í—ã—á–∏—Å–ª—è–µ—Ç –æ–±—â–∏–π –±–∞–ª–ª –∫–∞—á–µ—Å—Ç–≤–∞ attention."""
        diagonality = self._calculate_attention_diagonality(attention_matrix)
        monotonicity = self._calculate_attention_monotonicity(attention_matrix)
        focus = self._calculate_attention_focus(attention_matrix)
        
        # –í–∑–≤–µ—à–µ–Ω–Ω–∞—è –æ—Ü–µ–Ω–∫–∞
        return (diagonality * 0.5 + monotonicity * 0.3 + focus * 0.2)
    
    def _analyze_gate_quality(self, gate_outputs: torch.Tensor) -> Dict[str, float]:
        """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –∫–∞—á–µ—Å—Ç–≤–æ gate outputs."""
        try:
            # –ë–µ—Ä–µ–º –ø–µ—Ä–≤—ã–π —ç–ª–µ–º–µ–Ω—Ç –±–∞—Ç—á–∞
            gates = gate_outputs[0].detach().cpu().numpy()
            
            # –ë–∏–Ω–∞—Ä–∏–∑—É–µ–º gate outputs
            gate_binary = (gates > 0.5).astype(float)
            
            # –ò—â–µ–º –ø–æ–∑–∏—Ü–∏—é –æ—Å—Ç–∞–Ω–æ–≤–∞
            stop_positions = np.where(gate_binary > 0.5)[0]
            
            if len(stop_positions) > 0:
                stop_position = stop_positions[0]
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ gate –æ—Å—Ç–∞–µ—Ç—Å—è –∞–∫—Ç–∏–≤–Ω—ã–º –ø–æ—Å–ª–µ –ø–µ—Ä–≤–æ–≥–æ stop
                false_stops = np.sum(gate_binary[stop_position+1:] < 0.5) if stop_position < len(gates)-1 else 0
                accuracy = 1.0 - (false_stops / max(1, len(gates) - stop_position - 1))
            else:
                accuracy = 0.0  # –ù–µ—Ç —Å–∏–≥–Ω–∞–ª–∞ –æ—Å—Ç–∞–Ω–æ–≤–∞
            
            return {
                'accuracy': accuracy,
                'stop_position': stop_positions[0] if len(stop_positions) > 0 else len(gates),
                'stability': 1.0 - np.std(gates)  # –ú–µ–Ω—å—à–µ –≤–∞—Ä–∏–∞—Ü–∏–∏ = –ª—É—á—à–µ
            }
            
        except Exception:
            return {'accuracy': 0.0, 'stop_position': 0, 'stability': 0.0}
    
    def _analyze_loss_trend(self, metrics: Dict[str, Any]) -> Dict[str, float]:
        """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Ç—Ä–µ–Ω–¥ loss."""
        if len(self.training_history) < 5:
            return {'trend': 0.0, 'instability': 0.0}
        
        recent_losses = [h['metrics'].get('loss', 0) for h in self.training_history[-10:]]
        
        # –¢—Ä–µ–Ω–¥ (–æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã–π = —É–±—ã–≤–∞–Ω–∏–µ)
        if len(recent_losses) > 1:
            trend = np.polyfit(range(len(recent_losses)), recent_losses, 1)[0]
        else:
            trend = 0.0
        
        # –ù–µ—Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å (—Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–µ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ)
        instability = np.std(recent_losses) if len(recent_losses) > 1 else 0.0
        
        return {
            'trend': trend,
            'instability': instability,
            'current_loss': recent_losses[-1] if recent_losses else 0.0
        }
    
    def _determine_training_phase(self, step: int, metrics: Dict[str, Any]) -> str:
        """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç —Ç–µ–∫—É—â—É—é —Ñ–∞–∑—É –æ–±—É—á–µ–Ω–∏—è."""
        if step < 500:
            return "pre_alignment"
        elif step < 2000:
            return "alignment_learning"
        elif step < 3000:
            return "quality_optimization"
        else:
            return "fine_tuning"
    
    def _detect_training_issues(self, analysis: Dict[str, Any]) -> List[str]:
        """–û–±–Ω–∞—Ä—É–∂–∏–≤–∞–µ—Ç –ø—Ä–æ–±–ª–µ–º—ã –≤ –æ–±—É—á–µ–Ω–∏–∏."""
        issues = []
        
        # –ü—Ä–æ–±–ª–µ–º—ã —Å attention
        attention_quality = analysis.get('attention_quality', {})
        diagonality = attention_quality.get('diagonality_score', 0)
        
        if diagonality < 0.3:
            issues.append("–û—á–µ–Ω—å –Ω–∏–∑–∫–∞—è –¥–∏–∞–≥–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å attention - –º–æ–¥–µ–ª—å –ø–ª–æ—Ö–æ –≤—ã—Ä–∞–≤–Ω–∏–≤–∞–µ—Ç —Ç–µ–∫—Å—Ç –∏ –∞—É–¥–∏–æ")
        elif diagonality < 0.5:
            issues.append("–ù–∏–∑–∫–∞—è –¥–∏–∞–≥–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å attention - –Ω—É–∂–Ω–æ —É–ª—É—á—à–∏—Ç—å guided attention")
        
        # –ü—Ä–æ–±–ª–µ–º—ã —Å gate
        gate_quality = analysis.get('gate_quality', {})
        gate_accuracy = gate_quality.get('accuracy', 0)
        
        if gate_accuracy < 0.5:
            issues.append("–ù–∏–∑–∫–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å gate - –º–æ–¥–µ–ª—å –Ω–µ —É–º–µ–µ—Ç –æ–ø—Ä–µ–¥–µ–ª—è—Ç—å –∫–æ–Ω–µ—Ü –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è")
        
        # –ü—Ä–æ–±–ª–µ–º—ã —Å loss
        loss_trend = analysis.get('loss_trend', {})
        if loss_trend.get('trend', 0) > 0:
            issues.append("Loss —Ä–∞—Å—Ç–µ—Ç - –≤–æ–∑–º–æ–∂–Ω–æ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ –∏–ª–∏ —Å–ª–∏—à–∫–æ–º –≤—ã—Å–æ–∫–∏–π learning rate")
        
        if loss_trend.get('instability', 0) > 0.1:
            issues.append("–ù–µ—Å—Ç–∞–±–∏–ª—å–Ω—ã–π loss - —Ä–∞—Å—Å–º–æ—Ç—Ä–∏—Ç–µ —Å–Ω–∏–∂–µ–Ω–∏–µ learning rate")
        
        # –û–±—â–∏–µ –ø—Ä–æ–±–ª–µ–º—ã –∫–∞—á–µ—Å—Ç–≤–∞
        if analysis['quality_score'] < 0.4:
            issues.append("–û–±—â–µ–µ –∫–∞—á–µ—Å—Ç–≤–æ –Ω–∏–∑–∫–æ–µ - –Ω—É–∂–Ω—ã —Å—Ä–æ—á–Ω—ã–µ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è")
        
        return issues
    
    def _suggest_improvements(self, analysis: Dict[str, Any]) -> List[str]:
        """–ü—Ä–µ–¥–ª–∞–≥–∞–µ—Ç —É–ª—É—á—à–µ–Ω–∏—è."""
        improvements = []
        
        phase = analysis.get('phase', '')
        attention_quality = analysis.get('attention_quality', {})
        diagonality = attention_quality.get('diagonality_score', 0)
        
        if diagonality < 0.5:
            if phase == "pre_alignment":
                improvements.append("–£–≤–µ–ª–∏—á–∏—Ç—å –≤–µ—Å guided attention loss –¥–æ 10.0")
            else:
                improvements.append("–°–Ω–∏–∑–∏—Ç—å learning rate –∏ —É—Å–∏–ª–∏—Ç—å guided attention")
        
        gate_quality = analysis.get('gate_quality', {})
        if gate_quality.get('accuracy', 0) < 0.7:
            improvements.append("–ù–∞—Å—Ç—Ä–æ–∏—Ç—å –∞–¥–∞–ø—Ç–∏–≤–Ω—ã–π gate threshold (0.3‚Üí0.8)")
        
        loss_trend = analysis.get('loss_trend', {})
        if loss_trend.get('instability', 0) > 0.1:
            improvements.append("–°–Ω–∏–∑–∏—Ç—å learning rate –∏–ª–∏ —É–≤–µ–ª–∏—á–∏—Ç—å batch size")
        
        if analysis['quality_score'] < 0.6:
            improvements.append("–í–∫–ª—é—á–∏—Ç—å curriculum learning –¥–ª—è teacher forcing")
        
        return improvements
    
    def _estimate_completion_time(self, current_step: int, metrics: Dict[str, Any]) -> Optional[str]:
        """–û—Ü–µ–Ω–∏–≤–∞–µ—Ç –≤—Ä–µ–º—è –¥–æ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –æ–±—É—á–µ–Ω–∏—è."""
        try:
            if len(self.training_history) < 3:
                return None
            
            # –ü—Ä–æ—Å—Ç–∞—è –æ—Ü–µ–Ω–∫–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø—Ä–æ–≥—Ä–µ—Å—Å–∞
            target_steps = 10000  # –ü—Ä–∏–º–µ—Ä–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —à–∞–≥–æ–≤ –¥–ª—è —Ö–æ—Ä–æ—à–µ–≥–æ –∫–∞—á–µ—Å—Ç–≤–∞
            remaining_steps = max(0, target_steps - current_step)
            
            # –°–∫–æ—Ä–æ—Å—Ç—å –æ–±—É—á–µ–Ω–∏—è (—à–∞–≥–æ–≤ –≤ —á–∞—Å)
            time_deltas = []
            for i in range(1, min(len(self.training_history), 10)):
                prev_time = self.training_history[-i-1]['timestamp']
                curr_time = self.training_history[-i]['timestamp']
                time_delta = (curr_time - prev_time).total_seconds() / 3600  # —á–∞—Å—ã
                time_deltas.append(time_delta)
            
            if time_deltas:
                avg_time_per_interval = np.mean(time_deltas)
                steps_per_interval = self.notification_interval
                steps_per_hour = steps_per_interval / avg_time_per_interval if avg_time_per_interval > 0 else 0
                
                if steps_per_hour > 0:
                    hours_remaining = remaining_steps / steps_per_hour
                    if hours_remaining < 24:
                        return f"{hours_remaining:.1f} —á–∞—Å–æ–≤"
                    else:
                        return f"{hours_remaining/24:.1f} –¥–Ω–µ–π"
            
            return None
            
        except Exception:
            return None

    def send_training_complete_summary(self, final_analysis: Dict[str, Any]) -> bool:
        """–û—Ç–ø—Ä–∞–≤–ª—è–µ—Ç –∏—Ç–æ–≥–æ–≤—ã–π –æ—Ç—á–µ—Ç –æ –∑–∞–≤–µ—Ä—à–µ–Ω–∏–∏ –æ–±—É—á–µ–Ω–∏—è."""
        try:
            step = final_analysis['step']
            quality_score = final_analysis['quality_score']
            
            message = f"üéâ *–û–±—É—á–µ–Ω–∏–µ –ó–∞–≤–µ—Ä—à–µ–Ω–æ!*\n\n"
            message += f"üìç **–§–∏–Ω–∞–ª—å–Ω—ã–π —à–∞–≥:** `{step:,}`\n"
            message += f"üèÜ **–ò—Ç–æ–≥–æ–≤–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ:** `{quality_score:.1%}`\n\n"
            
            # –ò—Ç–æ–≥–æ–≤–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
            if len(self.training_history) > 0:
                total_time = (self.training_history[-1]['timestamp'] - self.training_history[0]['timestamp']).total_seconds() / 3600
                message += f"‚è±Ô∏è **–û–±—â–µ–µ –≤—Ä–µ–º—è:** `{total_time:.1f} —á–∞—Å–æ–≤`\n"
                
                # –õ—É—á—à–µ–µ –∫–∞—á–µ—Å—Ç–≤–æ
                best_quality = max(h['quality_score'] for h in self.training_history)
                message += f"üéØ **–õ—É—á—à–µ–µ –∫–∞—á–µ—Å—Ç–≤–æ:** `{best_quality:.1%}`\n"
            
            # –§–∏–Ω–∞–ª—å–Ω—ã–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
            message += f"\nüí° **–°–ª–µ–¥—É—é—â–∏–µ —à–∞–≥–∏:**\n"
            if quality_score > 0.8:
                message += f"  ‚úÖ –ú–æ–¥–µ–ª—å –≥–æ—Ç–æ–≤–∞ –∫ –ø—Ä–æ–¥–∞–∫—à–µ–Ω—É!\n"
                message += f"  üé§ –ü—Ä–æ–≤–µ–¥–∏—Ç–µ —Ñ–∏–Ω–∞–ª—å–Ω–æ–µ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ\n"
            elif quality_score > 0.6:
                message += f"  üìà –•–æ—Ä–æ—à–µ–µ –∫–∞—á–µ—Å—Ç–≤–æ, –º–æ–∂–Ω–æ –¥–æ–æ–±—É—á–∏—Ç—å\n"
                message += f"  üîß –†–∞—Å—Å–º–æ—Ç—Ä–∏—Ç–µ fine-tuning\n"
            else:
                message += f"  ‚ö†Ô∏è –¢—Ä–µ–±—É–µ—Ç—Å—è –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ\n"
                message += f"  üîß –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä—ã\n"
            
            return self._send_text_message(message)
            
        except Exception as e:
            self.logger.error(f"–û—à–∏–±–∫–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏ –∏—Ç–æ–≥–æ–≤–æ–≥–æ –æ—Ç—á–µ—Ç–∞: {e}")
            return False 