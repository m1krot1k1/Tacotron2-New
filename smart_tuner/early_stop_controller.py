"""
Early Stop Controller –¥–ª—è Smart Tuner V2
–ò–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω—ã–π –∫–æ–Ω—Ç—Ä–æ–ª—å —Ä–∞–Ω–Ω–µ–≥–æ –æ—Å—Ç–∞–Ω–æ–≤–∞ –∏ –ø—Ä–æ–∞–∫—Ç–∏–≤–Ω–æ–µ –≤–º–µ—à–∞—Ç–µ–ª—å—Å—Ç–≤–æ –≤ –æ–±—É—á–µ–Ω–∏–µ.
–¢–µ–ø–µ—Ä—å —Å –∞–¥–∞–ø—Ç–∏–≤–Ω—ã–º —Å–æ–≤–µ—Ç–Ω–∏–∫–æ–º –Ω–∞ –æ—Å–Ω–æ–≤–µ –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π –∏ TTS-—Å–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã–º–∏ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—è–º–∏.
"""

import yaml
import logging
import numpy as np
from typing import Dict, Any, List, Tuple, Optional
import sqlite3
import json
import os

# –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ —Ç–æ–ª—å–∫–æ –¥–ª—è –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏ –≤–∞–∂–Ω—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π
logging.basicConfig(level=logging.WARNING, format='%(asctime)s - [%(levelname)s] - (EarlyStopController) - %(message)s')

class EarlyStopController:
    """
    –£—Å–æ–≤–µ—Ä—à–µ–Ω—Å—Ç–≤–æ–≤–∞–Ω–Ω—ã–π –∫–æ–Ω—Ç—Ä–æ–ª–ª–µ—Ä –¥–ª—è TTS, –∫–æ—Ç–æ—Ä—ã–π —Å–æ–≤–º–µ—â–∞–µ—Ç:
    1. –ü—Ä–æ–∞–∫—Ç–∏–≤–Ω—ã–µ –º–µ—Ä—ã: –ø—ã—Ç–∞–µ—Ç—Å—è "–≤—ã–ª–µ—á–∏—Ç—å" –æ–±—É—á–µ–Ω–∏–µ, –µ—Å–ª–∏ –æ–Ω–æ –∏–¥–µ—Ç –Ω–µ —Ç–∞–∫.
    2. –†–∞–Ω–Ω–∏–π –æ—Å—Ç–∞–Ω–æ–≤: –æ—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç –±–µ–∑–Ω–∞–¥–µ–∂–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ –¥–ª—è —ç–∫–æ–Ω–æ–º–∏–∏ —Ä–µ—Å—É—Ä—Å–æ–≤.
    3. –ê–¥–∞–ø—Ç–∏–≤–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ: –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –±–∞–∑—É –∑–Ω–∞–Ω–∏–π –¥–ª—è –ø—Ä–∏–Ω—è—Ç–∏—è –±–æ–ª–µ–µ —É–º–Ω—ã—Ö —Ä–µ—à–µ–Ω–∏–π —Å–æ –≤—Ä–µ–º–µ–Ω–µ–º.
    4. TTS-—Å–ø–µ—Ü–∏—Ñ–∏—á–Ω–∞—è –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞: –ø–æ–Ω–∏–º–∞–µ—Ç –æ—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏ –æ–±—É—á–µ–Ω–∏—è Tacotron2.
    5. –§–∞–∑–æ–≤–æ–µ –æ–±—É—á–µ–Ω–∏–µ: –∞–¥–∞–ø—Ç–∏—Ä—É–µ—Ç—Å—è –∫ —Ä–∞–∑–ª–∏—á–Ω—ã–º —Ñ–∞–∑–∞–º –æ–±—É—á–µ–Ω–∏—è TTS –º–æ–¥–µ–ª–∏.
    """
    
    def __init__(self, config_path: str = "smart_tuner/config.yaml"):
        with open(config_path, 'r') as f:
            self.config = yaml.safe_load(f)
        
        self.advisor_config = self.config.get('adaptive_advisor', {})
        self.db_path = self.advisor_config.get('db_path', 'smart_tuner/advisor_kb.db')
        
        self.metrics_history = []
        self.last_action_step = 0
        self.last_action_info = {}
        
        # TTS-—Å–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏
        self.tts_phase_config = self.config.get('tts_phase_training', {})
        self.tts_metrics_config = self.config.get('tts_metrics', {})
        self.current_phase = "pre_alignment"  # –ù–∞—á–∞–ª—å–Ω–∞—è —Ñ–∞–∑–∞
        self.phase_start_step = 0

        # –°–æ–∑–¥–∞–µ–º "–ø—É—Å—Ç–æ–π" –ª–æ–≥–≥–µ—Ä, –∫–æ—Ç–æ—Ä—ã–π –Ω–∏—á–µ–≥–æ –Ω–µ –¥–µ–ª–∞–µ—Ç
        class DummyLogger:
            def info(self, *args, **kwargs): pass
            def debug(self, *args, **kwargs): pass
            def warning(self, *args, **kwargs): pass
            def error(self, *args, **kwargs): pass
            def critical(self, *args, **kwargs): pass
        
        self.logger = DummyLogger()
        self._init_kb()

    def _init_kb(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ—Ç –±–∞–∑—É –∑–Ω–∞–Ω–∏–π (SQLite) —Å TTS-—Å–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã–º–∏ –ø–æ–ª—è–º–∏."""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            # –°–æ–∑–¥–∞–µ–º —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—É—é —Ç–∞–±–ª–∏—Ü—É –¥–ª—è TTS
            cursor.execute('''
            CREATE TABLE IF NOT EXISTS knowledge_base (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                timestamp DATETIME DEFAULT CURRENT_TIMESTAMP,
                problem_context TEXT NOT NULL,
                action_taken TEXT NOT NULL,
                outcome_metrics TEXT,
                reward REAL,
                tts_phase TEXT,
                attention_score REAL,
                gate_accuracy REAL,
                mel_quality REAL
            )
            ''')
            conn.commit()
            conn.close()
            self.logger.info(f"TTS-—Å–ø–µ—Ü–∏—Ñ–∏—á–Ω–∞—è –±–∞–∑–∞ –∑–Ω–∞–Ω–∏–π –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞: {self.db_path}")
        except Exception as e:
            self.logger.error(f"–ù–µ —É–¥–∞–ª–æ—Å—å –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –±–∞–∑—É –∑–Ω–∞–Ω–∏–π: {e}")

    def add_metrics(self, metrics: Dict[str, float]):
        """–î–æ–±–∞–≤–ª—è–µ—Ç –Ω–æ–≤—ã–π –Ω–∞–±–æ—Ä –º–µ—Ç—Ä–∏–∫ –≤ –∏—Å—Ç–æ—Ä–∏—é —Å TTS-—Å–ø–µ—Ü–∏—Ñ–∏—á–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–æ–π."""
        # –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏ –¥–ª—è –±–∞–∑–æ–≤–æ–π —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏
        required_base_metrics = ['train_loss', 'val_loss', 'grad_norm']
        
        # TTS-—Å–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–µ)
        tts_metrics = [
            'attention_alignment_score', 'gate_accuracy', 'mel_quality_score',
            'attention_entropy', 'gate_precision', 'gate_recall'
        ]
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –±–∞–∑–æ–≤—ã—Ö –º–µ—Ç—Ä–∏–∫
        if all(k in metrics for k in required_base_metrics):
            # –û–±–æ–≥–∞—â–∞–µ–º –º–µ—Ç—Ä–∏–∫–∏ TTS-—Å–ø–µ—Ü–∏—Ñ–∏—á–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π
            enriched_metrics = metrics.copy()
            enriched_metrics['step'] = len(self.metrics_history)
            enriched_metrics['tts_phase'] = self._determine_training_phase(enriched_metrics)
            
            self.metrics_history.append(enriched_metrics)
            self._update_current_phase(enriched_metrics)
            
            self.logger.debug(f"–î–æ–±–∞–≤–ª–µ–Ω—ã –º–µ—Ç—Ä–∏–∫–∏ –¥–ª—è —à–∞–≥–∞ {enriched_metrics['step']}, —Ñ–∞–∑–∞: {enriched_metrics['tts_phase']}")
    
    def _determine_training_phase(self, metrics: Dict[str, float]) -> str:
        """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç —Ç–µ–∫—É—â—É—é —Ñ–∞–∑—É –æ–±—É—á–µ–Ω–∏—è TTS –Ω–∞ –æ—Å–Ω–æ–≤–µ –º–µ—Ç—Ä–∏–∫."""
        if not self.tts_phase_config.get('enabled', False):
            return "standard"
            
        current_step = metrics.get('step', len(self.metrics_history))
        phases = self.tts_phase_config.get('phases', {})
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–µ—Ä–µ—Ö–æ–¥ –º–µ–∂–¥—É —Ñ–∞–∑–∞–º–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ –º–µ—Ç—Ä–∏–∫
        attention_score = metrics.get('attention_alignment_score', 0.0)
        gate_accuracy = metrics.get('gate_accuracy', 0.0)
        
        if current_step < 50 or attention_score < 0.5:
            return "pre_alignment"
        elif attention_score >= 0.5 and attention_score < 0.8:
            return "alignment_learning"  
        elif attention_score >= 0.8 and gate_accuracy >= 0.7:
            return "fine_tuning"
        else:
            return "alignment_learning"  # –§–∞–∑–∞ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
    
    def _update_current_phase(self, metrics: Dict[str, float], telegram_monitor=None):
        """–û–±–Ω–æ–≤–ª—è–µ—Ç —Ç–µ–∫—É—â—É—é —Ñ–∞–∑—É –æ–±—É—á–µ–Ω–∏—è –∏ –ª–æ–≥–∏—Ä—É–µ—Ç –ø–µ—Ä–µ—Ö–æ–¥—ã."""
        new_phase = metrics.get('tts_phase', self.current_phase)
        if new_phase != self.current_phase:
            old_phase = self.current_phase
            self.logger.info(f"üîÑ –ü–µ—Ä–µ—Ö–æ–¥ —Ñ–∞–∑—ã –æ–±—É—á–µ–Ω–∏—è: {old_phase} ‚Üí {new_phase}")
            self.current_phase = new_phase
            self.phase_start_step = metrics.get('step', len(self.metrics_history))
            
            # üì± –û—Ç–ø—Ä–∞–≤–ª—è–µ–º Telegram —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ –æ —Å–º–µ–Ω–µ —Ñ–∞–∑—ã
            if telegram_monitor:
                step = metrics.get('step', len(self.metrics_history))
                
                # –§–æ—Ä–º–∏—Ä—É–µ–º –¥–æ—Å—Ç–∏–∂–µ–Ω–∏—è –ø—Ä–µ–¥—ã–¥—É—â–µ–π —Ñ–∞–∑—ã
                achievements = []
                if old_phase == 'pre_alignment' and new_phase == 'alignment_learning':
                    achievements.append("–ë–∞–∑–æ–≤–∞—è –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è attention –∑–∞–≤–µ—Ä—à–µ–Ω–∞")
                elif old_phase == 'alignment_learning' and new_phase == 'quality_optimization':
                    achievements.append(f"–î–∏–∞–≥–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å attention –¥–æ—Å—Ç–∏–≥–ª–∞ {metrics.get('attention_diagonality', 0):.1%}")
                    achievements.append("–í—ã—Ä–∞–≤–Ω–∏–≤–∞–Ω–∏–µ —Ç–µ–∫—Å—Ç-–∞—É–¥–∏–æ —Å—Ç–∞–±–∏–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–æ")
                elif old_phase == 'quality_optimization' and new_phase == 'fine_tuning':
                    achievements.append(f"–¢–æ—á–Ω–æ—Å—Ç—å gate –¥–æ—Å—Ç–∏–≥–ª–∞ {metrics.get('gate_accuracy', 0):.1%}")
                    achievements.append("–ö–∞—á–µ—Å—Ç–≤–æ mel-—Å–ø–µ–∫—Ç—Ä–æ–≥—Ä–∞–º–º –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–æ")
                
                try:
                    telegram_monitor.send_training_phase_notification(
                        old_phase=old_phase,
                        new_phase=new_phase,
                        step=step,
                        achievements=achievements
                    )
                except Exception as e:
                    self.logger.warning(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –æ—Ç–ø—Ä–∞–≤–∏—Ç—å —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ –æ —Å–º–µ–Ω–µ —Ñ–∞–∑—ã: {e}")

    def decide_next_step(self, current_hparams: Dict[str, Any]) -> Dict[str, Any]:
        """
        –ì–ª–∞–≤–Ω—ã–π –º–µ—Ç–æ–¥ –¥–ª—è TTS-–æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –ø—Ä–∏–Ω—è—Ç–∏—è —Ä–µ—à–µ–Ω–∏–π.
        """
        current_step = len(self.metrics_history)
        min_history = self.advisor_config.get('min_history_for_decision', 200)
        
        if current_step < min_history:
            return {'action': 'continue', 'reason': f'–ù–∞–∫–æ–ø–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è TTS –∞–Ω–∞–ª–∏–∑–∞ ({current_step}/{min_history})'}
        
        # 1. –û—Ü–µ–Ω–∫–∞ –ø—Ä–µ–¥—ã–¥—É—â–µ–≥–æ –¥–µ–π—Å—Ç–≤–∏—è
        evaluation_window = self.advisor_config.get('evaluation_window', 100)
        if self.last_action_step > 0 and (current_step - self.last_action_step) >= evaluation_window:
            self._evaluate_last_action_tts()

        # 2. TTS-—Å–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –ø—Ä–æ–±–ª–µ–º
        if self.last_action_step == 0:
            problem_context = self._diagnose_tts_problems()
            if problem_context:
                # 3. –ü–æ–ª—É—á–µ–Ω–∏–µ –ª—É—á—à–µ–≥–æ –¥–µ–π—Å—Ç–≤–∏—è —Å —É—á–µ—Ç–æ–º TTS —Ñ–∞–∑—ã
                recommended_action = self._get_best_tts_action(problem_context)
                
                if recommended_action and recommended_action.get('name') != 'continue':
                    # 4. –ü—Ä–∏–º–µ–Ω—è–µ–º TTS-—Å–ø–µ—Ü–∏—Ñ–∏—á–Ω–æ–µ –¥–µ–π—Å—Ç–≤–∏–µ
                    self.last_action_step = current_step
                    self.last_action_info = {
                        "context": problem_context,
                        "action": recommended_action,
                        "start_metrics": self.metrics_history[-1],
                        "tts_phase": self.current_phase
                    }
                    
                    db_id = self._log_tts_event_to_kb(problem_context, recommended_action)
                    self.last_action_info['db_id'] = db_id

                    return self._create_tts_response_from_action(recommended_action, current_hparams)

        return {'action': 'continue', 'reason': f'TTS –æ–±—É—á–µ–Ω–∏–µ —Å—Ç–∞–±–∏–ª—å–Ω–æ –≤ —Ñ–∞–∑–µ {self.current_phase}'}
    
    def _diagnose_tts_problems(self) -> Optional[Dict[str, Any]]:
        """
        TTS-—Å–ø–µ—Ü–∏—Ñ–∏—á–Ω–∞—è –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ –ø—Ä–æ–±–ª–µ–º —Å —É—á–µ—Ç–æ–º —Ñ–∞–∑—ã –æ–±—É—á–µ–Ω–∏—è.
        """
        conf = self.advisor_config.get('diagnostics', {})
        history_len = len(self.metrics_history)
        last_metrics = self.metrics_history[-1]
        current_phase = last_metrics.get('tts_phase', self.current_phase)

        # –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç 1: –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ –ø—Ä–æ–±–ª–µ–º—ã TTS
        
        # –í–∑—Ä—ã–≤ –≥—Ä–∞–¥–∏–µ–Ω—Ç–æ–≤ (–æ—Å–æ–±–µ–Ω–Ω–æ –∫—Ä–∏—Ç–∏—á–Ω–æ –¥–ª—è TTS)
        instability_conf = conf.get('instability', {})
        grad_threshold = instability_conf.get('grad_norm_threshold', 200.0)
        if last_metrics['grad_norm'] > grad_threshold:
            self.logger.warning(f"üö® TTS –Ω–µ—Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å: grad_norm={last_metrics['grad_norm']:.2f} > {grad_threshold}")
            return {
                "problem_type": "instability", 
                "grad_norm": last_metrics['grad_norm'],
                "tts_phase": current_phase,
                "severity": "critical"
            }

        # Attention failure (—Å–ø–µ—Ü–∏—Ñ–∏—á–Ω–æ –¥–ª—è TTS)
        attention_failure_conf = conf.get('attention_failure', {})
        if 'attention_alignment_score' in last_metrics:
            min_alignment = attention_failure_conf.get('min_alignment_score', 0.7)
            if last_metrics['attention_alignment_score'] < min_alignment and current_phase != "pre_alignment":
                self.logger.warning(f"üéØ TTS attention failure: score={last_metrics['attention_alignment_score']:.3f} < {min_alignment}")
                return {
                    "problem_type": "attention_failure",
                    "attention_score": last_metrics['attention_alignment_score'],
                    "tts_phase": current_phase,
                    "severity": "high"
                }

        # Gate collapse (—Å–ø–µ—Ü–∏—Ñ–∏—á–Ω–æ –¥–ª—è TTS)
        gate_collapse_conf = conf.get('gate_collapse', {})
        if 'gate_accuracy' in last_metrics:
            min_gate_acc = gate_collapse_conf.get('min_gate_accuracy', 0.8)
            if last_metrics['gate_accuracy'] < min_gate_acc and current_phase == "fine_tuning":
                self.logger.warning(f"üö™ TTS gate collapse: accuracy={last_metrics['gate_accuracy']:.3f} < {min_gate_acc}")
                return {
                    "problem_type": "gate_collapse",
                    "gate_accuracy": last_metrics['gate_accuracy'],
                    "tts_phase": current_phase,
                    "severity": "high"
                }

        # –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç 2: –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–µ –ø—Ä–æ–±–ª–µ–º—ã —Å TTS-–∞–¥–∞–ø—Ç–∞—Ü–∏–µ–π

        # –ü–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ (—Å —É—á–µ—Ç–æ–º TTS —Å–ø–µ—Ü–∏—Ñ–∏–∫–∏)
        overfitting_conf = conf.get('overfitting', {})
        window = overfitting_conf.get('window_size', 50)
        if history_len >= window:
            overfitting_gap = last_metrics['val_loss'] - last_metrics['train_loss']
            threshold = overfitting_conf.get('threshold', 5.0)
            if overfitting_gap > threshold:
                past_gaps = [m['val_loss'] - m['train_loss'] for m in self.metrics_history[-window:]]
                if len(past_gaps) > 10 and all(g1 <= g2 for g1, g2 in zip(past_gaps[-10:-5], past_gaps[-5:])):
                    self.logger.warning(f"üìà TTS –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ: gap={overfitting_gap:.3f} > {threshold}")
                    return {
                        "problem_type": "overfitting", 
                        "gap": overfitting_gap,
                        "tts_phase": current_phase,
                        "severity": "medium"
                    }
        
        # –°—Ç–∞–≥–Ω–∞—Ü–∏—è (—Å TTS-–∞–¥–∞–ø—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–º–∏ –ø–æ—Ä–æ–≥–∞–º–∏)
        stagnation_conf = conf.get('stagnation', {})
        window = stagnation_conf.get('window_size', 150)
        if history_len >= window:
            recent_val_losses = [m['val_loss'] for m in self.metrics_history[-window:]]
            improvement = recent_val_losses[0] - recent_val_losses[-1]
            min_delta = stagnation_conf.get('min_delta', 0.0005)
            
            if improvement < min_delta:
                self.logger.warning(f"üìä TTS —Å—Ç–∞–≥–Ω–∞—Ü–∏—è: improvement={improvement:.5f} < {min_delta}")
                return {
                    "problem_type": "stagnation", 
                    "improvement": improvement,
                    "tts_phase": current_phase,
                    "severity": "low"
                }
        
        return None

    def _get_best_tts_action(self, context: Dict) -> Dict[str, Any]:
        """
        –ü–æ–ª—É—á–∞–µ—Ç –ª—É—á—à–µ–µ –¥–µ–π—Å—Ç–≤–∏–µ –¥–ª—è TTS —Å —É—á–µ—Ç–æ–º —Ñ–∞–∑—ã –æ–±—É—á–µ–Ω–∏—è –∏ –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–æ–≥–æ –æ–ø—ã—Ç–∞.
        """
        problem_type = context.get("problem_type")
        tts_phase = context.get("tts_phase", self.current_phase)
        
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            # –ò—â–µ–º —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ –¥–µ–π—Å—Ç–≤–∏—è —Å —É—á–µ—Ç–æ–º TTS —Ñ–∞–∑—ã
            cursor.execute("""
                SELECT action_taken, reward, attention_score, gate_accuracy FROM knowledge_base
                WHERE json_extract(problem_context, '$.problem_type') = ? 
                AND (tts_phase = ? OR tts_phase IS NULL)
                AND reward IS NOT NULL
                ORDER BY reward DESC
            """, (problem_type, tts_phase))
            
            records = cursor.fetchall()
            conn.close()

            if not records:
                self.logger.warning(f"–î–ª—è TTS –ø—Ä–æ–±–ª–µ–º—ã '{problem_type}' –≤ —Ñ–∞–∑–µ '{tts_phase}' –Ω–µ—Ç –æ–ø—ã—Ç–∞. –ò—Å–ø–æ–ª—å–∑—É—é –¥–µ–π—Å—Ç–≤–∏–µ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é.")
                return self._get_default_tts_action(problem_type, tts_phase)

            # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –ª—É—á—à–∏–µ –¥–µ–π—Å—Ç–≤–∏—è –¥–ª—è —Ç–µ–∫—É—â–µ–π TTS —Ñ–∞–∑—ã
            action_scores = {}
            for action_str, reward, att_score, gate_acc in records:
                action = json.loads(action_str)
                action_name = action['name']
                
                # –ë–æ–Ω—É—Å –∑–∞ TTS-—Å–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã–µ —É–ª—É—á—à–µ–Ω–∏—è
                tts_bonus = 0.0
                if att_score and att_score > 0.8:
                    tts_bonus += 0.1
                if gate_acc and gate_acc > 0.85:
                    tts_bonus += 0.1
                    
                adjusted_reward = reward + tts_bonus
                
                if action_name not in action_scores:
                    action_scores[action_name] = []
                action_scores[action_name].append(adjusted_reward)
            
            # –ù–∞—Ö–æ–¥–∏–º –ª—É—á—à–µ–µ –¥–µ–π—Å—Ç–≤–∏–µ
            best_action_name = None
            max_avg_reward = -float('inf')
            
            for action_name, rewards in action_scores.items():
                avg_reward = sum(rewards) / len(rewards)
                self.logger.info(f"TTS –∞–Ω–∞–ª–∏–∑ –¥–ª—è '{problem_type}' –≤ —Ñ–∞–∑–µ '{tts_phase}': '{action_name}' –Ω–∞–≥—Ä–∞–¥–∞ {avg_reward:.4f}")
                if avg_reward > max_avg_reward:
                    max_avg_reward = avg_reward
                    best_action_name = action_name
            
            min_reward_threshold = self.advisor_config.get('min_reward_threshold', -0.1)
            if max_avg_reward < min_reward_threshold:
                self.logger.warning(f"–õ—É—á—à–µ–µ TTS –¥–µ–π—Å—Ç–≤–∏–µ '{best_action_name}' –∏–º–µ–µ—Ç –Ω–∏–∑–∫—É—é –Ω–∞–≥—Ä–∞–¥—É {max_avg_reward:.4f}. –ü—Ä–æ–ø—É—Å–∫–∞—é.")
                return {'name': 'continue'}

            # –ó–∞–≥—Ä—É–∂–∞–µ–º –ø–æ–ª–Ω–æ–µ TTS –¥–µ–π—Å—Ç–≤–∏–µ
            return self._get_default_tts_action(problem_type, tts_phase, preferred_action=best_action_name)
            
        except Exception as e:
            self.logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–∏—Å–∫–µ TTS –¥–µ–π—Å—Ç–≤–∏—è: {e}")
            return self._get_default_tts_action(problem_type, tts_phase)

    def _get_default_tts_action(self, problem_type: str, tts_phase: str = None, preferred_action: str = None) -> Dict[str, Any]:
        """
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç TTS-—Å–ø–µ—Ü–∏—Ñ–∏—á–Ω–æ–µ –¥–µ–π—Å—Ç–≤–∏–µ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é —Å —É—á–µ—Ç–æ–º —Ñ–∞–∑—ã –æ–±—É—á–µ–Ω–∏—è.
        """
        default_actions = self.advisor_config.get('default_actions', {})
        
        if problem_type in default_actions:
            action = default_actions[problem_type].copy()
            
            # –ê–¥–∞–ø—Ç–∏—Ä—É–µ–º –¥–µ–π—Å—Ç–≤–∏–µ –∫ TTS —Ñ–∞–∑–µ
            if tts_phase and 'params' in action:
                phase_configs = self.tts_phase_config.get('phases', {})
                if tts_phase in phase_configs:
                    phase_config = phase_configs[tts_phase]
                    
                    # –ö–æ—Ä—Ä–µ–∫—Ç–∏—Ä—É–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ñ–∞–∑—ã
                    if 'learning_rate_multiplier' in action['params'] and 'learning_rate_multiplier' in phase_config:
                        action['params']['learning_rate_multiplier'] *= phase_config['learning_rate_multiplier']
                    
                    if 'guided_attention_weight' in phase_config:
                        action['params']['guided_attention_weight'] = phase_config['guided_attention_weight']
            
            self.logger.info(f"–ò—Å–ø–æ–ª—å–∑—É—é TTS –¥–µ–π—Å—Ç–≤–∏–µ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –¥–ª—è '{problem_type}' –≤ —Ñ–∞–∑–µ '{tts_phase}': {action['name']}")
            return action
        
        self.logger.warning(f"–ù–µ—Ç TTS –¥–µ–π—Å—Ç–≤–∏—è –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –¥–ª—è '{problem_type}'")
        return {'name': 'continue'}

    def _evaluate_last_action_tts(self):
        """
        –û—Ü–µ–Ω–∏–≤–∞–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ –¥–µ–π—Å—Ç–≤–∏—è —Å —É—á–µ—Ç–æ–º TTS-—Å–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã—Ö –º–µ—Ç—Ä–∏–∫.
        """
        if not self.last_action_info:
            return

        try:
            current_step = len(self.metrics_history)
            start_step = self.last_action_step
            evaluation_window = min(50, current_step - start_step)
            
            if evaluation_window < 10:
                return  # –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ—Ü–µ–Ω–∫–∏

            # –ü–æ–ª—É—á–∞–µ–º –º–µ—Ç—Ä–∏–∫–∏ –¥–æ –∏ –ø–æ—Å–ª–µ –¥–µ–π—Å—Ç–≤–∏—è
            before_metrics = self.last_action_info["start_metrics"]
            after_metrics = self.metrics_history[-evaluation_window:]
            
            # –í—ã—á–∏—Å–ª—è–µ–º TTS-—Å–ø–µ—Ü–∏—Ñ–∏—á–Ω—É—é –Ω–∞–≥—Ä–∞–¥—É
            reward = self._calculate_tts_reward(before_metrics, after_metrics)
            
            # –û–±–Ω–æ–≤–ª—è–µ–º –±–∞–∑—É –∑–Ω–∞–Ω–∏–π
            db_id = self.last_action_info.get('db_id')
            if db_id:
                self._update_kb_with_tts_reward(db_id, reward, after_metrics[-1])
            
            action_name = self.last_action_info["action"]["name"]
            tts_phase = self.last_action_info.get("tts_phase", "unknown")
            self.logger.info(f"üîç TTS –æ—Ü–µ–Ω–∫–∞ –¥–µ–π—Å—Ç–≤–∏—è '{action_name}' –≤ —Ñ–∞–∑–µ '{tts_phase}': –Ω–∞–≥—Ä–∞–¥–∞ {reward:.4f}")
            
            # –°–±—Ä–æ—Å –¥–ª—è —Å–ª–µ–¥—É—é—â–µ–≥–æ —Ü–∏–∫–ª–∞
            self.last_action_step = 0
            self.last_action_info = {}
            
        except Exception as e:
            self.logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ TTS –æ—Ü–µ–Ω–∫–µ –¥–µ–π—Å—Ç–≤–∏—è: {e}")

    def _calculate_tts_reward(self, before_metrics: Dict, after_metrics: List[Dict]) -> float:
        """
        –í—ã—á–∏—Å–ª—è–µ—Ç –Ω–∞–≥—Ä–∞–¥—É —Å —É—á–µ—Ç–æ–º TTS-—Å–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã—Ö —É–ª—É—á—à–µ–Ω–∏–π.
        """
        if not after_metrics:
            return -1.0
            
        # –ë–∞–∑–æ–≤—ã–µ –≤–µ—Å–∞ –∏–∑ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
        reward_weights = self.advisor_config.get('reward_function', {}).get('weights', {})
        
        total_reward = 0.0
        total_weight = 0.0
        
        # –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏
        if 'val_loss' in reward_weights:
            before_val_loss = before_metrics.get('val_loss', float('inf'))
            after_val_loss = np.mean([m.get('val_loss', float('inf')) for m in after_metrics[-10:]])
            val_loss_improvement = (before_val_loss - after_val_loss) / before_val_loss if before_val_loss > 0 else 0
            
            weight = reward_weights['val_loss']
            total_reward += val_loss_improvement * weight
            total_weight += weight
        
        # TTS-—Å–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏
        tts_metrics = ['attention_alignment_score', 'gate_accuracy', 'mel_quality_score']
        for metric in tts_metrics:
            if metric in reward_weights:
                before_val = before_metrics.get(metric, 0.0)
                after_vals = [m.get(metric, 0.0) for m in after_metrics[-10:] if metric in m]
                if after_vals:
                    after_val = np.mean(after_vals)
                    improvement = (after_val - before_val) / max(before_val, 0.1)
                    
                    weight = reward_weights[metric]
                    total_reward += improvement * weight
                    total_weight += weight
        
        # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è
        if total_weight > 0:
            normalized_reward = total_reward / total_weight
        else:
            normalized_reward = -0.5  # –®—Ç—Ä–∞—Ñ –∑–∞ –æ—Ç—Å—É—Ç—Å—Ç–≤–∏–µ –¥–∞–Ω–Ω—ã—Ö
            
        return max(-2.0, min(2.0, normalized_reward))  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–∏–∞–ø–∞–∑–æ–Ω

    def _log_tts_event_to_kb(self, context: Dict, action: Dict) -> int:
        """
        –õ–æ–≥–∏—Ä—É–µ—Ç TTS —Å–æ–±—ã—Ç–∏–µ –≤ –±–∞–∑—É –∑–Ω–∞–Ω–∏–π —Å —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–º–∏ –ø–æ–ª—è–º–∏.
        """
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º TTS-—Å–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
            last_metrics = self.metrics_history[-1] if self.metrics_history else {}
            tts_phase = context.get('tts_phase', self.current_phase)
            attention_score = last_metrics.get('attention_alignment_score')
            gate_accuracy = last_metrics.get('gate_accuracy')  
            mel_quality = last_metrics.get('mel_quality_score')
            
            cursor.execute("""
                INSERT INTO knowledge_base 
                (problem_context, action_taken, tts_phase, attention_score, gate_accuracy, mel_quality)
                VALUES (?, ?, ?, ?, ?, ?)
            """, (
                json.dumps(context),
                json.dumps(action),
                tts_phase,
                attention_score,
                gate_accuracy,
                mel_quality
            ))
            
            event_id = cursor.lastrowid
            conn.commit()
            conn.close()
            
            self.logger.debug(f"TTS —Å–æ–±—ã—Ç–∏–µ {event_id} –∑–∞–ø–∏—Å–∞–Ω–æ –≤ –±–∞–∑—É –∑–Ω–∞–Ω–∏–π")
            return event_id
            
        except Exception as e:
            self.logger.error(f"–û—à–∏–±–∫–∞ –∑–∞–ø–∏—Å–∏ TTS —Å–æ–±—ã—Ç–∏—è –≤ –ë–ó: {e}")
            return -1

    def _update_kb_with_tts_reward(self, db_id: int, reward: float, final_metrics: Dict):
        """
        –û–±–Ω–æ–≤–ª—è–µ—Ç –∑–∞–ø–∏—Å—å –≤ –±–∞–∑–µ –∑–Ω–∞–Ω–∏–π —Å TTS –Ω–∞–≥—Ä–∞–¥–æ–π –∏ —Ñ–∏–Ω–∞–ª—å–Ω—ã–º–∏ –º–µ—Ç—Ä–∏–∫–∞–º–∏.
        """
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            cursor.execute("""
                UPDATE knowledge_base 
                SET reward = ?, outcome_metrics = ?, attention_score = ?, gate_accuracy = ?, mel_quality = ?
                WHERE id = ?
            """, (
                reward,
                json.dumps(final_metrics),
                final_metrics.get('attention_alignment_score'),
                final_metrics.get('gate_accuracy'),
                final_metrics.get('mel_quality_score'),
                db_id
            ))
            
            conn.commit()
            conn.close()
            
            self.logger.debug(f"TTS –Ω–∞–≥—Ä–∞–¥–∞ {reward:.4f} –æ–±–Ω–æ–≤–ª–µ–Ω–∞ –¥–ª—è —Å–æ–±—ã—Ç–∏—è {db_id}")
            
        except Exception as e:
            self.logger.error(f"–û—à–∏–±–∫–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è TTS –Ω–∞–≥—Ä–∞–¥—ã –≤ –ë–ó: {e}")

    def _create_tts_response_from_action(self, action: Dict, hparams: Dict, 
                                       step: int = 0, telegram_monitor=None) -> Dict:
        """
        –°–æ–∑–¥–∞–µ—Ç TTS-—Å–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã–π –æ—Ç–≤–µ—Ç –Ω–∞ –æ—Å–Ω–æ–≤–µ –¥–µ–π—Å—Ç–≤–∏—è.
        """
        response = {
            'action': action['name'],
            'reason': f"TTS –ø—Ä–æ–∞–∫—Ç–∏–≤–Ω–∞—è –º–µ—Ä–∞ –≤ —Ñ–∞–∑–µ {self.current_phase}",
            'tts_phase': self.current_phase,
            'hparams_changes': {},
            'training_changes': {}
        }
        
        params = action.get('params', {})
        
        # –û–±—Ä–∞–±–æ—Ç—á–∏–∫–∏ TTS-—Å–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã—Ö –¥–µ–π—Å—Ç–≤–∏–π
        if action['name'] == 'guided_attention_boost':
            if 'guide_loss_weight_multiplier' in params:
                current_weight = hparams.get('guided_attention_weight', 1.0)
                new_weight = current_weight * params['guide_loss_weight_multiplier']
                response['hparams_changes']['guided_attention_weight'] = new_weight
                
            if 'learning_rate_multiplier' in params:
                current_lr = hparams.get('learning_rate', 0.001)
                new_lr = current_lr * params['learning_rate_multiplier']
                response['hparams_changes']['learning_rate'] = new_lr
                
        elif action['name'] == 'attention_regularization':
            if 'attention_dropout_increase' in params:
                current_dropout = hparams.get('attention_dropout', 0.1)
                new_dropout = min(0.5, current_dropout + params['attention_dropout_increase'])
                response['hparams_changes']['attention_dropout'] = new_dropout
                
            if 'gate_threshold_adjust' in params:
                current_threshold = hparams.get('gate_threshold', 0.5)
                new_threshold = current_threshold + params['gate_threshold_adjust']
                response['hparams_changes']['gate_threshold'] = max(0.1, min(0.9, new_threshold))
                
        elif action['name'] == 'attention_recovery':
            response['hparams_changes']['use_guided_attention'] = params.get('use_guided_attention', True)
            response['hparams_changes']['guided_attention_weight'] = params.get('guide_loss_weight', 2.0)
            
        elif action['name'] == 'gate_regularization':
            response['hparams_changes']['gate_loss_weight'] = params.get('gate_loss_weight', 1.5)
            response['hparams_changes']['gate_threshold'] = params.get('gate_threshold', 0.5)
            
        elif action['name'] == 'adaptive_learning_boost':
            if 'learning_rate_multiplier' in params:
                current_lr = hparams.get('learning_rate', 0.001)
                new_lr = current_lr * params['learning_rate_multiplier']
                response['hparams_changes']['learning_rate'] = new_lr
                
        self.logger.info(f"üéØ TTS –¥–µ–π—Å—Ç–≤–∏–µ '{action['name']}' –ø–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω–æ –¥–ª—è —Ñ–∞–∑—ã '{self.current_phase}'")
        
        # üì± –û—Ç–ø—Ä–∞–≤–ª—è–µ–º Telegram —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ –æ–± –∞–¥–∞–ø—Ç–∏–≤–Ω–æ–º –¥–µ–π—Å—Ç–≤–∏–∏
        if telegram_monitor and response['hparams_changes']:
            old_params = {}  
            new_params = response['hparams_changes']
            
            # –ü–æ–ª—É—á–∞–µ–º —Å—Ç–∞—Ä—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
            for param_name, new_value in new_params.items():
                old_params[param_name] = hparams.get(param_name, '–Ω–µ –∑–∞–¥–∞–Ω–æ')
            
            reason = response['reason']
            try:
                telegram_monitor.send_auto_improvement_notification(
                    improvement_type=action['name'],
                    old_params=old_params,
                    new_params=new_params,
                    reason=reason,
                    step=step
                )
            except Exception as e:
                self.logger.warning(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –æ—Ç–ø—Ä–∞–≤–∏—Ç—å Telegram —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ –æ –¥–µ–π—Å—Ç–≤–∏–∏: {e}")
        
        return response

    def should_stop_early(self, metrics: Dict[str, float]) -> Tuple[bool, str]:
        """
        TTS-—Å–ø–µ—Ü–∏—Ñ–∏—á–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ —Ä–∞–Ω–Ω–µ–≥–æ –æ—Å—Ç–∞–Ω–æ–≤–∞ —Å –º—É–ª—å—Ç–∏–∫—Ä–∏—Ç–µ—Ä–∏–∞–ª—å–Ω–æ–π –æ—Ü–µ–Ω–∫–æ–π.
        """
        early_stop_config = self.config.get('early_stopping', {})
        if not early_stop_config.get('enabled', True):
            return False, "Early stopping –æ—Ç–∫–ª—é—á–µ–Ω"
            
        multi_criteria = early_stop_config.get('multi_criteria', {})
        if not multi_criteria.get('enabled', False):
            # –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞
            return self._standard_early_stop_check(metrics)
            
        # –ú—É–ª—å—Ç–∏–∫—Ä–∏—Ç–µ—Ä–∏–∞–ª—å–Ω–∞—è TTS –ø—Ä–æ–≤–µ—Ä–∫–∞
        criteria = multi_criteria.get('criteria', {})
        stop_reasons = []
        
        for criterion_name, criterion_config in criteria.items():
            metric_name = criterion_name.replace('_', '.')
            if metric_name in metrics:
                should_stop, reason = self._check_single_criterion(
                    metrics[metric_name], criterion_name, criterion_config
                )
                if should_stop:
                    stop_reasons.append(reason)
        
        # –û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º, –µ—Å–ª–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω—ã –∫—Ä–∏—Ç–µ—Ä–∏–∏ –¥–ª—è –æ—Å–Ω–æ–≤–Ω—ã—Ö TTS –º–µ—Ç—Ä–∏–∫
        critical_stops = [r for r in stop_reasons if any(word in r.lower() for word in ['attention', 'gate', 'validation'])]
        if len(critical_stops) >= 2:  # –ú–∏–Ω–∏–º—É–º 2 –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏—Ö –∫—Ä–∏—Ç–µ—Ä–∏—è
            combined_reason = " –∏ ".join(critical_stops[:2])
            return True, f"TTS –º—É–ª—å—Ç–∏–∫—Ä–∏—Ç–µ—Ä–∏–∞–ª—å–Ω—ã–π –æ—Å—Ç–∞–Ω–æ–≤: {combined_reason}"
            
        return False, "TTS –æ–±—É—á–µ–Ω–∏–µ –ø—Ä–æ–¥–æ–ª–∂–∞–µ—Ç—Å—è"

    def _standard_early_stop_check(self, metrics: Dict[str, float]) -> Tuple[bool, str]:
        """–°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ —Ä–∞–Ω–Ω–µ–≥–æ –æ—Å—Ç–∞–Ω–æ–≤–∞."""
        early_stop_config = self.config.get('early_stopping', {})
        
        monitor_metric = early_stop_config.get('monitor', 'validation.loss')
        if monitor_metric not in metrics:
            return False, f"–ú–µ—Ç—Ä–∏–∫–∞ {monitor_metric} –Ω–µ –Ω–∞–π–¥–µ–Ω–∞"
            
        patience = early_stop_config.get('patience', 150)
        min_delta = early_stop_config.get('min_delta', 0.0005)
        
        if len(self.metrics_history) < patience:
            return False, "–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –∏—Å—Ç–æ—Ä–∏–∏ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏"
            
        recent_values = [m.get(monitor_metric, float('inf')) for m in self.metrics_history[-patience:]]
        if len(recent_values) < patience:
            return False, "–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –ø–æ –º–µ—Ç—Ä–∏–∫–µ"
            
        best_value = min(recent_values[:-patience//2])
        current_value = recent_values[-1]
        
        if current_value - best_value > min_delta:
            return True, f"–†–∞–Ω–Ω–∏–π –æ—Å—Ç–∞–Ω–æ–≤: {monitor_metric} –Ω–µ —É–ª—É—á—à–∞–µ—Ç—Å—è {patience} —ç–ø–æ—Ö"
            
        return False, "–ú–µ—Ç—Ä–∏–∫–∞ —É–ª—É—á—à–∞–µ—Ç—Å—è"

    def _check_single_criterion(self, current_value: float, criterion_name: str, config: Dict) -> Tuple[bool, str]:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –æ–¥–Ω–æ–≥–æ –∫—Ä–∏—Ç–µ—Ä–∏—è —Ä–∞–Ω–Ω–µ–≥–æ –æ—Å—Ç–∞–Ω–æ–≤–∞."""
        patience = config.get('patience', 100)
        min_delta = config.get('min_delta', 0.001)
        mode = config.get('mode', 'min')
        
        if len(self.metrics_history) < patience:
            return False, f"–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –∏—Å—Ç–æ—Ä–∏–∏ –¥–ª—è {criterion_name}"
            
        # –ü–æ–ª—É—á–∞–µ–º –∏—Å—Ç–æ—Ä–∏—é –¥–ª—è —ç—Ç–æ–≥–æ –∫—Ä–∏—Ç–µ—Ä–∏—è
        metric_key = criterion_name.replace('_', '.')
        recent_values = []
        for m in self.metrics_history[-patience:]:
            if metric_key in m:
                recent_values.append(m[metric_key])
                
        if len(recent_values) < patience // 2:
            return False, f"–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è {criterion_name}"
            
        if mode == 'min':
            best_value = min(recent_values[:-patience//3])
            improvement = best_value - current_value
        else:  # mode == 'max'
            best_value = max(recent_values[:-patience//3])
            improvement = current_value - best_value
            
        if improvement < min_delta:
            return True, f"{criterion_name} —Å—Ç–∞–≥–Ω–∞—Ü–∏—è"
            
        return False, f"{criterion_name} —É–ª—É—á—à–∞–µ—Ç—Å—è"

    def reset(self):
        """–°–±—Ä–æ—Å —Å–æ—Å—Ç–æ—è–Ω–∏—è –∫–æ–Ω—Ç—Ä–æ–ª–ª–µ—Ä–∞ –¥–ª—è –Ω–æ–≤–æ–≥–æ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞."""
        self.metrics_history.clear()
        self.last_action_step = 0
        self.last_action_info.clear()
        self.current_phase = "pre_alignment"
        self.phase_start_step = 0
        self.logger.info("TTS EarlyStopController —Å–±—Ä–æ—à–µ–Ω –¥–ª—è –Ω–æ–≤–æ–≥–æ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞")

    def get_tts_training_summary(self) -> Dict[str, Any]:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–≤–æ–¥–∫—É TTS –æ–±—É—á–µ–Ω–∏—è —Å —Ñ–∞–∑–æ–≤–æ–π —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–æ–π."""
        if not self.metrics_history:
            return {"status": "no_data"}
            
        last_metrics = self.metrics_history[-1]
        total_steps = len(self.metrics_history)
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ —Ñ–∞–∑–∞–º
        phase_stats = {}
        current_phase_count = 0
        for m in self.metrics_history:
            phase = m.get('tts_phase', 'unknown')
            if phase not in phase_stats:
                phase_stats[phase] = 0
            phase_stats[phase] += 1
            if phase == self.current_phase:
                current_phase_count += 1
        
        return {
            "status": "training",
            "current_phase": self.current_phase,
            "current_phase_duration": current_phase_count,
            "total_steps": total_steps,
            "phase_distribution": phase_stats,
            "latest_metrics": {
                "val_loss": last_metrics.get('val_loss', 0.0),
                "attention_score": last_metrics.get('attention_alignment_score', 0.0),
                "gate_accuracy": last_metrics.get('gate_accuracy', 0.0),
                "grad_norm": last_metrics.get('grad_norm', 0.0)
            },
            "tts_health": self._evaluate_tts_health(last_metrics)
        }
    
    def _evaluate_tts_health(self, metrics: Dict[str, float]) -> str:
        """–û—Ü–µ–Ω–∏–≤–∞–µ—Ç –æ–±—â–µ–µ –∑–¥–æ—Ä–æ–≤—å–µ TTS –æ–±—É—á–µ–Ω–∏—è."""
        issues = []
        
        if metrics.get('grad_norm', 0) > 300:
            issues.append("high_gradients")
        if metrics.get('attention_alignment_score', 1.0) < 0.5:
            issues.append("poor_attention")
        if metrics.get('gate_accuracy', 1.0) < 0.7:
            issues.append("gate_problems")
        if metrics.get('val_loss', 0) > 10.0:
            issues.append("high_loss")
            
        if not issues:
            return "healthy"
        elif len(issues) == 1:
            return "minor_issues"
        elif len(issues) == 2:
            return "moderate_issues"
        else:
            return "critical_issues"