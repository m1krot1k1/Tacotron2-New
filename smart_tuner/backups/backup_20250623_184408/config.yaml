adaptive_advisor:
  db_path: smart_tuner/advisor_kb.db
  default_actions:
    instability:
      name: guided_attention_boost
      params:
        guide_loss_weight_multiplier: 1.5
        learning_rate_multiplier: 0.7
    overfitting:
      name: attention_regularization
      params:
        attention_dropout_increase: 0.1
        gate_threshold_adjust: 0.05
    stagnation:
      name: adaptive_learning_boost
      params:
        learning_rate_multiplier: 1.3
        guided_attention_boost: 0.2
    attention_failure:
      name: attention_recovery
      params:
        use_guided_attention: true
        guide_loss_weight: 2.0
        attention_dropout_reduction: 0.1
    gate_collapse:
      name: gate_regularization
      params:
        gate_loss_weight: 1.5
        gate_threshold: 0.5
  diagnostics:
    instability:
      grad_norm_threshold: 200.0
    overfitting:
      threshold: 5.0
      window_size: 50
    stagnation:
      min_delta: 0.0005
      window_size: 150
    attention_failure:
      min_alignment_score: 0.7
      alignment_window: 100
    gate_collapse:
      min_gate_accuracy: 0.8
      gate_window: 50
  enabled: true
  evaluation_window: 100
  min_history_for_decision: 200
  min_reward_threshold: -0.1
  reward_function:
    weights:
      val_loss: 0.4
      attention_alignment_score: 0.3
      gate_accuracy: 0.2
      mel_quality_score: 0.1
    action_inaction_threshold: 0.0005
    inaction_penalty: 0.005
checkpoint_path: data/checkpoint
dataset_path: data/dataset
early_stopping:
  enabled: true
  min_delta: 0.0005
  mode: min
  monitor: validation.loss
  patience: 150
  multi_criteria:
    enabled: true
    criteria:
      validation_loss:
        weight: 0.4
        patience: 150
        min_delta: 0.0005
      attention_alignment_score:
        weight: 0.3
        patience: 100
        min_delta: 0.01
        mode: max
      gate_accuracy:
        weight: 0.2
        patience: 80
        min_delta: 0.005
        mode: max
      mel_quality_score:
        weight: 0.1
        patience: 100
        min_delta: 0.01
        mode: max
experiment_name: tacotron2_production
final_training:
  epochs: 200
hparams_path: hparams.py
hyperparameter_search_space:
  batch_size:
    choices:
    - 8
    - 16
    - 24
    - 32
    - 48
    - 64
    default: 16
    type: categorical
  epochs:
    default: 200
    max: 500
    min: 100
    type: int
  learning_rate:
    default: 0.001
    log: true
    max: 0.01
    min: 0.0001
    type: float
  warmup_steps:
    default: 2000
    max: 5000
    min: 1000
    type: int
  guided_attention_enabled:
    type: categorical
    choices:
    - true
    - false
    default: true
  guide_loss_weight:
    default: 1.0
    max: 5.0
    min: 0.5
    type: float
  p_attention_dropout:
    default: 0.1
    max: 0.3
    min: 0.0
    type: float
  gate_threshold:
    default: 0.5
    max: 0.7
    min: 0.3
    type: float
  dropout_rate:
    default: 0.3
    max: 0.7
    min: 0.1
    type: float
  postnet_dropout_rate:
    default: 0.1
    max: 0.3
    min: 0.0
    type: float
mlflow:
  experiment_name: tacotron2_optimization
  tracking_uri: mlruns
model_registry:
  best_model_name: best_model.pt
  max_models: 5
  minimize_metric: true
  path: smart_tuner/models
  primary_metric: val_loss
optimization:
  continue_training: true
  direction: minimize
  full_epochs_per_trial: 100
  n_trials: 30
  objective_metric: composite_tts_score
  overfitting_penalty: 0.05
  tts_specific:
    min_training_steps: 20000
    attention_convergence_threshold: 0.8
    gate_accuracy_threshold: 0.85
    early_pruning_disabled_epochs: 100
  composite_objective:
    weights:
      validation_loss: 0.4
      attention_alignment_score: 0.3
      gate_accuracy: 0.2
      mel_quality_score: 0.1
    normalize_scores: true
output_dir: output
parameter_scheduling:
  learning_rate:
    enabled: true
    end_value: 0.0001
    start_value: 0.001
    strategy: cosine
    total_steps: 10000
parameter_scheduling_config:
  update_frequency: 10
ports:
  alert_manager: 5009
  early_stop_controller: 5008
  log_watcher: 5005
  metrics_store: 5006
  mlflow: 5000
  model_registry: 5010
  optimization_engine: 5002
  param_scheduler: 5007
  streamlit: 5003
  tensorboard: 5001
resources:
  checkpointing:
    path: output
search_space:
  batch_size:
    choices:
    - 8
    - 16
    - 24
    - 32
    - 48
    - 64
    default: 16
    type: categorical
  epochs:
    default: 200
    max: 500
    min: 100
    type: int
  learning_rate:
    default: 0.001
    log: true
    max: 0.01
    min: 0.0001
    type: float
  warmup_steps:
    default: 2000
    max: 5000
    min: 1000
    type: int
telegram:
  bot_token: 2010534305:AAHqgXYT5RPcLoJe-wNdFaFbIJvJsN2xUHA
  chat_id: '536955174'
  disable_web_page_preview: true
  enabled: true
  notifications:
    early_stop: true
    error_alerts: true
    metrics_summary: false
    optimization_updates: true
    training_complete: true
    training_start: true
  parse_mode: Markdown
training:
  base_command: python train.py
  continue_from_checkpoint: true
  full_training: true
  python_executable: python
  script_path: train.py
training_safety:
  enabled: true
  max_training_hours: 48.0
  max_validation_loss: 50.0
  min_training_hours: 8.0
  min_training_steps: 20000
  tts_quality_checks:
    min_attention_alignment: 0.6
    min_gate_accuracy: 0.7
    max_attention_entropy: 3.0
    mel_quality_threshold: 0.5
tts_phase_training:
  enabled: true
  phases:
    pre_alignment:
      duration_epochs: 50
      guided_attention_weight: 3.0
      learning_rate_multiplier: 1.0
      focus_metrics: [attention_alignment_score]
    alignment_learning:
      duration_epochs: 100
      guided_attention_weight: 1.5
      learning_rate_multiplier: 0.8
      focus_metrics: [attention_alignment_score, gate_accuracy]
    fine_tuning:
      duration_epochs: 150
      guided_attention_weight: 0.5
      learning_rate_multiplier: 0.6
      focus_metrics: [validation_loss, mel_quality_score]
tts_metrics:
  attention_metrics:
    alignment_score_weight: 1.0
    attention_entropy_weight: 0.5
    attention_sharpness_weight: 0.3
  gate_metrics:
    accuracy_weight: 1.0
    precision_weight: 0.8
    recall_weight: 0.8
  mel_metrics:
    spectral_distance_weight: 1.0
    mel_cepstral_distortion_weight: 0.7
