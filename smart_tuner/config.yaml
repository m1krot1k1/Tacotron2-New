adaptive_advisor:
  default_actions:
    attention_failure:
      name: attention_recovery
      params:
        attention_dropout_reduction: 0.03
        guided_attention_boost: 2.0
    gate_collapse:
      name: gate_recovery
      params:
        gate_loss_weight: 2.0
        gate_threshold_adjust: -0.1
    instability:
      name: stability_boost
      params:
        batch_size_adjust: 0.8
        gradient_clipping: 2.0
        learning_rate_multiplier: 0.5
    overfitting:
      name: regularization_boost
      params:
        dropout_increase: 0.02
        weight_decay_increase: 0.05
  diagnostics:
    attention_failure:
      alignment_window: 30
      min_alignment_score: 0.7
    gate_collapse:
      gate_window: 20
      min_gate_accuracy: 0.75
    instability:
      grad_norm_threshold: 50.0
    overfitting:
      threshold: 2.0
      window_size: 20
    stagnation:
      min_delta: 0.002
      window_size: 50
  enabled: true
  evaluation_window: 30
  min_history_for_decision: 50
  min_reward_threshold: -0.03
adaptive_learning:
  complexity_modifiers:
    complex: 1.3
    moderate: 1.0
    simple: 0.8
    very_complex: 1.6
  dataset_analysis:
    enabled: true
    factors:
    - dataset_size
    - voice_complexity
    - quality_metrics
    - hardware_constraints
  enabled: true
  epoch_recommendations:
    large: 2500
    medium: 3000
    small: 4000
    very_large: 2000
    very_small: 5000
checkpoint_path: data/checkpoint
dataset_path: data/dataset
early_stopping:
  adaptive_thresholds:
    alignment_phase:
      attention_threshold: 0.6
      min_improvement: 0.02
      patience: 200
    enabled: true
    fine_tuning_phase:
      attention_threshold: 0.9
      min_improvement: 0.0005
      patience: 400
    learning_phase:
      attention_threshold: 0.85
      min_improvement: 0.001
      patience: 250
  enabled: true
  min_delta: 0.0005
  monitor_metric: val_loss
  patience_epochs: 300
experiment_name: tacotron2_smart_v2
final_training:
  epochs: 200
guided_attention:
  adaptive_weight:
    decay_steps: 5000
    enabled: true
    final_weight: 1.0
    initial_weight: 5.0
  enabled: true
  final_guide_decay: 0.99999
  guide_decay_start: 2000
  initial_guide_decay: 0.9995
  sigma_schedule:
    decay_rate: 0.9999
    enabled: true
    final_sigma: 0.2
    initial_sigma: 0.4
hparams_path: hparams.py
hyperparameter_search_space:
  batch_size:
    default: 32
    max: 48
    min: 24
    type: int
  dropout_rate:
    default: 0.08
    max: 0.15
    min: 0.05
    type: float
  epochs:
    default: 1000
    max: 2000
    min: 500
    type: int
  gate_threshold:
    default: 0.5
    max: 0.6
    min: 0.4
    type: float
  guide_loss_weight:
    default: 2.5
    max: 5.0
    min: 1.0
    type: float
  guided_attention_enabled:
    choices:
    - true
    default: true
    type: categorical
  learning_rate:
    default: 0.0001
    log: true
    max: 0.0005
    min: 1.0e-05
    type: float
  p_attention_dropout:
    default: 0.05
    max: 0.1
    min: 0.0
    type: float
  postnet_dropout_rate:
    default: 0.05
    max: 0.1
    min: 0.0
    type: float
  use_location_relative_attention:
    choices:
    - true
    - false
    default: true
    type: categorical
  warmup_steps:
    default: 2000
    max: 5000
    min: 1000
    type: int
mlflow:
  experiment_name: tacotron2_smart_optimization
  tracking_uri: mlruns
model_registry:
  best_model_name: best_tts_model.pt
  max_models: 3
  minimize_metric: true
  path: smart_tuner/models
  primary_metric: val_loss
monitoring:
  emergency_notifications: true
  grad_norm_alert_threshold: 5.0
  gradient_monitoring: true
  loss_alert_threshold: 10.0
optimization:
  composite_objective:
    normalize_scores: true
    progress_weight: 0.15
    quality_bonus_threshold: 0.85
    weights:
      attention_alignment_score: 0.25
      gate_accuracy: 0.2
      mel_quality_score: 0.15
      validation_loss: 0.4
  continue_training: true
  direction: minimize
  full_epochs_per_trial: 120
  n_trials: 25
  objective_metric: composite_tts_score
  overfitting_penalty: 0.02
  sampler: bayesian
  tts_specific:
    attention_convergence_threshold: 0.75
    early_pruning_disabled_epochs: 100
    gate_accuracy_threshold: 0.8
    min_training_steps: 5000
output_dir: output
overfitting_detection:
  actions:
    early_stop_patience: 100
    increase_dropout: 0.02
    reduce_learning_rate: 0.5
  check_interval: 20
  enabled: true
  thresholds:
    attention_degradation: 0.1
    gate_instability: 0.15
    train_val_gap: 2.0
    val_loss_increase: 0.05
parameter_scheduling:
  learning_rate:
    enabled: true
    end_value: 0.0001
    start_value: 0.001
    strategy: cosine
    total_steps: 8000
parameter_scheduling_config:
  update_frequency: 20
ports:
  alert_manager: 5009
  early_stop_controller: 5008
  log_watcher: 5005
  metrics_store: 5006
  mlflow: 5000
  model_registry: 5010
  optimization_engine: 5002
  param_scheduler: 5007
  streamlit: 5003
  tensorboard: 5001
quality_monitoring:
  check_interval: 10
  enabled: true
  quality_metrics:
    attention_diagonality:
      enabled: true
      min_threshold: 0.7
      target_threshold: 0.9
    gate_quality:
      enabled: true
      max_premature_stop: 0.1
      min_accuracy: 0.75
    mel_spectrogram_quality:
      enabled: true
      max_noise_level: 0.2
      min_clarity: 0.6
    training_stability:
      enabled: true
      loss_smoothness: 0.8
      max_gradient_norm: 10.0
resources:
  checkpointing:
    path: output
smart_tuner:
  adaptive_learning_rate: true
  early_stop_patience: 50
  emergency_interventions: true
  emergency_mode: true
  gradient_clipping_enabled: true
  guided_attention_multiplier: 5.0
  learning_rate_multiplier: 0.1
  max_grad_norm: 1.0
  quality_threshold: 0.3
telegram:
  bot_token: 2010534305:AAHqgXYT5RPcLoJe-wNdFaFbIJvJsN2xUHA
  chat_id: '536955174'
  disable_web_page_preview: true
  enabled: true
  notifications:
    early_stop: true
    error_alerts: true
    metrics_summary: true
    optimization_updates: true
    quality_interventions: true
    training_complete: true
    training_restart: true
    training_start: true
  parse_mode: Markdown
training:
  base_command: python train.py
  continue_from_checkpoint: true
  full_training: true
  python_executable: python
  script_path: train.py
training_safety:
  enabled: true
  max_training_hours: 12.0
  max_validation_loss: 20.0
  min_training_hours: 1.0
  min_training_steps: 3000
  tts_quality_checks:
    critical_checks:
    - attention_alignment
    - gate_accuracy
    - validation_loss
    - mel_quality
    max_validation_loss: 30.0
    mel_quality_threshold: 0.5
    min_attention_alignment: 0.4
    min_gate_accuracy: 0.6
    min_training_progress: 0.1
    min_training_time_minutes: 30
    min_validation_steps: 10
    required_checks_percentage: 0.95
tts_loss_functions:
  enabled: true
  perceptual_loss:
    enabled: true
    weight: 0.2
  spectral_loss:
    enabled: true
    fft_sizes:
    - 1024
    - 2048
    - 4096
    weight: 0.3
  style_loss:
    enabled: true
    weight: 0.1
tts_metrics:
  attention_metrics:
    diagonality_score: true
    entropy_score: true
    focus_score: true
    monotonicity_score: true
  enabled: true
  gate_metrics:
    accuracy: true
    f1_score: true
    precision: true
    recall: true
  mel_metrics:
    harmonic_clarity: true
    spectral_quality: true
    temporal_consistency: true
tts_phase_training:
  enabled: true
  phases:
    alignment_learning:
      epochs: 1500
      focus: attention_stabilization
      guided_attention_weight: 3.0
      learning_rate_modifier: 0.8
    fine_tuning:
      epochs: 500
      focus: final_polishing
      guided_attention_weight: 0.5
      learning_rate_modifier: 0.3
    pre_alignment:
      epochs: 500
      focus: attention_learning
      guided_attention_weight: 10.0
      learning_rate_modifier: 1.0
    quality_optimization:
      epochs: 1000
      focus: quality_improvement
      guided_attention_weight: 1.0
      learning_rate_modifier: 0.5
