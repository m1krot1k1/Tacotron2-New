adaptive_advisor:
  db_path: smart_tuner/advisor_kb.db
  default_actions:
    instability:
      name: change_lr
      params:
        multiplier: 0.5
    overfitting:
      name: increase_regularization
      params:
        dropout_increase: 0.05
    stagnation:
      name: change_lr
      params:
        multiplier: 1.2
  diagnostics:
    instability:
      grad_norm_threshold: 200.0
    overfitting:
      threshold: 5.0
      window_size: 30
    stagnation:
      min_delta: 0.001
      window_size: 100
  enabled: false
  evaluation_window: 50
  min_history_for_decision: 100
  reward_function:
    action_inaction_threshold: 0.0001
    inaction_penalty: 0.01
    weights:
      overfitting_gap: 0.5
      val_loss: 1.0
checkpoint_path: data/checkpoint
dataset_path: data/dataset
early_stopping:
  enabled: true
  min_delta: 0.001
  mode: min
  monitor: validation.loss
  patience: 100
experiment_name: tacotron2_production
final_training:
  epochs: 200
hparams_path: hparams.py
hyperparameter_search_space:
  batch_size:
    choices:
    - 16
    - 32
    - 64
    default: 32
    type: categorical
  epochs:
    default: 100
    max: 200
    min: 50
    type: int
  learning_rate:
    default: 0.001
    log: true
    max: 0.01
    min: 0.0001
    type: float
  warmup_steps:
    default: 1000
    max: 2000
    min: 500
    type: int
mlflow:
  experiment_name: tacotron2_optimization
  tracking_uri: mlruns
model_registry:
  best_model_name: best_model.pt
  max_models: 5
  minimize_metric: true
  path: smart_tuner/models
  primary_metric: val_loss
optimization:
  continue_training: true
  direction: minimize
  full_epochs_per_trial: 50
  n_trials: 20
  objective_metric: val_loss
  overfitting_penalty: 0.1
output_dir: output
parameter_scheduling:
  learning_rate:
    enabled: true
    end_value: 0.0001
    start_value: 0.001
    strategy: cosine
    total_steps: 10000
parameter_scheduling_config:
  update_frequency: 10
ports:
  alert_manager: 5009
  early_stop_controller: 5008
  log_watcher: 5005
  metrics_store: 5006
  mlflow: 5000
  model_registry: 5010
  optimization_engine: 5002
  param_scheduler: 5007
  streamlit: 5003
  tensorboard: 5001
resources:
  checkpointing:
    path: output
search_space:
  batch_size:
    choices:
    - 16
    - 32
    - 64
    default: 32
    type: categorical
  epochs:
    default: 100
    max: 200
    min: 50
    type: int
  learning_rate:
    default: 0.001
    log: true
    max: 0.01
    min: 0.0001
    type: float
  warmup_steps:
    default: 1000
    max: 2000
    min: 500
    type: int
telegram:
  bot_token: 2010534305:AAHqgXYT5RPcLoJe-wNdFaFbIJvJsN2xUHA
  chat_id: '536955174'
  disable_web_page_preview: true
  enabled: true
  notifications:
    early_stop: true
    error_alerts: true
    metrics_summary: false
    optimization_updates: true
    training_complete: true
    training_start: true
  parse_mode: Markdown
training:
  base_command: python train.py
  continue_from_checkpoint: true
  full_training: true
  python_executable: python
  script_path: train.py
training_safety:
  enabled: true
  max_training_hours: 15.0
  max_validation_loss: 100.0
  min_training_hours: 4.0
  min_training_steps: 5000
