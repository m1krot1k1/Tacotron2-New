#!/usr/bin/env python3
"""
üéØ –î–∏–∞–≥–Ω–æ—Å—Ç–∏—á–µ—Å–∫–∞—è —É—Ç–∏–ª–∏—Ç–∞ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ Alignment –º–∞—Ç—Ä–∏—Ü Tacotron2
–ê–≤—Ç–æ—Ä: AI Assistant –¥–ª—è –ø—Ä–æ–µ–∫—Ç–∞ Intelligent TTS Training Pipeline

–≠—Ç–æ—Ç –º–æ–¥—É–ª—å –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è–µ—Ç –∫–æ–º–ø–ª–µ–∫—Å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –∫–∞—á–µ—Å—Ç–≤–∞ attention alignment
–∏ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ —É–ª—É—á—à–µ–Ω–∏—é –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏.
"""

import numpy as np
import torch
import matplotlib.pyplot as plt
import seaborn as sns
from pathlib import Path
import json
from typing import Dict, List, Tuple, Any
import logging

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class AlignmentDiagnostics:
    """–ö–ª–∞—Å—Å –¥–ª—è –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏ –∏ –∞–Ω–∞–ª–∏–∑–∞ alignment –º–∞—Ç—Ä–∏—Ü."""
    
    def __init__(self):
        self.results = {}
        
    def analyze_alignment_matrix(self, alignment: np.ndarray, 
                               step: int = 0, 
                               text_length: int = None,
                               audio_length: int = None) -> Dict[str, Any]:
        """
        –ö–æ–º–ø–ª–µ–∫—Å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ alignment –º–∞—Ç—Ä–∏—Ü—ã.
        
        Args:
            alignment: numpy array —Ä–∞–∑–º–µ—Ä–æ–º (decoder_steps, encoder_steps)
            step: –Ω–æ–º–µ—Ä —à–∞–≥–∞ –æ–±—É—á–µ–Ω–∏—è
            text_length: —Ä–µ–∞–ª—å–Ω–∞—è –¥–ª–∏–Ω–∞ —Ç–µ–∫—Å—Ç–∞ (–±–µ–∑ padding)
            audio_length: —Ä–µ–∞–ª—å–Ω–∞—è –¥–ª–∏–Ω–∞ –∞—É–¥–∏–æ (–±–µ–∑ padding)
            
        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –∞–Ω–∞–ª–∏–∑–∞
        """
        logger.info(f"üîç –ê–Ω–∞–ª–∏–∑ alignment –º–∞—Ç—Ä–∏—Ü—ã –Ω–∞ —à–∞–≥–µ {step}")
        logger.info(f"üìè –†–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å: {alignment.shape}")
        
        results = {
            'step': step,
            'shape': alignment.shape,
            'diagnostics': {},
            'problems': [],
            'recommendations': []
        }
        
        # 1. –ë–∞–∑–æ–≤—ã–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
        results['diagnostics']['mean_attention'] = float(np.mean(alignment))
        results['diagnostics']['max_attention'] = float(np.max(alignment))
        results['diagnostics']['min_attention'] = float(np.min(alignment))
        results['diagnostics']['std_attention'] = float(np.std(alignment))
        
        # 2. –ê–Ω–∞–ª–∏–∑ –¥–∏–∞–≥–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏
        diag_score = self._calculate_diagonal_score(alignment)
        results['diagnostics']['diagonal_score'] = diag_score
        
        # 3. –ê–Ω–∞–ª–∏–∑ –º–æ–Ω–æ—Ç–æ–Ω–Ω–æ—Å—Ç–∏
        monotonic_score = self._calculate_monotonic_score(alignment)
        results['diagnostics']['monotonic_score'] = monotonic_score
        
        # 4. –ê–Ω–∞–ª–∏–∑ —Ñ–æ–∫—É—Å–∏—Ä–æ–≤–∫–∏
        focus_score = self._calculate_focus_score(alignment)
        results['diagnostics']['focus_score'] = focus_score
        
        # 5. –ê–Ω–∞–ª–∏–∑ —ç–Ω—Ç—Ä–æ–ø–∏–∏
        entropy_score = self._calculate_entropy_score(alignment)
        results['diagnostics']['entropy_score'] = entropy_score
        
        # 6. –î–µ—Ç–µ–∫—Ü–∏—è –ø—Ä–æ–±–ª–µ–º
        problems = self._detect_problems(alignment, results['diagnostics'])
        results['problems'] = problems
        
        # 7. –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π
        recommendations = self._generate_recommendations(problems, results['diagnostics'])
        results['recommendations'] = recommendations
        
        # 8. –û—Ü–µ–Ω–∫–∞ –æ–±—â–µ–≥–æ –∫–∞—á–µ—Å—Ç–≤–∞
        overall_score = self._calculate_overall_score(results['diagnostics'])
        results['overall_score'] = overall_score
        
        self._log_results(results)
        return results
    
    def _calculate_diagonal_score(self, alignment: np.ndarray) -> float:
        """–í—ã—á–∏—Å–ª—è–µ—Ç —Å—Ç–µ–ø–µ–Ω—å –¥–∏–∞–≥–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏ alignment –º–∞—Ç—Ä–∏—Ü—ã."""
        H, W = alignment.shape
        diagonal_sum = 0.0
        total_sum = np.sum(alignment)
        
        if total_sum == 0:
            return 0.0
        
        # –°–æ–∑–¥–∞–µ–º –∏–¥–µ–∞–ª—å–Ω—É—é –¥–∏–∞–≥–æ–Ω–∞–ª—å–Ω—É—é –º–∞—Å–∫—É
        for i in range(H):
            # –ü—Ä–æ–ø–æ—Ä—Ü–∏–æ–Ω–∞–ª—å–Ω–∞—è –ø–æ–∑–∏—Ü–∏—è –Ω–∞ –¥–∏–∞–≥–æ–Ω–∞–ª–∏
            diag_pos = int((i / H) * W)
            # –°—É–º–º–∏—Ä—É–µ–º –≤–µ—Å–∞ –≤ –æ–∫—Ä–µ—Å—Ç–Ω–æ—Å—Ç–∏ –¥–∏–∞–≥–æ–Ω–∞–ª–∏ (¬±3 –ø–æ–∑–∏—Ü–∏–∏)
            for j in range(max(0, diag_pos-3), min(W, diag_pos+4)):
                diagonal_sum += alignment[i, j]
        
        return diagonal_sum / total_sum
    
    def _calculate_monotonic_score(self, alignment: np.ndarray) -> float:
        """–í—ã—á–∏—Å–ª—è–µ—Ç —Å—Ç–µ–ø–µ–Ω—å –º–æ–Ω–æ—Ç–æ–Ω–Ω–æ—Å—Ç–∏ alignment."""
        H, W = alignment.shape
        monotonic_violations = 0
        total_transitions = 0
        
        prev_peak = 0
        for i in range(1, H):
            # –ù–∞—Ö–æ–¥–∏–º –ø–∏–∫ attention –¥–ª—è —Ç–µ–∫—É—â–µ–π —Å—Ç—Ä–æ–∫–∏
            current_peak = np.argmax(alignment[i])
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –º–æ–Ω–æ—Ç–æ–Ω–Ω–æ—Å—Ç—å
            if current_peak < prev_peak:
                monotonic_violations += 1
            
            prev_peak = current_peak
            total_transitions += 1
        
        if total_transitions == 0:
            return 1.0
            
        return 1.0 - (monotonic_violations / total_transitions)
    
    def _calculate_focus_score(self, alignment: np.ndarray) -> float:
        """–í—ã—á–∏—Å–ª—è–µ—Ç —Å—Ç–µ–ø–µ–Ω—å —Ñ–æ–∫—É—Å–∏—Ä–æ–≤–∫–∏ attention."""
        # –í—ã—á–∏—Å–ª—è–µ–º —Å—Ä–µ–¥–Ω—é—é –∫–æ–Ω—Ü–µ–Ω—Ç—Ä–∞—Ü–∏—é attention –ø–æ —Å—Ç—Ä–æ–∫–∞–º
        focus_scores = []
        for i in range(alignment.shape[0]):
            row = alignment[i]
            if np.sum(row) > 0:
                # –í—ã—á–∏—Å–ª—è–µ–º —ç–Ω—Ç—Ä–æ–ø–∏—é —Å—Ç—Ä–æ–∫–∏ (–Ω–∏–∑–∫–∞—è —ç–Ω—Ç—Ä–æ–ø–∏—è = –≤—ã—Å–æ–∫–∞—è —Ñ–æ–∫—É—Å–∏—Ä–æ–≤–∫–∞)
                row_normalized = row / np.sum(row)
                entropy = -np.sum(row_normalized * np.log(row_normalized + 1e-8))
                # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º —ç–Ω—Ç—Ä–æ–ø–∏—é –≤ score —Ñ–æ–∫—É—Å–∏—Ä–æ–≤–∫–∏ (0-1)
                max_entropy = np.log(len(row))
                focus_score = 1.0 - (entropy / max_entropy)
                focus_scores.append(focus_score)
        
        return np.mean(focus_scores) if focus_scores else 0.0
    
    def _calculate_entropy_score(self, alignment: np.ndarray) -> float:
        """–í—ã—á–∏—Å–ª—è–µ—Ç —ç–Ω—Ç—Ä–æ–ø–∏—é –≤—Å–µ–π alignment –º–∞—Ç—Ä–∏—Ü—ã."""
        flat = alignment.flatten()
        if np.sum(flat) == 0:
            return 0.0
        
        flat_normalized = flat / np.sum(flat)
        entropy = -np.sum(flat_normalized * np.log(flat_normalized + 1e-8))
        max_entropy = np.log(len(flat))
        return entropy / max_entropy
    
    def _detect_problems(self, alignment: np.ndarray, diagnostics: Dict) -> List[Dict]:
        """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç –ø—Ä–æ–±–ª–µ–º—ã –≤ alignment –º–∞—Ç—Ä–∏—Ü–µ."""
        problems = []
        
        # –ü—Ä–æ–±–ª–µ–º–∞ 1: –ì–æ—Ä–∏–∑–æ–Ω—Ç–∞–ª—å–Ω–∞—è –ø–æ–ª–æ—Å–∞ (–∫–∞–∫ –Ω–∞ –≤–∞—à–µ–º –≥—Ä–∞—Ñ–∏–∫–µ)
        if diagnostics['diagonal_score'] < 0.3:
            problems.append({
                'type': 'horizontal_stripe',
                'severity': 'critical',
                'description': 'Attention —Ñ–æ–∫—É—Å–∏—Ä—É–µ—Ç—Å—è —Ç–æ–ª—å–∫–æ –Ω–∞ –ø–µ—Ä–≤—ã—Ö encoder timesteps',
                'score': diagnostics['diagonal_score']
            })
        
        # –ü—Ä–æ–±–ª–µ–º–∞ 2: –ù–∏–∑–∫–∞—è –º–æ–Ω–æ—Ç–æ–Ω–Ω–æ—Å—Ç—å
        if diagnostics['monotonic_score'] < 0.5:
            problems.append({
                'type': 'non_monotonic',
                'severity': 'high',
                'description': 'Attention –Ω–µ —Å–ª–µ–¥—É–µ—Ç –º–æ–Ω–æ—Ç–æ–Ω–Ω–æ–π –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏',
                'score': diagnostics['monotonic_score']
            })
        
        # –ü—Ä–æ–±–ª–µ–º–∞ 3: –†–∞–∑–º—ã—Ç—ã–π attention
        if diagnostics['focus_score'] < 0.4:
            problems.append({
                'type': 'unfocused_attention',
                'severity': 'medium',
                'description': 'Attention —Å–ª–∏—à–∫–æ–º —Ä–∞–∑–º—ã—Ç, –Ω–µ—Ç —á–µ—Ç–∫–æ–π —Ñ–æ–∫—É—Å–∏—Ä–æ–≤–∫–∏',
                'score': diagnostics['focus_score']
            })
        
        # –ü—Ä–æ–±–ª–µ–º–∞ 4: –í—ã—Å–æ–∫–∞—è —ç–Ω—Ç—Ä–æ–ø–∏—è
        if diagnostics['entropy_score'] > 0.8:
            problems.append({
                'type': 'high_entropy',
                'severity': 'medium',
                'description': '–°–ª–∏—à–∫–æ–º —Ä–∞–≤–Ω–æ–º–µ—Ä–Ω–æ–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ attention –≤–µ—Å–æ–≤',
                'score': diagnostics['entropy_score']
            })
        
        # –ü—Ä–æ–±–ª–µ–º–∞ 5: –û—á–µ–Ω—å –º–∞–ª–µ–Ω—å–∫–∏–µ –≤–µ—Å–∞
        if diagnostics['max_attention'] < 0.1:
            problems.append({
                'type': 'weak_attention',
                'severity': 'high',
                'description': 'Attention –≤–µ—Å–∞ —Å–ª–∏—à–∫–æ–º –º–∞–ª—ã',
                'score': diagnostics['max_attention']
            })
        
        return problems
    
    def _generate_recommendations(self, problems: List[Dict], diagnostics: Dict) -> List[str]:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ —É–ª—É—á—à–µ–Ω–∏—é."""
        recommendations = []
        
        for problem in problems:
            if problem['type'] == 'horizontal_stripe':
                recommendations.extend([
                    "üîß –ö–†–ò–¢–ò–ß–ù–û: –£–≤–µ–ª–∏—á–∏—Ç—å –≤–µ—Å guided attention loss –≤ –Ω–∞—á–∞–ª–µ –æ–±—É—á–µ–Ω–∏—è",
                    "üîß –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –ø—Ä–∞–≤–∏–ª—å–Ω–æ—Å—Ç—å —Ñ–æ—Ä–º—É–ª—ã guided attention loss",
                    "üîß –£–º–µ–Ω—å—à–∏—Ç—å learning rate –¥–ª—è —Å—Ç–∞–±–∏–ª–∏–∑–∞—Ü–∏–∏ –æ–±—É—á–µ–Ω–∏—è",
                    "üîß –£–≤–µ–ª–∏—á–∏—Ç—å –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —à–∞–≥–æ–≤ –¥–æ –Ω–∞—á–∞–ª–∞ decay guided loss",
                    "üîß –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—é attention –≤–µ—Å–æ–≤"
                ])
            
            if problem['type'] == 'non_monotonic':
                recommendations.extend([
                    "üîß –í–∫–ª—é—á–∏—Ç—å forward attention constraint",
                    "üîß –£–≤–µ–ª–∏—á–∏—Ç—å sigma –ø–∞—Ä–∞–º–µ—Ç—Ä –≤ guided attention",
                    "üîß –î–æ–±–∞–≤–∏—Ç—å monotonic alignment regularization"
                ])
                
            if problem['type'] == 'unfocused_attention':
                recommendations.extend([
                    "üîß –£–º–µ–Ω—å—à–∏—Ç—å dropout –≤ attention —Å–ª–æ—è—Ö",
                    "üîß –£–≤–µ–ª–∏—á–∏—Ç—å attention dimension",
                    "üîß –ü—Ä–æ–≤–µ—Ä–∏—Ç—å location-based attention –ø–∞—Ä–∞–º–µ—Ç—Ä—ã"
                ])
        
        # –û–±—â–∏–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
        if diagnostics['diagonal_score'] < 0.5:
            recommendations.append("üìä –ü—Ä–æ–¥–æ–ª–∂–∏—Ç—å –æ–±—É—á–µ–Ω–∏–µ - –º–æ–¥–µ–ª—å –µ—â–µ –Ω–µ –Ω–∞—É—á–∏–ª–∞—Å—å alignment")
        
        return list(set(recommendations))  # –£–±–∏—Ä–∞–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã
    
    def _calculate_overall_score(self, diagnostics: Dict) -> float:
        """–í—ã—á–∏—Å–ª—è–µ—Ç –æ–±—â—É—é –æ—Ü–µ–Ω–∫—É –∫–∞—á–µ—Å—Ç–≤–∞ alignment."""
        weights = {
            'diagonal_score': 0.4,
            'monotonic_score': 0.3,
            'focus_score': 0.2,
            'entropy_score': 0.1  # –û–±—Ä–∞—Ç–Ω—ã–π –≤–µ—Å - –Ω–∏–∑–∫–∞—è —ç–Ω—Ç—Ä–æ–ø–∏—è –ª—É—á—à–µ
        }
        
        score = 0.0
        for metric, weight in weights.items():
            if metric == 'entropy_score':
                # –î–ª—è —ç–Ω—Ç—Ä–æ–ø–∏–∏: —á–µ–º –º–µ–Ω—å—à–µ, —Ç–µ–º –ª—É—á—à–µ
                score += (1.0 - diagnostics[metric]) * weight
            else:
                score += diagnostics[metric] * weight
        
        return score
    
    def _log_results(self, results: Dict):
        """–õ–æ–≥–∏—Ä—É–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∞–Ω–∞–ª–∏–∑–∞."""
        logger.info("=" * 60)
        logger.info(f"üìä –î–ò–ê–ì–ù–û–°–¢–ò–ö–ê ALIGNMENT –ú–ê–¢–†–ò–¶–´ - –®–ê–ì {results['step']}")
        logger.info("=" * 60)
        
        # –û—Å–Ω–æ–≤–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏
        diag = results['diagnostics']
        logger.info(f"üéØ –î–∏–∞–≥–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å: {diag['diagonal_score']:.3f}")
        logger.info(f"üìà –ú–æ–Ω–æ—Ç–æ–Ω–Ω–æ—Å—Ç—å: {diag['monotonic_score']:.3f}")
        logger.info(f"üîç –§–æ–∫—É—Å–∏—Ä–æ–≤–∫–∞: {diag['focus_score']:.3f}")
        logger.info(f"üåä –≠–Ω—Ç—Ä–æ–ø–∏—è: {diag['entropy_score']:.3f}")
        logger.info(f"‚≠ê –û–±—â–∞—è –æ—Ü–µ–Ω–∫–∞: {results['overall_score']:.3f}")
        
        # –ü—Ä–æ–±–ª–µ–º—ã
        if results['problems']:
            logger.warning("üö® –û–ë–ù–ê–†–£–ñ–ï–ù–ù–´–ï –ü–†–û–ë–õ–ï–ú–´:")
            for problem in results['problems']:
                logger.warning(f"  - {problem['type']}: {problem['description']}")
        
        # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
        if results['recommendations']:
            logger.info("üí° –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò:")
            for rec in results['recommendations'][:5]:  # –¢–æ–ø-5 —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π
                logger.info(f"  {rec}")
    
    def visualize_alignment(self, alignment: np.ndarray, 
                          step: int, 
                          save_path: str = None) -> str:
        """–°–æ–∑–¥–∞–µ—Ç –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—é alignment –º–∞—Ç—Ä–∏—Ü—ã —Å –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–æ–π."""
        fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 12))
        
        # 1. –û—Å–Ω–æ–≤–Ω–∞—è alignment –º–∞—Ç—Ä–∏—Ü–∞
        im1 = ax1.imshow(alignment, aspect='auto', origin='lower', cmap='Blues')
        ax1.set_title(f'Alignment Matrix (Step {step})')
        ax1.set_xlabel('Encoder timestep')
        ax1.set_ylabel('Decoder timestep')
        plt.colorbar(im1, ax=ax1)
        
        # 2. –î–∏–∞–≥–æ–Ω–∞–ª—å–Ω–∞—è –ø—Ä–æ–µ–∫—Ü–∏—è
        H, W = alignment.shape
        diagonal_profile = []
        for i in range(H):
            diag_pos = int((i / H) * W)
            if diag_pos < W:
                diagonal_profile.append(alignment[i, diag_pos])
            else:
                diagonal_profile.append(0)
        
        ax2.plot(diagonal_profile, 'r-', linewidth=2)
        ax2.set_title('Diagonal Attention Profile')
        ax2.set_xlabel('Decoder timestep')
        ax2.set_ylabel('Attention weight')
        ax2.grid(True, alpha=0.3)
        
        # 3. Attention —Ñ–æ–∫—É—Å –ø–æ –≤—Ä–µ–º–µ–Ω–Ω—ã–º —à–∞–≥–∞–º
        attention_peaks = [np.argmax(alignment[i]) for i in range(H)]
        ideal_peaks = [int((i / H) * W) for i in range(H)]
        
        ax3.plot(attention_peaks, 'b-', label='Actual peaks', linewidth=2)
        ax3.plot(ideal_peaks, 'r--', label='Ideal diagonal', linewidth=2)
        ax3.set_title('Attention Peak Progression')
        ax3.set_xlabel('Decoder timestep')
        ax3.set_ylabel('Encoder timestep')
        ax3.legend()
        ax3.grid(True, alpha=0.3)
        
        # 4. Attention —ç–Ω—Ç—Ä–æ–ø–∏—è –ø–æ —Å—Ç—Ä–æ–∫–∞–º
        entropies = []
        for i in range(H):
            row = alignment[i]
            if np.sum(row) > 0:
                row_norm = row / np.sum(row)
                entropy = -np.sum(row_norm * np.log(row_norm + 1e-8))
                entropies.append(entropy)
            else:
                entropies.append(0)
        
        ax4.plot(entropies, 'g-', linewidth=2)
        ax4.set_title('Attention Entropy per Decoder Step')
        ax4.set_xlabel('Decoder timestep')
        ax4.set_ylabel('Entropy')
        ax4.grid(True, alpha=0.3)
        
        plt.tight_layout()
        
        if save_path:
            plt.savefig(save_path, dpi=150, bbox_inches='tight')
            logger.info(f"üíæ –î–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: {save_path}")
            return save_path
        else:
            plt.show()
            return "displayed"

def analyze_current_alignment(alignment_path: str = None, step: int = 500):
    """
    –ë—ã—Å—Ç—Ä—ã–π –∞–Ω–∞–ª–∏–∑ —Ç–µ–∫—É—â–µ–π alignment –º–∞—Ç—Ä–∏—Ü—ã.
    –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ —ç—Ç—É —Ñ—É–Ω–∫—Ü–∏—é –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –≤–∞—à–µ–π –ø—Ä–æ–±–ª–µ–º—ã.
    """
    logger.info("üöÄ –ó–∞–ø—É—Å–∫ –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏ alignment –º–∞—Ç—Ä–∏—Ü—ã")
    
    # –ï—Å–ª–∏ –ø—É—Ç—å –∫ alignment –Ω–µ —É–∫–∞–∑–∞–Ω, —Å–æ–∑–¥–∞–µ–º —Å–∏–º—É–ª—è—Ü–∏—é –ø—Ä–æ–±–ª–µ–º—ã –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
    if alignment_path is None:
        logger.warning("‚ö†Ô∏è –ü—É—Ç—å –∫ alignment –Ω–µ —É–∫–∞–∑–∞–Ω, —Å–æ–∑–¥–∞–µ–º —Å–∏–º—É–ª—è—Ü–∏—é –ø—Ä–æ–±–ª–µ–º—ã")
        # –°–∏–º—É–ª–∏—Ä—É–µ–º –ø—Ä–æ–±–ª–µ–º—É: –≥–æ—Ä–∏–∑–æ–Ω—Ç–∞–ª—å–Ω–∞—è –ø–æ–ª–æ—Å–∞ —Å–≤–µ—Ä—Ö—É
        alignment = np.zeros((200, 2500))
        # –°–æ–∑–¥–∞–µ–º –≥–æ—Ä–∏–∑–æ–Ω—Ç–∞–ª—å–Ω—É—é –ø–æ–ª–æ—Å—É –≤ –≤–µ—Ä—Ö–Ω–µ–π —á–∞—Å—Ç–∏ (–∫–∞–∫ –Ω–∞ –≤–∞—à–µ–º –≥—Ä–∞—Ñ–∏–∫–µ)
        alignment[:50, :] = np.random.exponential(0.1, (50, 2500))
        alignment[:10, :] = np.random.exponential(0.3, (10, 2500))  # –ï—â–µ —è—Ä—á–µ —Å–≤–µ—Ä—Ö—É
    else:
        alignment = np.load(alignment_path)
    
    diagnostics = AlignmentDiagnostics()
    results = diagnostics.analyze_alignment_matrix(alignment, step=step)
    
    # –°–æ–∑–¥–∞–µ–º –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—é
    vis_path = f"alignment_diagnostics_step_{step}.png"
    diagnostics.visualize_alignment(alignment, step, vis_path)
    
    return results

if __name__ == "__main__":
    # –ê–Ω–∞–ª–∏–∑ —Ç–µ–∫—É—â–µ–π –ø—Ä–æ–±–ª–µ–º—ã –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
    results = analyze_current_alignment(step=500)
    
    print("\n" + "="*80)
    print("üéØ –ó–ê–ö–õ–Æ–ß–ï–ù–ò–ï –ü–û –í–ê–®–ï–ô –ü–†–û–ë–õ–ï–ú–ï:")
    print("="*80)
    print(f"–û–±—â–∞—è –æ—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞: {results['overall_score']:.1%}")
    print(f"–î–∏–∞–≥–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å: {results['diagnostics']['diagonal_score']:.1%}")
    print(f"–ú–æ–Ω–æ—Ç–æ–Ω–Ω–æ—Å—Ç—å: {results['diagnostics']['monotonic_score']:.1%}")
    
    if results['problems']:
        print("\nüö® –ö–†–ò–¢–ò–ß–ï–°–ö–ò–ï –ü–†–û–ë–õ–ï–ú–´:")
        for problem in results['problems']:
            print(f"  ‚Ä¢ {problem['description']}")
    
    if results['recommendations']:
        print("\nüí° –ü–ï–†–í–û–û–ß–ï–†–ï–î–ù–´–ï –î–ï–ô–°–¢–í–ò–Ø:")
        for i, rec in enumerate(results['recommendations'][:3], 1):
            print(f"{i}. {rec}") 