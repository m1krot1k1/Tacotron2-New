#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
–û—Å–Ω–æ–≤–Ω–æ–π entrypoint –¥–ª—è –æ–±—É—á–µ–Ω–∏—è Tacotron2 —Å –ø–æ–ª–Ω–æ–π –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–µ–π EnhancedTacotronTrainer
- –ò—Å–ø–æ–ª—å–∑—É–µ—Ç —Ç–æ–ª—å–∫–æ —Å–æ–≤—Ä–µ–º–µ–Ω–Ω—É—é –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É
- –ü–æ–¥–¥–µ—Ä–∂–∫–∞ Smart Tuner, Telegram, MLflow
- –°–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å —Å legacy train.py (—Ç–æ–ª—å–∫–æ –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏)
"""

import argparse
import logging
import os
import sys
import yaml
import torch
import numpy as np
from typing import Dict, Any, Optional

from enhanced_training_main import EnhancedTacotronTrainer, prepare_dataloaders
from hparams import create_hparams

# === MLflow: –±–µ–∑–æ–ø–∞—Å–Ω–∞—è –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è ===
try:
    import mlflow
    import mlflow.pytorch
    MLFLOW_AVAILABLE = True
except ImportError:
    MLFLOW_AVAILABLE = False

# === Telegram: –±–µ–∑–æ–ø–∞—Å–Ω–∞—è –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è ===
try:
    from smart_tuner.telegram_monitor_enhanced import TelegramMonitorEnhanced
    TELEGRAM_AVAILABLE = True
except ImportError:
    TELEGRAM_AVAILABLE = False


def main():
    parser = argparse.ArgumentParser(description='Enhanced Tacotron2 Training Entrypoint')
    parser.add_argument('--config', type=str, default='smart_tuner/config.yaml', help='–ü—É—Ç—å –∫ –∫–æ–Ω—Ñ–∏–≥—É Smart Tuner')
    parser.add_argument('--epochs', type=int, default=None, help='–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —ç–ø–æ—Ö –æ–±—É—á–µ–Ω–∏—è')
    parser.add_argument('--batch_size', type=int, default=None, help='–†–∞–∑–º–µ—Ä batch')
    parser.add_argument('--learning_rate', type=float, default=None, help='Learning rate')
    parser.add_argument('--mode', type=str, choices=['train', 'validate', 'test'], default='train', help='–†–µ–∂–∏–º —Ä–∞–±–æ—Ç—ã')
    parser.add_argument('--output', type=str, default='output', help='–î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è —á–µ–∫–ø–æ–∏–Ω—Ç–æ–≤ –∏ –ª–æ–≥–æ–≤')
    args = parser.parse_args()

    # === –ó–∞–≥—Ä—É–∑–∫–∞ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ ===
    hparams = create_hparams()
    if args.epochs:
        hparams.epochs = args.epochs
    if args.batch_size:
        hparams.batch_size = args.batch_size
    if args.learning_rate:
        hparams.learning_rate = args.learning_rate

    # === –ó–∞–≥—Ä—É–∑–∫–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ Smart Tuner ===
    config = {}
    if os.path.exists(args.config):
        with open(args.config, 'r', encoding='utf-8') as f:
            config = yaml.safe_load(f)

    # === Telegram Monitor ===
    telegram_monitor = None
    if TELEGRAM_AVAILABLE and config.get('telegram', {}).get('enabled', False):
        tg = config['telegram']
        telegram_monitor = TelegramMonitorEnhanced(
            bot_token=tg.get('bot_token'),
            chat_id=tg.get('chat_id'),
            enabled=True
        )

    # === –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö ===
    train_loader, val_loader = prepare_dataloaders(hparams)

    # === –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –¥–∞—Ç–∞—Å–µ—Ç–µ (–º–æ–∂–Ω–æ —Ä–∞—Å—à–∏—Ä–∏—Ç—å) ===
    dataset_info = {
        'total_duration_minutes': 120,
        'num_speakers': 1,
        'voice_complexity': 'moderate',
        'audio_quality': 'good',
        'language': 'ru'
    }

    # === –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Ç—Ä–µ–Ω–µ—Ä–∞ ===
    trainer = EnhancedTacotronTrainer(hparams, dataset_info)
    if telegram_monitor:
        trainer.telegram_monitor = telegram_monitor
    
    # üîß –ö–†–ò–¢–ò–ß–ï–°–ö–û–ï –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–∏
    print("üîß –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤ –æ–±—É—á–µ–Ω–∏—è...")
    trainer.initialize_training()

    # === –ó–∞–ø—É—Å–∫ –æ–±—É—á–µ–Ω–∏—è ===
    if args.mode == 'train':
        print('üöÄ –ó–∞–ø—É—Å–∫ –æ–±—É—á–µ–Ω–∏—è —á–µ—Ä–µ–∑ EnhancedTacotronTrainer...')
        trainer.train(train_loader, val_loader, max_epochs=hparams.epochs)
        print('üéâ –û–±—É—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ!')
    elif args.mode == 'validate':
        print('üîç –í–∞–ª–∏–¥–∞—Ü–∏—è –º–æ–¥–µ–ª–∏...')
        val_result = trainer.validate_step(val_loader)
        print(f'–í–∞–ª–∏–¥–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞: {val_result}')
    elif args.mode == 'test':
        print('üß™ –¢–µ—Å—Ç–æ–≤—ã–π –∑–∞–ø—É—Å–∫...')
        batch = next(iter(train_loader))
        result = trainer.train_step(batch)
        print(f'–¢–µ—Å—Ç–æ–≤—ã–π —à–∞–≥: {result}')

if __name__ == "__main__":
    main() 