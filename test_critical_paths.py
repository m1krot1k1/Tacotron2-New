#!/usr/bin/env python3
"""
üß™ Unit-—Ç–µ—Å—Ç—ã –¥–ª—è –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏—Ö –ø—É—Ç–µ–π Tacotron2-New
–ü—Ä–æ–≤–µ—Ä–∫–∞ NaN-recovery, emergency restart, distributed —Ä–µ–∂–∏–º–∞
"""

import unittest
import torch
import numpy as np
import tempfile
import os
import sys
from pathlib import Path

# –î–æ–±–∞–≤–ª—è–µ–º –∫–æ—Ä–Ω–µ–≤—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –≤ –ø—É—Ç—å
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from hparams import create_hparams
from smart_tuner.optimization_engine import OptimizationEngine
from smart_tuner.optuna_integration import OptunaTrainerIntegration


class TestCriticalPaths(unittest.TestCase):
    """–¢–µ—Å—Ç—ã –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏—Ö –ø—É—Ç–µ–π —Å–∏—Å—Ç–µ–º—ã"""
    
    def setUp(self):
        """–ù–∞—Å—Ç—Ä–æ–π–∫–∞ —Ç–µ—Å—Ç–æ–≤"""
        self.hparams = create_hparams()
        self.temp_dir = tempfile.mkdtemp()
        
    def tearDown(self):
        """–û—á–∏—Å—Ç–∫–∞ –ø–æ—Å–ª–µ —Ç–µ—Å—Ç–æ–≤"""
        import shutil
        shutil.rmtree(self.temp_dir, ignore_errors=True)
    
    def test_nan_recovery(self):
        """–¢–µ—Å—Ç –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è –ø–æ—Å–ª–µ NaN"""
        print("üß™ –¢–µ—Å—Ç–∏—Ä—É–µ–º NaN recovery...")
        
        # –°–æ–∑–¥–∞–µ–º —Ç–µ–Ω–∑–æ—Ä —Å NaN
        nan_tensor = torch.tensor([1.0, float('nan'), 3.0])
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–µ—Ç–µ–∫—Ü–∏—é NaN
        self.assertTrue(torch.isnan(nan_tensor).any())
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ
        recovered_tensor = torch.where(torch.isnan(nan_tensor), torch.tensor(0.0), nan_tensor)
        self.assertFalse(torch.isnan(recovered_tensor).any())
        
        print("‚úÖ NaN recovery —Ä–∞–±–æ—Ç–∞–µ—Ç –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ")
    
    def test_emergency_restart_params(self):
        """–¢–µ—Å—Ç –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ —ç–∫—Å—Ç—Ä–µ–Ω–Ω–æ–≥–æ –ø–µ—Ä–µ–∑–∞–ø—É—Å–∫–∞"""
        print("üß™ –¢–µ—Å—Ç–∏—Ä—É–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã emergency restart...")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–æ–∑–¥–∞–Ω–∏–µ –±–µ–∑–æ–ø–∞—Å–Ω—ã—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
        safe_hparams = create_hparams()
        safe_hparams.learning_rate = 1e-6  # –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π LR
        safe_hparams.batch_size = 2        # –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π batch
        safe_hparams.grad_clip_thresh = 0.01  # –°—Ç—Ä–æ–≥–æ–µ –∫–ª–∏–ø–∏—Ä–æ–≤–∞–Ω–∏–µ
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ –±–µ–∑–æ–ø–∞—Å–Ω—ã–µ
        self.assertLess(safe_hparams.learning_rate, 1e-5)
        self.assertLess(safe_hparams.batch_size, 4)
        self.assertLess(safe_hparams.grad_clip_thresh, 0.1)
        
        print("‚úÖ Emergency restart –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã")
    
    def test_optimization_engine_initialization(self):
        """–¢–µ—Å—Ç –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ Optimization Engine"""
        print("üß™ –¢–µ—Å—Ç–∏—Ä—É–µ–º –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—é Optimization Engine...")
        
        try:
            # –°–æ–∑–¥–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π –∫–æ–Ω—Ñ–∏–≥
            config_content = """
optimization:
  n_trials: 5
  direction: minimize
  
hyperparameter_search_space:
  learning_rate:
    type: float
    min: 1e-6
    max: 1e-3
  batch_size:
    type: int
    min: 4
    max: 32
    
training_safety:
  tts_quality_checks:
    min_attention_alignment: 0.1
    max_validation_loss: 10.0
"""
            
            config_path = os.path.join(self.temp_dir, "test_config.yaml")
            with open(config_path, 'w') as f:
                f.write(config_content)
            
            # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º Optimization Engine
            engine = OptimizationEngine(config_path)
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ engine –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω
            self.assertIsNotNone(engine)
            self.assertIsNotNone(engine.config)
            
            print("‚úÖ Optimization Engine –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ")
            
        except Exception as e:
            self.fail(f"–û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ Optimization Engine: {e}")
    
    def test_optuna_integration(self):
        """–¢–µ—Å—Ç –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ Optuna"""
        print("üß™ –¢–µ—Å—Ç–∏—Ä—É–µ–º –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—é Optuna...")
        
        try:
            # –°–æ–∑–¥–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π –∫–æ–Ω—Ñ–∏–≥
            config_content = """
optimization:
  n_trials: 3
  direction: minimize
  
hyperparameter_search_space:
  learning_rate:
    type: float
    min: 1e-5
    max: 1e-3
  batch_size:
    type: int
    min: 4
    max: 16
"""
            
            config_path = os.path.join(self.temp_dir, "test_config.yaml")
            with open(config_path, 'w') as f:
                f.write(config_content)
            
            # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—é
            integration = OptunaTrainerIntegration(config_path)
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ integration –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω
            self.assertIsNotNone(integration)
            self.assertIsNotNone(integration.optimization_engine)
            
            print("‚úÖ Optuna –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Ä–∞–±–æ—Ç–∞–µ—Ç –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ")
            
        except Exception as e:
            self.fail(f"–û—à–∏–±–∫–∞ –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ Optuna: {e}")
    
    def test_distributed_restart_logic(self):
        """–¢–µ—Å—Ç –ª–æ–≥–∏–∫–∏ distributed restart"""
        print("üß™ –¢–µ—Å—Ç–∏—Ä—É–µ–º –ª–æ–≥–∏–∫—É distributed restart...")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ª–æ–≥–∏–∫—É –ø–µ—Ä–µ–∑–∞–ø—É—Å–∫–∞ –±–µ–∑ —Ä–µ–∞–ª—å–Ω–æ–≥–æ distributed
        restart_attempts = 0
        max_attempts = 3
        
        def simulate_restart():
            nonlocal restart_attempts
            restart_attempts += 1
            return restart_attempts <= max_attempts
        
        # –°–∏–º—É–ª–∏—Ä—É–µ–º –Ω–µ—Å–∫–æ–ª—å–∫–æ –ø–æ–ø—ã—Ç–æ–∫ –ø–µ—Ä–µ–∑–∞–ø—É—Å–∫–∞
        for i in range(5):
            success = simulate_restart()
            if not success:
                break
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –ø–µ—Ä–µ–∑–∞–ø—É—Å–∫ –æ—Å—Ç–∞–Ω–æ–≤–∏–ª—Å—è –ø–æ—Å–ª–µ max_attempts
        self.assertEqual(restart_attempts, max_attempts)
        
        print("‚úÖ Distributed restart –ª–æ–≥–∏–∫–∞ —Ä–∞–±–æ—Ç–∞–µ—Ç –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ")
    
    def test_hyperparameter_validation(self):
        """–¢–µ—Å—Ç –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤"""
        print("üß™ –¢–µ—Å—Ç–∏—Ä—É–µ–º –≤–∞–ª–∏–¥–∞—Ü–∏—é –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤...")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –≤–∞–ª–∏–¥–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
        valid_params = {
            'learning_rate': 1e-4,
            'batch_size': 16,
            'grad_clip_thresh': 1.0
        }
        
        for param_name, param_value in valid_params.items():
            if hasattr(self.hparams, param_name):
                setattr(self.hparams, param_name, param_value)
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω—ã
        self.assertEqual(self.hparams.learning_rate, 1e-4)
        self.assertEqual(self.hparams.batch_size, 16)
        self.assertEqual(self.hparams.grad_clip_thresh, 1.0)
        
        print("‚úÖ –í–∞–ª–∏–¥–∞—Ü–∏—è –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ —Ä–∞–±–æ—Ç–∞–µ—Ç –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ")
    
    def test_loss_components_handling(self):
        """–¢–µ—Å—Ç –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤ loss"""
        print("üß™ –¢–µ—Å—Ç–∏—Ä—É–µ–º –æ–±—Ä–∞–±–æ—Ç–∫—É –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤ loss...")
        
        # –°–æ–∑–¥–∞–µ–º —Ç–µ—Å—Ç–æ–≤—ã–µ loss –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã
        loss_components = {
            'mel_loss': 1.5,
            'gate_loss': 0.3,
            'guide_loss': 0.2,
            'emb_loss': 0.1
        }
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –≤—Å–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã–µ
        for component_name, component_value in loss_components.items():
            self.assertGreater(component_value, 0)
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –≤—ã—á–∏—Å–ª–µ–Ω–∏–µ –æ–±—â–µ–≥–æ loss
        total_loss = sum(loss_components.values())
        self.assertAlmostEqual(total_loss, 2.1, places=2)
        
        print("‚úÖ –û–±—Ä–∞–±–æ—Ç–∫–∞ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤ loss —Ä–∞–±–æ—Ç–∞–µ—Ç –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ")
    
    def test_attention_diagonality_calculation(self):
        """–¢–µ—Å—Ç –≤—ã—á–∏—Å–ª–µ–Ω–∏—è –¥–∏–∞–≥–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏ attention"""
        print("üß™ –¢–µ—Å—Ç–∏—Ä—É–µ–º –≤—ã—á–∏—Å–ª–µ–Ω–∏–µ –¥–∏–∞–≥–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏ attention...")
        
        # –°–æ–∑–¥–∞–µ–º —Ç–µ—Å—Ç–æ–≤—É—é attention –º–∞—Ç—Ä–∏—Ü—É
        attention_matrix = np.array([
            [0.8, 0.1, 0.1],
            [0.1, 0.8, 0.1],
            [0.1, 0.1, 0.8]
        ])
        
        # –í—ã—á–∏—Å–ª—è–µ–º –¥–∏–∞–≥–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å
        diagonal_elements = np.diag(attention_matrix)
        diagonality = np.mean(diagonal_elements)
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –¥–∏–∞–≥–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å –≤ —Ä–∞–∑—É–º–Ω—ã—Ö –ø—Ä–µ–¥–µ–ª–∞—Ö
        self.assertGreater(diagonality, 0.5)
        self.assertLess(diagonality, 1.0)
        
        print("‚úÖ –í—ã—á–∏—Å–ª–µ–Ω–∏–µ –¥–∏–∞–≥–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏ attention —Ä–∞–±–æ—Ç–∞–µ—Ç –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ")
    
    def test_gradient_clipping(self):
        """–¢–µ—Å—Ç –æ–±—Ä–µ–∑–∞–Ω–∏—è –≥—Ä–∞–¥–∏–µ–Ω—Ç–æ–≤"""
        print("üß™ –¢–µ—Å—Ç–∏—Ä—É–µ–º –æ–±—Ä–µ–∑–∞–Ω–∏–µ –≥—Ä–∞–¥–∏–µ–Ω—Ç–æ–≤...")
        
        # –°–æ–∑–¥–∞–µ–º —Ç–µ—Å—Ç–æ–≤—ã–µ –≥—Ä–∞–¥–∏–µ–Ω—Ç—ã
        gradients = torch.randn(10) * 10  # –ë–æ–ª—å—à–∏–µ –≥—Ä–∞–¥–∏–µ–Ω—Ç—ã
        
        # –ü—Ä–∏–º–µ–Ω—è–µ–º clipping
        max_norm = 1.0
        clipped_gradients = torch.nn.utils.clip_grad_norm_(gradients, max_norm)
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –≥—Ä–∞–¥–∏–µ–Ω—Ç—ã –æ–±—Ä–µ–∑–∞–Ω—ã
        grad_norm = torch.norm(clipped_gradients)
        self.assertLessEqual(grad_norm, max_norm)
        
        print("‚úÖ –û–±—Ä–µ–∑–∞–Ω–∏–µ –≥—Ä–∞–¥–∏–µ–Ω—Ç–æ–≤ —Ä–∞–±–æ—Ç–∞–µ—Ç –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ")
    
    def test_telegram_monitor_fallback(self):
        """–¢–µ—Å—Ç fallback Telegram –º–æ–Ω–∏—Ç–æ—Ä–∞"""
        print("üß™ –¢–µ—Å—Ç–∏—Ä—É–µ–º fallback Telegram –º–æ–Ω–∏—Ç–æ—Ä–∞...")
        
        # –°–∏–º—É–ª–∏—Ä—É–µ–º –æ—Ç—Å—É—Ç—Å—Ç–≤–∏–µ –Ω–∞—Å—Ç—Ä–æ–µ–∫ Telegram
        telegram_config = {
            'bot_token': None,
            'chat_id': None,
            'enabled': False
        }
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —Å–∏—Å—Ç–µ–º–∞ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –æ—Ç—Å—É—Ç—Å—Ç–≤–∏–µ –Ω–∞—Å—Ç—Ä–æ–µ–∫
        if not telegram_config['bot_token'] or not telegram_config['chat_id']:
            telegram_config['enabled'] = False
        
        self.assertFalse(telegram_config['enabled'])
        
        print("‚úÖ Fallback Telegram –º–æ–Ω–∏—Ç–æ—Ä–∞ —Ä–∞–±–æ—Ç–∞–µ—Ç –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ")


class TestSmartTunerIntegration(unittest.TestCase):
    """–¢–µ—Å—Ç—ã –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ Smart Tuner"""
    
    def setUp(self):
        """–ù–∞—Å—Ç—Ä–æ–π–∫–∞ —Ç–µ—Å—Ç–æ–≤"""
        self.temp_dir = tempfile.mkdtemp()
    
    def tearDown(self):
        """–û—á–∏—Å—Ç–∫–∞ –ø–æ—Å–ª–µ —Ç–µ—Å—Ç–æ–≤"""
        import shutil
        shutil.rmtree(self.temp_dir, ignore_errors=True)
    
    def test_smart_tuner_initialization(self):
        """–¢–µ—Å—Ç –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ Smart Tuner"""
        print("üß™ –¢–µ—Å—Ç–∏—Ä—É–µ–º –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—é Smart Tuner...")
        
        try:
            from smart_tuner.smart_tuner_integration import SmartTunerIntegration
            
            # –°–æ–∑–¥–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π –∫–æ–Ω—Ñ–∏–≥
            config_content = """
smart_tuner_enabled: true
optimization_enabled: true
quality_control_enabled: true
early_stopping_enabled: true
adaptive_learning_enabled: true
"""
            
            config_path = os.path.join(self.temp_dir, "test_config.yaml")
            with open(config_path, 'w') as f:
                f.write(config_content)
            
            # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º Smart Tuner
            smart_tuner = SmartTunerIntegration(config_path)
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ Smart Tuner –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω
            self.assertIsNotNone(smart_tuner)
            self.assertIsNotNone(smart_tuner.config)
            
            print("‚úÖ Smart Tuner –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ")
            
        except Exception as e:
            self.fail(f"–û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ Smart Tuner: {e}")


def run_all_tests():
    """–ó–∞–ø—É—Å–∫ –≤—Å–µ—Ö —Ç–µ—Å—Ç–æ–≤"""
    print("üöÄ –ó–∞–ø—É—Å–∫ unit-—Ç–µ—Å—Ç–æ–≤ –¥–ª—è –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏—Ö –ø—É—Ç–µ–π...")
    
    # –°–æ–∑–¥–∞–µ–º test suite
    test_suite = unittest.TestSuite()
    
    # –î–æ–±–∞–≤–ª—è–µ–º —Ç–µ—Å—Ç—ã
    test_suite.addTest(unittest.TestLoader().loadTestsFromTestCase(TestCriticalPaths))
    test_suite.addTest(unittest.TestLoader().loadTestsFromTestCase(TestSmartTunerIntegration))
    
    # –ó–∞–ø—É—Å–∫–∞–µ–º —Ç–µ—Å—Ç—ã
    runner = unittest.TextTestRunner(verbosity=2)
    result = runner.run(test_suite)
    
    # –í—ã–≤–æ–¥–∏–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
    print(f"\nüìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Ç–µ—Å—Ç–æ–≤:")
    print(f"‚úÖ –£—Å–ø–µ—à–Ω—ã—Ö —Ç–µ—Å—Ç–æ–≤: {result.testsRun - len(result.failures) - len(result.errors)}")
    print(f"‚ùå –ù–µ—É–¥–∞—á–Ω—ã—Ö —Ç–µ—Å—Ç–æ–≤: {len(result.failures)}")
    print(f"üö® –û—à–∏–±–æ–∫: {len(result.errors)}")
    
    if result.failures:
        print(f"\n‚ùå –ù–µ—É–¥–∞—á–Ω—ã–µ —Ç–µ—Å—Ç—ã:")
        for test, traceback in result.failures:
            print(f"  - {test}: {traceback}")
    
    if result.errors:
        print(f"\nüö® –û—à–∏–±–∫–∏:")
        for test, traceback in result.errors:
            print(f"  - {test}: {traceback}")
    
    return result.wasSuccessful()


if __name__ == "__main__":
    success = run_all_tests()
    sys.exit(0 if success else 1) 