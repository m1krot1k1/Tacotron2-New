#!/usr/bin/env python3
"""
üîç –¢–µ—Å—Ç —Å–∏—Å—Ç–µ–º—ã Debug Reporter
–ü—Ä–æ–≤–µ—Ä—è–µ—Ç —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å —Å–±–æ—Ä–∞ –∏ –æ—Ç–ø—Ä–∞–≤–∫–∏ debug –æ—Ç—á–µ—Ç–æ–≤
"""

import numpy as np
import torch
from debug_reporter import initialize_debug_reporter

# –°–æ–∑–¥–∞–µ–º –º–æ–∫ telegram_monitor –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
class MockTelegramMonitor:
    def __init__(self):
        self.bot_token = "test_token"
        self.chat_id = "test_chat"
        self.messages_sent = []
        self.files_sent = []
    
    def _send_text_message(self, text, parse_mode="Markdown"):
        self.messages_sent.append(text)
        print(f"üì± Mock Telegram: –û—Ç–ø—Ä–∞–≤–ª–µ–Ω–æ —Å–æ–æ–±—â–µ–Ω–∏–µ ({len(text)} —Å–∏–º–≤–æ–ª–æ–≤)")
        return True
    
    def _send_document(self, filename, caption):
        self.files_sent.append((filename, caption))
        print(f"üìÑ Mock Telegram: –û—Ç–ø—Ä–∞–≤–ª–µ–Ω —Ñ–∞–π–ª {filename}")
        return True

def test_debug_reporter():
    print("üîç –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ Debug Reporter...")
    
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º mock telegram
    mock_telegram = MockTelegramMonitor()
    
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º debug reporter
    debug_reporter = initialize_debug_reporter(mock_telegram)
    
    print("‚úÖ Debug Reporter –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
    
    # –°–æ–∑–¥–∞–µ–º —Ç–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ
    for step in range(1, 1005):  # –¢–µ—Å—Ç–∏—Ä—É–µ–º –¥–æ –æ—Ç–ø—Ä–∞–≤–∫–∏ –æ—Ç—á–µ—Ç–∞
        # –°–∏–º—É–ª–∏—Ä—É–µ–º –º–µ—Ç—Ä–∏–∫–∏
        loss = 2.5 + np.random.normal(0, 0.1)  # –ù–æ—Ä–º–∞–ª—å–Ω—ã–π loss
        if step > 500:  # –£—Ö—É–¥—à–µ–Ω–∏–µ –ø–æ—Å–ª–µ 500 —à–∞–≥–æ–≤
            loss += 0.01 * (step - 500)
        
        metrics = {
            'loss': loss,
            'grad_norm': np.random.uniform(0.1, 2.0),
            'learning_rate': 1e-4,
            'batch_size': 32,
            'iteration': step,
            'epoch': step // 100,
            'diagonality': max(0, min(1, 0.8 + np.random.normal(0, 0.1))),
            'quality': max(0, min(1, 0.75 + np.random.normal(0, 0.05)))
        }
        
        # –°–∏–º—É–ª–∏—Ä—É–µ–º y_pred —Å attention
        mel_len, text_len = 80, 20
        attention_matrix = np.random.rand(mel_len, text_len)
        # –î–µ–ª–∞–µ–º –±–æ–ª–µ–µ –¥–∏–∞–≥–æ–Ω–∞–ª—å–Ω—ã–º
        for i in range(mel_len):
            j = int(i * text_len / mel_len)
            if j < text_len:
                attention_matrix[i, j] += 0.5
        
        # –°–æ–∑–¥–∞–µ–º –º–æ–∫ y_pred
        alignments = torch.tensor(attention_matrix).unsqueeze(0)  # –î–æ–±–∞–≤–ª—è–µ–º batch dim
        y_pred = [None, None, None, alignments]  # Mock y_pred
        
        # Loss –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã
        loss_components = {
            'total_loss': loss,
            'mel_loss': loss * 0.7,
            'gate_loss': loss * 0.2,
            'guided_loss': loss * 0.1
        }
        
        # Mock hparams
        class MockHparams:
            learning_rate = 1e-4
            batch_size = 32
            use_guided_attn = True
            grad_clip_thresh = 1.0
            
        hparams = MockHparams()
        
        # Smart tuner decisions
        smart_tuner_decisions = {
            'quality_controller': {
                'active': True,
                'status': '–ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –∫–∞—á–µ—Å—Ç–≤–∞'
            },
            'recommendations': ['–°—Ç–∞–±–∏–ª—å–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ'],
            'warnings': ['–ù–µ–±–æ–ª—å—à–æ–µ —É–≤–µ–ª–∏—á–µ–Ω–∏–µ loss'] if step > 800 else []
        }
        
        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –¥–∞–Ω–Ω—ã–µ –≤ debug reporter
        debug_reporter.collect_step_data(
            step=step,
            metrics=metrics,
            model=None,  # –î–ª—è —Ç–µ—Å—Ç–∞ –Ω–µ –ø–µ—Ä–µ–¥–∞–µ–º –º–æ–¥–µ–ª—å
            y_pred=y_pred,
            loss_components=loss_components,
            hparams=hparams,
            smart_tuner_decisions=smart_tuner_decisions
        )
        
        if step % 200 == 0:
            print(f"üîÑ –û–±—Ä–∞–±–æ—Ç–∞–Ω —à–∞–≥ {step}, loss: {loss:.4f}")
    
    print("\nüìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è:")
    print(f"  ‚Ä¢ –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ —à–∞–≥–æ–≤: 1004")
    print(f"  ‚Ä¢ –û—Ç–ø—Ä–∞–≤–ª–µ–Ω–æ —Å–æ–æ–±—â–µ–Ω–∏–π: {len(mock_telegram.messages_sent)}")
    print(f"  ‚Ä¢ –û—Ç–ø—Ä–∞–≤–ª–µ–Ω–æ —Ñ–∞–π–ª–æ–≤: {len(mock_telegram.files_sent)}")
    
    if mock_telegram.files_sent:
        last_file = mock_telegram.files_sent[-1]
        print(f"  ‚Ä¢ –ü–æ—Å–ª–µ–¥–Ω–∏–π –æ—Ç—á–µ—Ç: {last_file[0]}")
        print(f"  ‚Ä¢ –ü–æ–¥–ø–∏—Å—å: {last_file[1][:50]}...")
    
    print("\n‚úÖ –¢–µ—Å—Ç –∑–∞–≤–µ—Ä—à–µ–Ω —É—Å–ø–µ—à–Ω–æ!")

if __name__ == "__main__":
    test_debug_reporter() 