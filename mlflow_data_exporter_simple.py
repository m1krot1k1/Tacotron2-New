#!/usr/bin/env python3
"""
–£–ø—Ä–æ—â–µ–Ω–Ω—ã–π —Å–∫—Ä–∏–ø—Ç –¥–ª—è —ç–∫—Å–ø–æ—Ä—Ç–∞ –∏ –∞–Ω–∞–ª–∏–∑–∞ –¥–∞–Ω–Ω—ã—Ö –∏–∑ MLflow

–ê–≤—Ç–æ—Ä: Smart Tuner System
–ù–∞–∑–Ω–∞—á–µ–Ω–∏–µ: –≠–∫—Å–ø–æ—Ä—Ç –¥–∞–Ω–Ω—ã—Ö –æ–±—É—á–µ–Ω–∏—è –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –ø—Ä–∏—á–∏–Ω –æ—Å—Ç–∞–Ω–æ–≤–∫–∏
"""

import mlflow
import json
import os
from datetime import datetime
from pathlib import Path

class MLFlowDataExporter:
    """
    –≠–∫—Å–ø–æ—Ä—Ç–µ—Ä –¥–∞–Ω–Ω—ã—Ö –∏–∑ MLflow –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –ø—Ä–∏—á–∏–Ω –æ—Å—Ç–∞–Ω–æ–≤–∫–∏ –æ–±—É—á–µ–Ω–∏—è
    """
    
    def __init__(self, tracking_uri="mlruns", experiment_name="tacotron2_production"):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —ç–∫—Å–ø–æ—Ä—Ç–µ—Ä–∞
        
        Args:
            tracking_uri: URI –¥–ª—è MLflow
            experiment_name: –ò–º—è —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞
        """
        self.tracking_uri = tracking_uri
        self.experiment_name = experiment_name
        mlflow.set_tracking_uri(tracking_uri)
        self.client = mlflow.tracking.MlflowClient(tracking_uri=tracking_uri)
        
        # –°–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –¥–ª—è —ç–∫—Å–ø–æ—Ä—Ç–∞
        self.export_dir = Path("mlflow_export")
        self.export_dir.mkdir(exist_ok=True)
        
        print(f"üîç MLFlow Data Exporter –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
        print(f"üìÅ URI: {tracking_uri}")
        print(f"üéØ –≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç: {experiment_name}")
        print(f"üíæ –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è —ç–∫—Å–ø–æ—Ä—Ç–∞: {self.export_dir}")
    
    def export_run_data(self, run_id):
        """
        –≠–∫—Å–ø–æ—Ä—Ç –¥–∞–Ω–Ω—ã—Ö –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ run
        
        Args:
            run_id: ID run –¥–ª—è —ç–∫—Å–ø–æ—Ä—Ç–∞
            
        Returns:
            dict: –≠–∫—Å–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
        """
        try:
            run = self.client.get_run(run_id)
            
            # –ë–∞–∑–æ–≤–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ run
            run_info = {
                "run_id": run.info.run_id,
                "experiment_id": run.info.experiment_id,
                "status": run.info.status,
                "start_time": run.info.start_time,
                "end_time": run.info.end_time,
                "duration_ms": run.info.end_time - run.info.start_time if run.info.end_time else None,
                "lifecycle_stage": run.info.lifecycle_stage,
                "artifact_uri": run.info.artifact_uri
            }
            
            # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã
            params = dict(run.data.params)
            
            # –ú–µ—Ç—Ä–∏–∫–∏ (—Ç–µ–∫—É—â–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è)
            metrics = dict(run.data.metrics)
            
            # –ò—Å—Ç–æ—Ä–∏—è –º–µ—Ç—Ä–∏–∫
            metrics_history = {}
            for metric_name in metrics.keys():
                history = self.client.get_metric_history(run_id, metric_name)
                metrics_history[metric_name] = [
                    {
                        "timestamp": metric.timestamp,
                        "step": metric.step,
                        "value": metric.value
                    }
                    for metric in history
                ]
            
            # –¢–µ–≥–∏
            tags = dict(run.data.tags)
            
            return {
                "info": run_info,
                "params": params,
                "metrics": metrics,
                "metrics_history": metrics_history,
                "tags": tags
            }
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ —ç–∫—Å–ø–æ—Ä—Ç–∞ run {run_id}: {e}")
            return None
    
    def analyze_training_failure(self, run_data):
        """
        –ê–Ω–∞–ª–∏–∑ –ø—Ä–∏—á–∏–Ω –æ—Å—Ç–∞–Ω–æ–≤–∫–∏ –æ–±—É—á–µ–Ω–∏—è
        
        Args:
            run_data: –î–∞–Ω–Ω—ã–µ run –∏–∑ export_run_data
            
        Returns:
            dict: –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –∞–Ω–∞–ª–∏–∑–∞
        """
        if not run_data:
            return {"error": "–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞"}
        
        analysis = {
            "summary": {},
            "potential_issues": [],
            "recommendations": [],
            "metrics_analysis": {}
        }
        
        info = run_data["info"]
        metrics_history = run_data["metrics_history"]
        
        # –ê–Ω–∞–ª–∏–∑ –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
        if info["duration_ms"]:
            duration_hours = info["duration_ms"] / (1000 * 60 * 60)
            analysis["summary"]["duration_hours"] = round(duration_hours, 2)
            
            if duration_hours < 3:
                analysis["potential_issues"].append(
                    f"‚è∞ –°–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–æ–µ –æ–±—É—á–µ–Ω–∏–µ: {duration_hours:.1f} —á–∞—Å–æ–≤"
                )
        
        # –ê–Ω–∞–ª–∏–∑ —Å—Ç–∞—Ç—É—Å–∞
        if info["status"] == "FINISHED":
            analysis["potential_issues"].append(
                "üî¥ –û–±—É—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–∏–ª–æ—Å—å –ø—Ä–µ–∂–¥–µ–≤—Ä–µ–º–µ–Ω–Ω–æ (—Å—Ç–∞—Ç—É—Å: FINISHED)"
            )
        elif info["status"] == "FAILED":
            analysis["potential_issues"].append(
                "üí• –û–±—É—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–∏–ª–æ—Å—å —Å –æ—à–∏–±–∫–æ–π (—Å—Ç–∞—Ç—É—Å: FAILED)"
            )
        
        # –ê–Ω–∞–ª–∏–∑ –º–µ—Ç—Ä–∏–∫
        for metric_name, history in metrics_history.items():
            if not history:
                continue
                
            values = [h["value"] for h in history]
            steps = [h["step"] for h in history]
            
            if not values:
                continue
            
            metric_analysis = {
                "total_steps": len(steps),
                "final_value": values[-1],
                "min_value": min(values),
                "max_value": max(values),
                "trend": "–Ω–µ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω"
            }
            
            # –ê–Ω–∞–ª–∏–∑ —Ç—Ä–µ–Ω–¥–∞ (–ø–æ—Å–ª–µ–¥–Ω–∏–µ 20% –∑–Ω–∞—á–µ–Ω–∏–π)
            if len(values) > 10:
                recent_count = max(5, len(values) // 5)
                recent_values = values[-recent_count:]
                early_values = values[:recent_count]
                
                if len(recent_values) > 1 and len(early_values) > 1:
                    recent_avg = sum(recent_values) / len(recent_values)
                    early_avg = sum(early_values) / len(early_values)
                    
                    if "loss" in metric_name.lower():
                        if recent_avg < early_avg * 0.95:
                            metric_analysis["trend"] = "—É–ª—É—á—à–∞–µ—Ç—Å—è"
                        elif recent_avg > early_avg * 1.05:
                            metric_analysis["trend"] = "—É—Ö—É–¥—à–∞–µ—Ç—Å—è"
                        else:
                            metric_analysis["trend"] = "—Å—Ç–∞–±–∏–ª–µ–Ω"
                    else:
                        if recent_avg > early_avg * 1.05:
                            metric_analysis["trend"] = "—Ä–∞—Å—Ç–µ—Ç"
                        elif recent_avg < early_avg * 0.95:
                            metric_analysis["trend"] = "–ø–∞–¥–∞–µ—Ç"
                        else:
                            metric_analysis["trend"] = "—Å—Ç–∞–±–∏–ª–µ–Ω"
            
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –∑–∞–≤–∏—Å–∞–Ω–∏–µ (–æ–¥–∏–Ω–∞–∫–æ–≤—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –ø–æ–¥—Ä—è–¥)
            if len(values) > 20:
                last_values = values[-20:]
                rounded_values = [round(v, 6) for v in last_values]
                if len(set(rounded_values)) == 1:
                    analysis["potential_issues"].append(
                        f"üîí –ú–µ—Ç—Ä–∏–∫–∞ {metric_name} –∑–∞–≤–∏—Å–ª–∞ –Ω–∞ –∑–Ω–∞—á–µ–Ω–∏–∏ {last_values[0]:.6f}"
                    )
            
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –≤–∑—Ä—ã–≤–Ω–æ–π –≥—Ä–∞–¥–∏–µ–Ω—Ç
            if "grad_norm" in metric_name:
                if values and max(values) > 100:
                    analysis["potential_issues"].append(
                        f"üí• –í–∑—Ä—ã–≤–Ω–æ–π –≥—Ä–∞–¥–∏–µ–Ω—Ç! –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –Ω–æ—Ä–º–∞: {max(values):.2f}"
                    )
            
            analysis["metrics_analysis"][metric_name] = metric_analysis
        
        # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π
        self._generate_recommendations(analysis, run_data)
        
        return analysis
    
    def _generate_recommendations(self, analysis, run_data):
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π –ø–æ —É–ª—É—á—à–µ–Ω–∏—é –æ–±—É—á–µ–Ω–∏—è"""
        recommendations = []
        
        # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
        if analysis["summary"].get("duration_hours", 0) < 5:
            recommendations.append(
                "‚è≥ –£–≤–µ–ª–∏—á–∏—Ç—å –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –≤—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è (—Å–µ–π—á–∞—Å —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–æ–µ)"
            )
        
        # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ –≥—Ä–∞–¥–∏–µ–Ω—Ç–∞–º
        grad_issues = [issue for issue in analysis["potential_issues"] if "–≥—Ä–∞–¥–∏–µ–Ω—Ç" in issue.lower()]
        if grad_issues:
            recommendations.append(
                "üìâ –£–º–µ–Ω—å—à–∏—Ç—å learning rate –∏–ª–∏ –¥–æ–±–∞–≤–∏—Ç—å –≥—Ä–∞–¥–∏–µ–Ω—Ç–Ω—ã–π –∫–ª–∏–ø–ø–∏–Ω–≥"
            )
        
        # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ –∑–∞–≤–∏—Å–∞–Ω–∏—é –º–µ—Ç—Ä–∏–∫
        stuck_metrics = [issue for issue in analysis["potential_issues"] if "–∑–∞–≤–∏—Å–ª–∞" in issue]
        if stuck_metrics:
            recommendations.append(
                "üîÑ –î–æ–±–∞–≤–∏—Ç—å –±–æ–ª–µ–µ –∞–≥—Ä–µ—Å—Å–∏–≤–Ω—ã–µ —É—Å–ª–æ–≤–∏—è early stopping"
            )
            recommendations.append(
                "üìä –ü—Ä–æ–≤–µ—Ä–∏—Ç—å —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–∏–µ –¥–∞–Ω–Ω—ã—Ö –∏ –ø–µ—Ä–µ–º–µ—à–∏–≤–∞–Ω–∏–µ"
            )
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ validation loss
        val_loss_history = run_data["metrics_history"].get("validation.loss", [])
        if val_loss_history:
            val_losses = [h["value"] for h in val_loss_history]
            if len(val_losses) > 5:
                recent_losses = val_losses[-5:]
                if all(loss > 10 for loss in recent_losses):  # –í—ã—Å–æ–∫–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è validation loss
                    recommendations.append(
                        "üìà Validation loss —Å–ª–∏—à–∫–æ–º –≤—ã—Å–æ–∫–∏–π - –ø—Ä–æ–≤–µ—Ä–∏—Ç—å –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ –∏–ª–∏ –∫–∞—á–µ—Å—Ç–≤–æ –¥–∞–Ω–Ω—ã—Ö"
                    )
        
        analysis["recommendations"] = recommendations
    
    def export_specific_run(self, run_id):
        """
        –≠–∫—Å–ø–æ—Ä—Ç –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ run –ø–æ ID
        
        Args:
            run_id: ID run –¥–ª—è —ç–∫—Å–ø–æ—Ä—Ç–∞
        """
        print(f"\nüîç –≠–∫—Å–ø–æ—Ä—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è Run ID: {run_id}")
        
        # –≠–∫—Å–ø–æ—Ä—Ç–∏—Ä—É–µ–º –¥–∞–Ω–Ω—ã–µ
        run_data = self.export_run_data(run_id)
        if not run_data:
            print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —ç–∫—Å–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å –¥–∞–Ω–Ω—ã–µ")
            return None
        
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –ø—Ä–∏—á–∏–Ω—ã –æ—Å—Ç–∞–Ω–æ–≤–∫–∏
        analysis = self.analyze_training_failure(run_data)
        
        # –°–æ–∑–¥–∞–µ–º –æ—Ç—á–µ—Ç
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        report_path = self.export_dir / f"training_analysis_{run_id}_{timestamp}.json"
        
        # –û–±—ä–µ–¥–∏–Ω—è–µ–º –≤—Å–µ –¥–∞–Ω–Ω—ã–µ
        full_report = {
            "export_info": {
                "timestamp": timestamp,
                "run_id": run_id,
                "exporter_version": "1.0"
            },
            "run_data": run_data,
            "analysis": analysis
        }
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º JSON –æ—Ç—á–µ—Ç
        with open(report_path, 'w', encoding='utf-8') as f:
            json.dump(full_report, f, indent=2, ensure_ascii=False, default=str)
        
        print(f"üíæ –û—Ç—á–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {report_path}")
        
        # –°–æ–∑–¥–∞–µ–º —Ç–µ–∫—Å—Ç–æ–≤—ã–π –æ—Ç—á–µ—Ç –¥–ª—è —É–¥–æ–±–Ω–æ–≥–æ —á—Ç–µ–Ω–∏—è
        text_report_path = self.export_dir / f"analysis_report_{run_id}_{timestamp}.txt"
        self.create_text_report(full_report, text_report_path)
        
        return full_report
    
    def create_text_report(self, full_report, save_path):
        """–°–æ–∑–¥–∞–Ω–∏–µ —Ç–µ–∫—Å—Ç–æ–≤–æ–≥–æ –æ—Ç—á–µ—Ç–∞ –¥–ª—è —É–¥–æ–±–Ω–æ–≥–æ —á—Ç–µ–Ω–∏—è"""
        with open(save_path, 'w', encoding='utf-8') as f:
            f.write("=" * 80 + "\n")
            f.write("ü§ñ –ê–ù–ê–õ–ò–ó –û–°–¢–ê–ù–û–í–ö–ò –û–ë–£–ß–ï–ù–ò–Ø TACOTRON2\n")
            f.write("=" * 80 + "\n\n")
            
            # –û—Å–Ω–æ–≤–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è
            info = full_report["run_data"]["info"]
            f.write(f"üìä –û–°–ù–û–í–ù–ê–Ø –ò–ù–§–û–†–ú–ê–¶–ò–Ø\n")
            f.write("-" * 40 + "\n")
            f.write(f"Run ID: {info['run_id']}\n")
            f.write(f"–°—Ç–∞—Ç—É—Å: {info['status']}\n")
            f.write(f"–í—Ä–µ–º—è —Å—Ç–∞—Ä—Ç–∞: {datetime.fromtimestamp(info['start_time']/1000)}\n")
            if info['end_time']:
                f.write(f"–í—Ä–µ–º—è –æ–∫–æ–Ω—á–∞–Ω–∏—è: {datetime.fromtimestamp(info['end_time']/1000)}\n")
            if info['duration_ms']:
                hours = info['duration_ms'] / (1000 * 60 * 60)
                f.write(f"–î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å: {hours:.2f} —á–∞—Å–æ–≤\n")
            f.write("\n")
            
            # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –æ–±—É—á–µ–Ω–∏—è
            params = full_report["run_data"]["params"]
            f.write(f"‚öôÔ∏è –ü–ê–†–ê–ú–ï–¢–†–´ –û–ë–£–ß–ï–ù–ò–Ø\n")
            f.write("-" * 40 + "\n")
            for key, value in params.items():
                f.write(f"{key}: {value}\n")
            f.write("\n")
            
            # –§–∏–Ω–∞–ª—å–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏
            metrics = full_report["run_data"]["metrics"]
            f.write(f"üìà –§–ò–ù–ê–õ–¨–ù–´–ï –ú–ï–¢–†–ò–ö–ò\n")
            f.write("-" * 40 + "\n")
            for key, value in metrics.items():
                f.write(f"{key}: {value:.6f}\n")
            f.write("\n")
            
            # –ê–Ω–∞–ª–∏–∑ –ø—Ä–æ–±–ª–µ–º
            analysis = full_report["analysis"]
            f.write(f"üîç –û–ë–ù–ê–†–£–ñ–ï–ù–ù–´–ï –ü–†–û–ë–õ–ï–ú–´\n")
            f.write("-" * 40 + "\n")
            if analysis["potential_issues"]:
                for issue in analysis["potential_issues"]:
                    f.write(f"‚Ä¢ {issue}\n")
            else:
                f.write("–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏—Ö –ø—Ä–æ–±–ª–µ–º –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–æ\n")
            f.write("\n")
            
            # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
            f.write(f"üí° –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò –ü–û –£–õ–£–ß–®–ï–ù–ò–Æ\n")
            f.write("-" * 40 + "\n")
            if analysis["recommendations"]:
                for rec in analysis["recommendations"]:
                    f.write(f"‚Ä¢ {rec}\n")
            else:
                f.write("–°–ø–µ—Ü–∏–∞–ª—å–Ω—ã—Ö —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π –Ω–µ—Ç\n")
            f.write("\n")
            
            # –î–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –º–µ—Ç—Ä–∏–∫
            f.write(f"üìä –î–ï–¢–ê–õ–¨–ù–´–ô –ê–ù–ê–õ–ò–ó –ú–ï–¢–†–ò–ö\n")
            f.write("-" * 40 + "\n")
            for metric_name, metric_analysis in analysis["metrics_analysis"].items():
                f.write(f"\n{metric_name}:\n")
                f.write(f"  ‚Ä¢ –®–∞–≥–æ–≤: {metric_analysis['total_steps']}\n")
                f.write(f"  ‚Ä¢ –§–∏–Ω–∞–ª—å–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ: {metric_analysis['final_value']:.6f}\n")
                f.write(f"  ‚Ä¢ –ú–∏–Ω–∏–º—É–º: {metric_analysis['min_value']:.6f}\n")
                f.write(f"  ‚Ä¢ –ú–∞–∫—Å–∏–º—É–º: {metric_analysis['max_value']:.6f}\n")
                f.write(f"  ‚Ä¢ –¢—Ä–µ–Ω–¥: {metric_analysis['trend']}\n")
        
        print(f"üìÑ –¢–µ–∫—Å—Ç–æ–≤—ã–π –æ—Ç—á–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {save_path}")

def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    print("üöÄ –ó–∞–ø—É—Å–∫ MLflow Data Exporter")
    print("=" * 50)
    
    # –°–æ–∑–¥–∞–µ–º —ç–∫—Å–ø–æ—Ä—Ç–µ—Ä
    exporter = MLFlowDataExporter()
    
    # ID run –∏–∑ –≤–∞—à–µ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è
    target_run_id = "4f9a0a2937fc49a09b0c1233de968601"
    
    # –≠–∫—Å–ø–æ—Ä—Ç–∏—Ä—É–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
    result = exporter.export_specific_run(target_run_id)
    
    if result:
        print("\n‚úÖ –≠–ö–°–ü–û–†–¢ –ó–ê–í–ï–†–®–ï–ù –£–°–ü–ï–®–ù–û!")
        print(f"üìÅ –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é: {exporter.export_dir}")
        
        # –í—ã–≤–æ–¥–∏–º –∫—Ä–∞—Ç–∫–∏–π –∞–Ω–∞–ª–∏–∑ –≤ –∫–æ–Ω—Å–æ–ª—å
        analysis = result["analysis"]
        print(f"\nüîç –ö–†–ê–¢–ö–ò–ô –ê–ù–ê–õ–ò–ó:")
        print(f"   –î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å: {analysis['summary'].get('duration_hours', '–Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–æ')} —á–∞—Å–æ–≤")
        print(f"   –ü—Ä–æ–±–ª–µ–º –æ–±–Ω–∞—Ä—É–∂–µ–Ω–æ: {len(analysis['potential_issues'])}")
        print(f"   –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π: {len(analysis['recommendations'])}")
        
        if analysis["potential_issues"]:
            print(f"\n‚ö†Ô∏è –ì–õ–ê–í–ù–´–ï –ü–†–û–ë–õ–ï–ú–´:")
            for issue in analysis["potential_issues"][:3]:  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ 3
                print(f"   ‚Ä¢ {issue}")
                
        if analysis["recommendations"]:
            print(f"\nüí° –ì–õ–ê–í–ù–´–ï –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò:")
            for rec in analysis["recommendations"][:3]:  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ 3
                print(f"   ‚Ä¢ {rec}")
    else:
        print("‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —ç–∫—Å–ø–æ—Ä—Ç–µ –¥–∞–Ω–Ω—ã—Ö")

if __name__ == "__main__":
    main()