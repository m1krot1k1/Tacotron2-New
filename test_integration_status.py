#!/usr/bin/env python3
"""
üîç –¢–ï–°–¢ –ò–ù–¢–ï–ì–†–ê–¶–ò–ò SMART TUNER V2
–ü—Ä–æ–≤–µ—Ä—è–µ—Ç —Å—Ç–∞—Ç—É—Å –≤—Å–µ—Ö –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤ –∏ –∏—Ö –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—é –≤ –ø—Ä–æ—Ü–µ—Å—Å –æ–±—É—á–µ–Ω–∏—è.
"""

import sys
import os
import torch
import logging
from pathlib import Path

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

def test_smart_tuner_imports():
    """–¢–µ—Å—Ç–∏—Ä—É–µ—Ç –∏–º–ø–æ—Ä—Ç –≤—Å–µ—Ö –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤ Smart Tuner."""
    print("üîç –¢–ï–°–¢ 1: –ò–º–ø–æ—Ä—Ç –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤ Smart Tuner")
    
    components = {
        'gradient_clipper': 'smart_tuner.gradient_clipper',
        'smart_lr_adapter': 'smart_tuner.smart_lr_adapter', 
        'safe_ddc_loss': 'smart_tuner.safe_ddc_loss',
        'integration_manager': 'smart_tuner.integration_manager'
    }
    
    results = {}
    for name, module in components.items():
        try:
            __import__(module)
            results[name] = "‚úÖ –£–°–ü–ï–®–ù–û"
            print(f"  {name}: ‚úÖ –£–°–ü–ï–®–ù–û")
        except ImportError as e:
            results[name] = f"‚ùå –û–®–ò–ë–ö–ê: {e}"
            print(f"  {name}: ‚ùå –û–®–ò–ë–ö–ê: {e}")
    
    return results

def test_component_initialization():
    """–¢–µ—Å—Ç–∏—Ä—É–µ—Ç –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—é –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤."""
    print("\nüîç –¢–ï–°–¢ 2: –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤")
    
    results = {}
    
    # –¢–µ—Å—Ç Gradient Clipper
    try:
        from smart_tuner.gradient_clipper import AdaptiveGradientClipper, get_global_clipper, set_global_clipper
        
        clipper = AdaptiveGradientClipper(max_norm=1.0, adaptive=True)
        set_global_clipper(clipper)
        retrieved_clipper = get_global_clipper()
        
        if retrieved_clipper is not None:
            results['gradient_clipper'] = "‚úÖ –£–°–ü–ï–®–ù–û"
            print("  gradient_clipper: ‚úÖ –£–°–ü–ï–®–ù–û")
        else:
            results['gradient_clipper'] = "‚ùå –û–®–ò–ë–ö–ê: –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å clipper"
            print("  gradient_clipper: ‚ùå –û–®–ò–ë–ö–ê: –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å clipper")
            
    except Exception as e:
        results['gradient_clipper'] = f"‚ùå –û–®–ò–ë–ö–ê: {e}"
        print(f"  gradient_clipper: ‚ùå –û–®–ò–ë–ö–ê: {e}")
    
    # –¢–µ—Å—Ç Smart LR Adapter
    try:
        from smart_tuner.smart_lr_adapter import SmartLRAdapter, get_global_lr_adapter, set_global_lr_adapter
        
        # –°–æ–∑–¥–∞–µ–º —Ñ–∏–∫—Ç–∏–≤–Ω—ã–π –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä
        model = torch.nn.Linear(10, 1)
        optimizer = torch.optim.Adam(model.parameters(), lr=0.001)
        
        lr_adapter = SmartLRAdapter(optimizer=optimizer, patience=10, factor=0.5)
        set_global_lr_adapter(lr_adapter)
        retrieved_adapter = get_global_lr_adapter()
        
        if retrieved_adapter is not None:
            results['smart_lr_adapter'] = "‚úÖ –£–°–ü–ï–®–ù–û"
            print("  smart_lr_adapter: ‚úÖ –£–°–ü–ï–®–ù–û")
        else:
            results['smart_lr_adapter'] = "‚ùå –û–®–ò–ë–ö–ê: –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å adapter"
            print("  smart_lr_adapter: ‚ùå –û–®–ò–ë–ö–ê: –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å adapter")
            
    except Exception as e:
        results['smart_lr_adapter'] = f"‚ùå –û–®–ò–ë–ö–ê: {e}"
        print(f"  smart_lr_adapter: ‚ùå –û–®–ò–ë–ö–ê: {e}")
    
    # –¢–µ—Å—Ç Safe DDC Loss
    try:
        from smart_tuner.safe_ddc_loss import SafeDDCLoss, get_global_ddc_loss, set_global_ddc_loss
        
        ddc_loss = SafeDDCLoss(weight=1.0, use_masking=True)
        set_global_ddc_loss(ddc_loss)
        retrieved_ddc = get_global_ddc_loss()
        
        if retrieved_ddc is not None:
            results['safe_ddc_loss'] = "‚úÖ –£–°–ü–ï–®–ù–û"
            print("  safe_ddc_loss: ‚úÖ –£–°–ü–ï–®–ù–û")
        else:
            results['safe_ddc_loss'] = "‚ùå –û–®–ò–ë–ö–ê: –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å DDC loss"
            print("  safe_ddc_loss: ‚ùå –û–®–ò–ë–ö–ê: –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å DDC loss")
            
    except Exception as e:
        results['safe_ddc_loss'] = f"‚ùå –û–®–ò–ë–ö–ê: {e}"
        print(f"  safe_ddc_loss: ‚ùå –û–®–ò–ë–ö–ê: {e}")
    
    # –¢–µ—Å—Ç Integration Manager
    try:
        from smart_tuner.integration_manager import initialize_smart_tuner
        
        manager = initialize_smart_tuner()
        
        if manager is not None:
            results['integration_manager'] = "‚úÖ –£–°–ü–ï–®–ù–û"
            print("  integration_manager: ‚úÖ –£–°–ü–ï–®–ù–û")
        else:
            results['integration_manager'] = "‚ùå –û–®–ò–ë–ö–ê: –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å manager"
            print("  integration_manager: ‚ùå –û–®–ò–ë–ö–ê: –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å manager")
            
    except Exception as e:
        results['integration_manager'] = f"‚ùå –û–®–ò–ë–ö–ê: {e}"
        print(f"  integration_manager: ‚ùå –û–®–ò–ë–ö–ê: {e}")
    
    return results

def test_train_integration():
    """–¢–µ—Å—Ç–∏—Ä—É–µ—Ç –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—é –≤ train.py."""
    print("\nüîç –¢–ï–°–¢ 3: –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è –≤ train.py")
    
    results = {}
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –∏–º–ø–æ—Ä—Ç–æ–≤ –≤ train.py
    try:
        with open('train.py', 'r', encoding='utf-8') as f:
            train_content = f.read()
        
        required_imports = [
            'from smart_tuner.integration_manager import initialize_smart_tuner',
            'from smart_tuner.gradient_clipper import get_global_clipper, AdaptiveGradientClipper',
            'from smart_tuner.smart_lr_adapter import get_global_lr_adapter, SmartLRAdapter',
            'from smart_tuner.safe_ddc_loss import get_global_ddc_loss, SafeDDCLoss'
        ]
        
        for imp in required_imports:
            if imp in train_content:
                print(f"  {imp}: ‚úÖ –ù–ê–ô–î–ï–ù")
            else:
                print(f"  {imp}: ‚ùå –ù–ï –ù–ê–ô–î–ï–ù")
                results['train_imports'] = "‚ùå –û–®–ò–ë–ö–ê: –ù–µ –≤—Å–µ –∏–º–ø–æ—Ä—Ç—ã –Ω–∞–π–¥–µ–Ω—ã"
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ IntegrationManager
        if 'integration_manager = initialize_smart_tuner()' in train_content:
            print("  –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è IntegrationManager: ‚úÖ –ù–ê–ô–î–ï–ù–ê")
        else:
            print("  –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è IntegrationManager: ‚ùå –ù–ï –ù–ê–ô–î–ï–ù–ê")
            results['train_init'] = "‚ùå –û–®–ò–ë–ö–ê: –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –Ω–µ –Ω–∞–π–¥–µ–Ω–∞"
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –≤—ã–∑–æ–≤–∞ step
        if 'integration_manager.step(' in train_content:
            print("  –í—ã–∑–æ–≤ integration_manager.step(): ‚úÖ –ù–ê–ô–î–ï–ù")
        else:
            print("  –í—ã–∑–æ–≤ integration_manager.step(): ‚ùå –ù–ï –ù–ê–ô–î–ï–ù")
            results['train_step'] = "‚ùå –û–®–ò–ë–ö–ê: –í—ã–∑–æ–≤ step –Ω–µ –Ω–∞–π–¥–µ–Ω"
        
        if 'results' not in results:
            results['train_integration'] = "‚úÖ –£–°–ü–ï–®–ù–û"
            
    except Exception as e:
        results['train_integration'] = f"‚ùå –û–®–ò–ë–ö–ê: {e}"
        print(f"  train_integration: ‚ùå –û–®–ò–ë–ö–ê: {e}")
    
    return results

def test_loss_function_integration():
    """–¢–µ—Å—Ç–∏—Ä—É–µ—Ç –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—é –≤ loss_function.py."""
    print("\nüîç –¢–ï–°–¢ 4: –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è –≤ loss_function.py")
    
    results = {}
    
    try:
        with open('loss_function.py', 'r', encoding='utf-8') as f:
            loss_content = f.read()
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –∏–º–ø–æ—Ä—Ç–æ–≤ SafeDDCLoss
        if 'from smart_tuner.safe_ddc_loss import get_global_ddc_loss, SafeDDCLoss' in loss_content:
            print("  –ò–º–ø–æ—Ä—Ç SafeDDCLoss: ‚úÖ –ù–ê–ô–î–ï–ù")
        else:
            print("  –ò–º–ø–æ—Ä—Ç SafeDDCLoss: ‚ùå –ù–ï –ù–ê–ô–î–ï–ù")
            results['loss_imports'] = "‚ùå –û–®–ò–ë–ö–ê: –ò–º–ø–æ—Ä—Ç SafeDDCLoss –Ω–µ –Ω–∞–π–¥–µ–Ω"
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è SafeDDCLoss
        if 'get_global_ddc_loss()' in loss_content:
            print("  –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ get_global_ddc_loss(): ‚úÖ –ù–ê–ô–î–ï–ù–û")
        else:
            print("  –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ get_global_ddc_loss(): ‚ùå –ù–ï –ù–ê–ô–î–ï–ù–û")
            results['loss_usage'] = "‚ùå –û–®–ò–ë–ö–ê: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ SafeDDCLoss –Ω–µ –Ω–∞–π–¥–µ–Ω–æ"
        
        if 'results' not in results:
            results['loss_integration'] = "‚úÖ –£–°–ü–ï–®–ù–û"
            
    except Exception as e:
        results['loss_integration'] = f"‚ùå –û–®–ò–ë–ö–ê: {e}"
        print(f"  loss_integration: ‚ùå –û–®–ò–ë–ö–ê: {e}")
    
    return results

def test_component_functionality():
    """–¢–µ—Å—Ç–∏—Ä—É–µ—Ç —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤."""
    print("\nüîç –¢–ï–°–¢ 5: –§—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤")
    
    results = {}
    
    # –¢–µ—Å—Ç Gradient Clipper
    try:
        from smart_tuner.gradient_clipper import AdaptiveGradientClipper
        
        model = torch.nn.Linear(10, 1)
        clipper = AdaptiveGradientClipper(max_norm=1.0, adaptive=True)
        
        # –°–æ–∑–¥–∞–µ–º —Ñ–∏–∫—Ç–∏–≤–Ω—ã–µ –≥—Ä–∞–¥–∏–µ–Ω—Ç—ã
        model.weight.grad = torch.randn_like(model.weight) * 10
        model.bias.grad = torch.randn_like(model.bias) * 10
        
        was_clipped, grad_norm, clip_threshold = clipper.clip_gradients(model, step=1)
        
        if isinstance(was_clipped, bool) and isinstance(grad_norm, float):
            results['gradient_clipper_func'] = "‚úÖ –£–°–ü–ï–®–ù–û"
            print("  gradient_clipper —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å: ‚úÖ –£–°–ü–ï–®–ù–û")
        else:
            results['gradient_clipper_func'] = "‚ùå –û–®–ò–ë–ö–ê: –ù–µ–≤–µ—Ä–Ω—ã–π —Ç–∏–ø –≤–æ–∑–≤—Ä–∞—â–∞–µ–º—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π"
            print("  gradient_clipper —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å: ‚ùå –û–®–ò–ë–ö–ê: –ù–µ–≤–µ—Ä–Ω—ã–π —Ç–∏–ø –≤–æ–∑–≤—Ä–∞—â–∞–µ–º—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π")
            
    except Exception as e:
        results['gradient_clipper_func'] = f"‚ùå –û–®–ò–ë–ö–ê: {e}"
        print(f"  gradient_clipper —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å: ‚ùå –û–®–ò–ë–ö–ê: {e}")
    
    # –¢–µ—Å—Ç Smart LR Adapter
    try:
        from smart_tuner.smart_lr_adapter import SmartLRAdapter
        
        model = torch.nn.Linear(10, 1)
        optimizer = torch.optim.Adam(model.parameters(), lr=0.001)
        lr_adapter = SmartLRAdapter(optimizer=optimizer, patience=10, factor=0.5)
        
        # –¢–µ—Å—Ç–∏—Ä—É–µ–º step
        lr_changed = lr_adapter.step(loss=1.0, grad_norm=5.0, step=1)
        
        if isinstance(lr_changed, bool):
            results['lr_adapter_func'] = "‚úÖ –£–°–ü–ï–®–ù–û"
            print("  lr_adapter —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å: ‚úÖ –£–°–ü–ï–®–ù–û")
        else:
            results['lr_adapter_func'] = "‚ùå –û–®–ò–ë–ö–ê: –ù–µ–≤–µ—Ä–Ω—ã–π —Ç–∏–ø –≤–æ–∑–≤—Ä–∞—â–∞–µ–º–æ–≥–æ –∑–Ω–∞—á–µ–Ω–∏—è"
            print("  lr_adapter —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å: ‚ùå –û–®–ò–ë–ö–ê: –ù–µ–≤–µ—Ä–Ω—ã–π —Ç–∏–ø –≤–æ–∑–≤—Ä–∞—â–∞–µ–º–æ–≥–æ –∑–Ω–∞—á–µ–Ω–∏—è")
            
    except Exception as e:
        results['lr_adapter_func'] = f"‚ùå –û–®–ò–ë–ö–ê: {e}"
        print(f"  lr_adapter —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å: ‚ùå –û–®–ò–ë–ö–ê: {e}")
    
    # –¢–µ—Å—Ç Safe DDC Loss
    try:
        from smart_tuner.safe_ddc_loss import SafeDDCLoss
        
        ddc_loss = SafeDDCLoss(weight=1.0, use_masking=True)
        
        # –°–æ–∑–¥–∞–µ–º —Ñ–∏–∫—Ç–∏–≤–Ω—ã–µ —Ç–µ–Ω–∑–æ—Ä—ã
        mel1 = torch.randn(2, 80, 100)
        mel2 = torch.randn(2, 80, 100)
        
        loss_value = ddc_loss(mel1, mel2, step=1)
        
        if isinstance(loss_value, torch.Tensor):
            results['ddc_loss_func'] = "‚úÖ –£–°–ü–ï–®–ù–û"
            print("  ddc_loss —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å: ‚úÖ –£–°–ü–ï–®–ù–û")
        else:
            results['ddc_loss_func'] = "‚ùå –û–®–ò–ë–ö–ê: –ù–µ–≤–µ—Ä–Ω—ã–π —Ç–∏–ø –≤–æ–∑–≤—Ä–∞—â–∞–µ–º–æ–≥–æ –∑–Ω–∞—á–µ–Ω–∏—è"
            print("  ddc_loss —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å: ‚ùå –û–®–ò–ë–ö–ê: –ù–µ–≤–µ—Ä–Ω—ã–π —Ç–∏–ø –≤–æ–∑–≤—Ä–∞—â–∞–µ–º–æ–≥–æ –∑–Ω–∞—á–µ–Ω–∏—è")
            
    except Exception as e:
        results['ddc_loss_func'] = f"‚ùå –û–®–ò–ë–ö–ê: {e}"
        print(f"  ddc_loss —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å: ‚ùå –û–®–ò–ë–ö–ê: {e}")
    
    return results

def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è."""
    print("üöÄ –ó–ê–ü–£–°–ö –¢–ï–°–¢–ê –ò–ù–¢–ï–ì–†–ê–¶–ò–ò SMART TUNER V2")
    print("=" * 60)
    
    # –ó–∞–ø—É—Å–∫–∞–µ–º –≤—Å–µ —Ç–µ—Å—Ç—ã
    test_results = {}
    
    test_results.update(test_smart_tuner_imports())
    test_results.update(test_component_initialization())
    test_results.update(test_train_integration())
    test_results.update(test_loss_function_integration())
    test_results.update(test_component_functionality())
    
    # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
    print("\n" + "=" * 60)
    print("üìä –ò–¢–û–ì–û–í–´–ô –û–¢–ß–ï–¢")
    print("=" * 60)
    
    successful_tests = 0
    total_tests = len(test_results)
    
    for test_name, result in test_results.items():
        if "‚úÖ –£–°–ü–ï–®–ù–û" in result:
            successful_tests += 1
            print(f"‚úÖ {test_name}: {result}")
        else:
            print(f"‚ùå {test_name}: {result}")
    
    print(f"\nüìà –†–ï–ó–£–õ–¨–¢–ê–¢: {successful_tests}/{total_tests} —Ç–µ—Å—Ç–æ–≤ –ø—Ä–æ—à–ª–∏ —É—Å–ø–µ—à–Ω–æ")
    
    if successful_tests == total_tests:
        print("üéâ –í–°–ï –ö–û–ú–ü–û–ù–ï–ù–¢–´ SMART TUNER –£–°–ü–ï–®–ù–û –ò–ù–¢–ï–ì–†–ò–†–û–í–ê–ù–´!")
        return True
    else:
        print("‚ö†Ô∏è –û–ë–ù–ê–†–£–ñ–ï–ù–´ –ü–†–û–ë–õ–ï–ú–´ –° –ò–ù–¢–ï–ì–†–ê–¶–ò–ï–ô!")
        return False

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1) 