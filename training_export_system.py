#!/usr/bin/env python3
"""
–°–∏—Å—Ç–µ–º–∞ —ç–∫—Å–ø–æ—Ä—Ç–∞ –¥–∞–Ω–Ω—ã—Ö –æ–±—É—á–µ–Ω–∏—è –¥–ª—è AI –∞–Ω–∞–ª–∏–∑–∞

–ê–≤—Ç–æ—Ä: AI Assistant
–ù–∞–∑–Ω–∞—á–µ–Ω–∏–µ: –≠–∫—Å–ø–æ—Ä—Ç –∏—Å—Ç–æ—Ä–∏–∏ –æ–±—É—á–µ–Ω–∏—è –≤ —É–¥–æ–±–Ω–æ–º —Ç–µ–∫—Å—Ç–æ–≤–æ–º —Ñ–æ—Ä–º–∞—Ç–µ
"""

import os
import json
import mlflow
from datetime import datetime
from pathlib import Path
import pandas as pd
from typing import Dict, List, Optional

class TrainingExportSystem:
    """
    –°–∏—Å—Ç–µ–º–∞ —ç–∫—Å–ø–æ—Ä—Ç–∞ –¥–∞–Ω–Ω—ã—Ö –æ–±—É—á–µ–Ω–∏—è –¥–ª—è AI –∞–Ω–∞–ª–∏–∑–∞
    """
    
    def __init__(self, export_dir="training_exports"):
        self.export_dir = Path(export_dir)
        self.export_dir.mkdir(exist_ok=True)
        
        # –°–æ–∑–¥–∞–µ–º –ø–æ–¥–ø–∞–ø–∫–∏
        (self.export_dir / "text_reports").mkdir(exist_ok=True)
        (self.export_dir / "csv_data").mkdir(exist_ok=True)
        (self.export_dir / "json_raw").mkdir(exist_ok=True)
        
        print(f"üìÅ Training Export System –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω –≤ {self.export_dir}")
    
    def export_current_training(self, run_id: str = None, format_type: str = "all"):
        """
        –≠–∫—Å–ø–æ—Ä—Ç —Ç–µ–∫—É—â–µ–≥–æ –æ–±—É—á–µ–Ω–∏—è –≤ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö —Ñ–æ—Ä–º–∞—Ç–∞—Ö
        
        Args:
            run_id: ID MLflow run (–µ—Å–ª–∏ None, –±–µ—Ä–µ—Ç—Å—è –ø–æ—Å–ª–µ–¥–Ω–∏–π)
            format_type: —Ç–∏–ø —ç–∫—Å–ø–æ—Ä—Ç–∞ ("text", "csv", "json", "all")
        """
        if run_id is None:
            run_id = self._get_latest_run_id()
        
        if not run_id:
            print("‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω –∞–∫—Ç–∏–≤–Ω—ã–π run –¥–ª—è —ç–∫—Å–ø–æ—Ä—Ç–∞")
            return None
        
        print(f"üìä –ù–∞—á–∏–Ω–∞—é —ç–∫—Å–ø–æ—Ä—Ç run: {run_id}")
        
        # –ü–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∏–∑ MLflow
        training_data = self._extract_mlflow_data(run_id)
        
        if not training_data:
            print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –æ–±—É—á–µ–Ω–∏—è")
            return None
        
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        exported_files = {}
        
        # –≠–∫—Å–ø–æ—Ä—Ç –≤ —Ç–µ–∫—Å—Ç–æ–≤–æ–º —Ñ–æ—Ä–º–∞—Ç–µ (–¥–ª—è AI)
        if format_type in ["text", "all"]:
            text_file = self._export_text_format(training_data, run_id, timestamp)
            exported_files["text"] = text_file
        
        # –≠–∫—Å–ø–æ—Ä—Ç –≤ CSV —Ñ–æ—Ä–º–∞—Ç–µ
        if format_type in ["csv", "all"]:
            csv_file = self._export_csv_format(training_data, run_id, timestamp)
            exported_files["csv"] = csv_file
        
        # –≠–∫—Å–ø–æ—Ä—Ç –≤ JSON —Ñ–æ—Ä–º–∞—Ç–µ
        if format_type in ["json", "all"]:
            json_file = self._export_json_format(training_data, run_id, timestamp)
            exported_files["json"] = json_file
        
        # –°–æ–∑–¥–∞–µ–º –∏—Ç–æ–≥–æ–≤—ã–π –æ—Ç—á–µ—Ç
        summary_file = self._create_export_summary(exported_files, training_data, timestamp)
        
        print("‚úÖ –≠–∫—Å–ø–æ—Ä—Ç –∑–∞–≤–µ—Ä—à–µ–Ω!")
        print(f"üìÑ –§–∞–π–ª—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤: {self.export_dir}")
        
        return {
            "exported_files": exported_files,
            "summary": summary_file,
            "run_id": run_id
        }
    
    def _get_latest_run_id(self):
        """–ü–æ–ª—É—á–∞–µ—Ç ID –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ –∞–∫—Ç–∏–≤–Ω–æ–≥–æ run"""
        try:
            client = mlflow.tracking.MlflowClient()
            experiments = client.search_experiments()
            
            if not experiments:
                return None
            
            # –ò—â–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–π run –≤ –∞–∫—Ç–∏–≤–Ω–æ–º —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–µ
            latest_run = None
            for experiment in experiments:
                runs = client.search_runs(
                    experiment_ids=[experiment.experiment_id],
                    max_results=1,
                    order_by=["start_time DESC"]
                )
                if runs and (latest_run is None or runs[0].info.start_time > latest_run.info.start_time):
                    latest_run = runs[0]
            
            return latest_run.info.run_id if latest_run else None
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ run: {e}")
            return None
    
    def _extract_mlflow_data(self, run_id: str):
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –∏–∑ MLflow"""
        try:
            client = mlflow.tracking.MlflowClient()
            run = client.get_run(run_id)
            
            # –ë–∞–∑–æ–≤–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è
            run_info = {
                "run_id": run.info.run_id,
                "experiment_id": run.info.experiment_id,
                "status": run.info.status,
                "start_time": run.info.start_time,
                "end_time": run.info.end_time,
                "duration_ms": run.info.end_time - run.info.start_time if run.info.end_time else None
            }
            
            # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã
            params = dict(run.data.params)
            
            # –ú–µ—Ç—Ä–∏–∫–∏ (—Ç–µ–∫—É—â–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è)
            metrics = dict(run.data.metrics)
            
            # –ò—Å—Ç–æ—Ä–∏—è –º–µ—Ç—Ä–∏–∫
            metrics_history = {}
            for metric_name in metrics.keys():
                history = client.get_metric_history(run_id, metric_name)
                metrics_history[metric_name] = [
                    {
                        "timestamp": metric.timestamp,
                        "step": metric.step,
                        "value": metric.value
                    }
                    for metric in history
                ]
            
            # –¢–µ–≥–∏
            tags = dict(run.data.tags)
            
            return {
                "info": run_info,
                "params": params,
                "metrics": metrics,
                "metrics_history": metrics_history,
                "tags": tags
            }
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö MLflow: {e}")
            return None
    
    def _export_text_format(self, training_data: Dict, run_id: str, timestamp: str):
        """–≠–∫—Å–ø–æ—Ä—Ç –≤ —Ç–µ–∫—Å—Ç–æ–≤–æ–º —Ñ–æ—Ä–º–∞—Ç–µ –¥–ª—è AI –∞–Ω–∞–ª–∏–∑–∞"""
        try:
            filename = f"training_report_{run_id[:8]}_{timestamp}.txt"
            filepath = self.export_dir / "text_reports" / filename
            
            with open(filepath, 'w', encoding='utf-8') as f:
                f.write("=" * 80 + "\n")
                f.write("ü§ñ –û–¢–ß–ï–¢ –û–ë–£–ß–ï–ù–ò–Ø –î–õ–Ø AI –ê–ù–ê–õ–ò–ó–ê\n")
                f.write("=" * 80 + "\n\n")
                
                # –û—Å–Ω–æ–≤–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è
                info = training_data["info"]
                f.write("üìä –û–°–ù–û–í–ù–ê–Ø –ò–ù–§–û–†–ú–ê–¶–ò–Ø\n")
                f.write("-" * 40 + "\n")
                f.write(f"Run ID: {info['run_id']}\n")
                f.write(f"–°—Ç–∞—Ç—É—Å: {info['status']}\n")
                f.write(f"–í—Ä–µ–º—è —Å—Ç–∞—Ä—Ç–∞: {datetime.fromtimestamp(info['start_time']/1000)}\n")
                if info['end_time']:
                    f.write(f"–í—Ä–µ–º—è –æ–∫–æ–Ω—á–∞–Ω–∏—è: {datetime.fromtimestamp(info['end_time']/1000)}\n")
                if info['duration_ms']:
                    hours = info['duration_ms'] / (1000 * 60 * 60)
                    f.write(f"–î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å: {hours:.2f} —á–∞—Å–æ–≤\n")
                f.write("\n")
                
                # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –æ–±—É—á–µ–Ω–∏—è
                params = training_data["params"]
                f.write("‚öôÔ∏è –ü–ê–†–ê–ú–ï–¢–†–´ –û–ë–£–ß–ï–ù–ò–Ø\n")
                f.write("-" * 40 + "\n")
                for key, value in params.items():
                    f.write(f"{key}: {value}\n")
                f.write("\n")
                
                # –§–∏–Ω–∞–ª—å–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏
                metrics = training_data["metrics"]
                f.write("üìà –§–ò–ù–ê–õ–¨–ù–´–ï –ú–ï–¢–†–ò–ö–ò\n")
                f.write("-" * 40 + "\n")
                for key, value in metrics.items():
                    if isinstance(value, (int, float)):
                        f.write(f"{key}: {value:.6f}\n")
                    else:
                        f.write(f"{key}: {value}\n")
                f.write("\n")
                
                # –ò—Å—Ç–æ—Ä–∏—è –∫–ª—é—á–µ–≤—ã—Ö –º–µ—Ç—Ä–∏–∫ (—Å–∂–∞—Ç–æ)
                f.write("üìä –ò–°–¢–û–†–ò–Ø –ö–õ–Æ–ß–ï–í–´–• –ú–ï–¢–†–ò–ö (–ü–û–°–õ–ï–î–ù–ò–ï 20 –ó–ù–ê–ß–ï–ù–ò–ô)\n")
                f.write("-" * 40 + "\n")
                
                key_metrics = [
                    "training.loss", "validation.loss", "grad_norm", 
                    "learning_rate", "training.gate_loss", "training.taco_loss"
                ]
                
                for metric_name in key_metrics:
                    if metric_name in training_data["metrics_history"]:
                        history = training_data["metrics_history"][metric_name]
                        if history:
                            # –ë–µ—Ä–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ 20 –∑–Ω–∞—á–µ–Ω–∏–π
                            recent_history = history[-20:]
                            f.write(f"\n{metric_name} (–ø–æ—Å–ª–µ–¥–Ω–∏–µ {len(recent_history)} –∑–Ω–∞—á–µ–Ω–∏–π):\n")
                            
                            for i, entry in enumerate(recent_history):
                                step = entry['step']
                                value = entry['value']
                                if i < 5 or i >= len(recent_history) - 5:
                                    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ 5 –∏ –ø–æ—Å–ª–µ–¥–Ω–∏–µ 5
                                    f.write(f"  –®–∞–≥ {step:6d}: {value:.6f}\n")
                                elif i == 5:
                                    f.write("  ...\n")
                f.write("\n")
                
                # –ê–Ω–∞–ª–∏–∑ —Ç—Ä–µ–Ω–¥–æ–≤
                f.write("üìà –ê–ù–ê–õ–ò–ó –¢–†–ï–ù–î–û–í\n")
                f.write("-" * 40 + "\n")
                
                for metric_name in key_metrics:
                    if metric_name in training_data["metrics_history"]:
                        history = training_data["metrics_history"][metric_name]
                        if len(history) > 10:
                            values = [h["value"] for h in history]
                            
                            # –ü—Ä–æ—Å—Ç–æ–π –∞–Ω–∞–ª–∏–∑ —Ç—Ä–µ–Ω–¥–∞
                            start_avg = sum(values[:5]) / 5 if len(values) >= 5 else values[0]
                            end_avg = sum(values[-5:]) / 5 if len(values) >= 5 else values[-1]
                            
                            change = end_avg - start_avg
                            change_percent = (change / start_avg) * 100 if start_avg != 0 else 0
                            
                            trend = "—É–ª—É—á—à–∞–µ—Ç—Å—è" if change < 0 else "—É—Ö—É–¥—à–∞–µ—Ç—Å—è" if change > 0 else "—Å—Ç–∞–±–∏–ª–µ–Ω"
                            if "loss" not in metric_name.lower():
                                trend = "—Ä–∞—Å—Ç–µ—Ç" if change > 0 else "–ø–∞–¥–∞–µ—Ç" if change < 0 else "—Å—Ç–∞–±–∏–ª–µ–Ω"
                            
                            f.write(f"{metric_name}: {trend} ({change_percent:+.2f}%)\n")
                f.write("\n")
                
                # –ü—Ä–æ–±–ª–µ–º—ã –∏ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ (—É–ø—Ä–æ—â–µ–Ω–Ω—ã–µ)
                f.write("üîç –ö–†–ê–¢–ö–ò–ô –ê–ù–ê–õ–ò–ó –ü–†–û–ë–õ–ï–ú\n")
                f.write("-" * 40 + "\n")
                
                issues = []
                
                # –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
                if info['duration_ms']:
                    hours = info['duration_ms'] / (1000 * 60 * 60)
                    if hours < 3:
                        issues.append(f"‚è∞ –ö–æ—Ä–æ—Ç–∫–æ–µ –æ–±—É—á–µ–Ω–∏–µ: {hours:.1f} —á–∞—Å–æ–≤")
                
                # –ü—Ä–æ–≤–µ—Ä–∫–∞ validation loss
                if 'validation.loss' in metrics:
                    val_loss = metrics['validation.loss']
                    if val_loss > 20:
                        issues.append(f"üìà –í—ã—Å–æ–∫–∏–π validation loss: {val_loss:.3f}")
                
                # –ü—Ä–æ–≤–µ—Ä–∫–∞ –≥—Ä–∞–¥–∏–µ–Ω—Ç–æ–≤
                if 'grad_norm' in metrics:
                    grad_norm = metrics['grad_norm']
                    if grad_norm > 100:
                        issues.append(f"üí• –í—ã—Å–æ–∫–∞—è –Ω–æ—Ä–º–∞ –≥—Ä–∞–¥–∏–µ–Ω—Ç–æ–≤: {grad_norm:.3f}")
                
                if issues:
                    for issue in issues:
                        f.write(f"‚Ä¢ {issue}\n")
                else:
                    f.write("‚úÖ –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏—Ö –ø—Ä–æ–±–ª–µ–º –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–æ\n")
                
                f.write("\n")
                f.write("=" * 80 + "\n")
                f.write(f"–û—Ç—á–µ—Ç —Å–æ–∑–¥–∞–Ω: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
                f.write("–î–ª—è –æ—Ç–ø—Ä–∞–≤–∫–∏ AI Assistant —Å–∫–æ–ø–∏—Ä—É–π—Ç–µ –≤–µ—Å—å —Ç–µ–∫—Å—Ç –≤—ã—à–µ\n")
                f.write("=" * 80 + "\n")
            
            print(f"üìÑ –¢–µ–∫—Å—Ç–æ–≤—ã–π –æ—Ç—á–µ—Ç: {filepath}")
            return filepath
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è —Ç–µ–∫—Å—Ç–æ–≤–æ–≥–æ –æ—Ç—á–µ—Ç–∞: {e}")
            return None
    
    def _export_csv_format(self, training_data: Dict, run_id: str, timestamp: str):
        """–≠–∫—Å–ø–æ—Ä—Ç –≤ CSV —Ñ–æ—Ä–º–∞—Ç–µ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –≤ Excel/Python"""
        try:
            filename = f"training_metrics_{run_id[:8]}_{timestamp}.csv"
            filepath = self.export_dir / "csv_data" / filename
            
            # –°–æ–∑–¥–∞–µ–º DataFrame –∏–∑ –∏—Å—Ç–æ—Ä–∏–∏ –º–µ—Ç—Ä–∏–∫
            all_metrics = []
            
            for metric_name, history in training_data["metrics_history"].items():
                for entry in history:
                    all_metrics.append({
                        "metric_name": metric_name,
                        "step": entry["step"],
                        "value": entry["value"],
                        "timestamp": entry["timestamp"]
                    })
            
            if all_metrics:
                df = pd.DataFrame(all_metrics)
                df.to_csv(filepath, index=False, encoding='utf-8')
                print(f"üìä CSV —Ñ–∞–π–ª: {filepath}")
                return filepath
            else:
                print("‚ö†Ô∏è –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è CSV —ç–∫—Å–ø–æ—Ä—Ç–∞")
                return None
                
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è CSV: {e}")
            return None
    
    def _export_json_format(self, training_data: Dict, run_id: str, timestamp: str):
        """–≠–∫—Å–ø–æ—Ä—Ç –≤ JSON —Ñ–æ—Ä–º–∞—Ç–µ –¥–ª—è –ø—Ä–æ–≥—Ä–∞–º–º–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞"""
        try:
            filename = f"training_data_{run_id[:8]}_{timestamp}.json"
            filepath = self.export_dir / "json_raw" / filename
            
            with open(filepath, 'w', encoding='utf-8') as f:
                json.dump(training_data, f, indent=2, ensure_ascii=False, default=str)
            
            print(f"üì¶ JSON —Ñ–∞–π–ª: {filepath}")
            return filepath
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è JSON: {e}")
            return None
    
    def _create_export_summary(self, exported_files: Dict, training_data: Dict, timestamp: str):
        """–°–æ–∑–¥–∞–µ—Ç –∏—Ç–æ–≥–æ–≤—É—é —Å–≤–æ–¥–∫—É —ç–∫—Å–ø–æ—Ä—Ç–∞"""
        try:
            filename = f"export_summary_{timestamp}.md"
            filepath = self.export_dir / filename
            
            with open(filepath, 'w', encoding='utf-8') as f:
                f.write(f"# üìä –°–≤–æ–¥–∫–∞ —ç–∫—Å–ø–æ—Ä—Ç–∞ –æ–±—É—á–µ–Ω–∏—è\n\n")
                f.write(f"**–î–∞—Ç–∞ —ç–∫—Å–ø–æ—Ä—Ç–∞:** {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")
                
                # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ–± –æ–±—É—á–µ–Ω–∏–∏
                info = training_data["info"]
                f.write("## üéØ –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ–± –æ–±—É—á–µ–Ω–∏–∏\n\n")
                f.write(f"- **Run ID:** `{info['run_id']}`\n")
                f.write(f"- **–°—Ç–∞—Ç—É—Å:** {info['status']}\n")
                
                if info['duration_ms']:
                    hours = info['duration_ms'] / (1000 * 60 * 60)
                    f.write(f"- **–î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å:** {hours:.2f} —á–∞—Å–æ–≤\n")
                
                # –≠–∫—Å–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã
                f.write("\n## üìÅ –≠–∫—Å–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã\n\n")
                for format_type, filepath in exported_files.items():
                    if filepath:
                        f.write(f"- **{format_type.upper()}:** `{filepath.name}`\n")
                
                # –ë—ã—Å—Ç—Ä—ã–µ –º–µ—Ç—Ä–∏–∫–∏
                f.write("\n## üìà –ë—ã—Å—Ç—Ä—ã–µ –º–µ—Ç—Ä–∏–∫–∏\n\n")
                metrics = training_data["metrics"]
                quick_metrics = [
                    "training.loss", "validation.loss", "grad_norm", 
                    "learning_rate", "training.gate_loss"
                ]
                
                for metric in quick_metrics:
                    if metric in metrics:
                        value = metrics[metric]
                        if isinstance(value, (int, float)):
                            f.write(f"- **{metric}:** {value:.6f}\n")
                
                f.write("\n## üöÄ –ö–∞–∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å\n\n")
                f.write("1. **–î–ª—è –æ—Ç–ø—Ä–∞–≤–∫–∏ AI Assistant:** –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ —Ñ–∞–π–ª –∏–∑ –ø–∞–ø–∫–∏ `text_reports/`\n")
                f.write("2. **–î–ª—è –∞–Ω–∞–ª–∏–∑–∞ –≤ Excel:** –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ —Ñ–∞–π–ª –∏–∑ –ø–∞–ø–∫–∏ `csv_data/`\n") 
                f.write("3. **–î–ª—è –ø—Ä–æ–≥—Ä–∞–º–º–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞:** –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ —Ñ–∞–π–ª –∏–∑ –ø–∞–ø–∫–∏ `json_raw/`\n")
            
            print(f"üìã –°–≤–æ–¥–∫–∞ —ç–∫—Å–ø–æ—Ä—Ç–∞: {filepath}")
            return filepath
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è —Å–≤–æ–¥–∫–∏: {e}")
            return None

def export_training_for_ai(run_id: str = None):
    """
    –ë—ã—Å—Ç—Ä–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è —ç–∫—Å–ø–æ—Ä—Ç–∞ –æ–±—É—á–µ–Ω–∏—è –¥–ª—è AI –∞–Ω–∞–ª–∏–∑–∞
    
    Args:
        run_id: ID MLflow run (–µ—Å–ª–∏ None, –±–µ—Ä–µ—Ç—Å—è –ø–æ—Å–ª–µ–¥–Ω–∏–π)
    
    Returns:
        –ü—É—Ç—å –∫ —Ç–µ–∫—Å—Ç–æ–≤–æ–º—É —Ñ–∞–π–ª—É –¥–ª—è –æ—Ç–ø—Ä–∞–≤–∫–∏ AI
    """
    exporter = TrainingExportSystem()
    result = exporter.export_current_training(run_id, format_type="text")
    
    if result and "text" in result["exported_files"]:
        text_file = result["exported_files"]["text"]
        print(f"\nüì§ –ì–û–¢–û–í–û –î–õ–Ø –û–¢–ü–†–ê–í–ö–ò AI:")
        print(f"   –§–∞–π–ª: {text_file}")
        print(f"   üìã –°–∫–æ–ø–∏—Ä—É–π—Ç–µ —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ —Ñ–∞–π–ª–∞ –∏ –æ—Ç–ø—Ä–∞–≤—å—Ç–µ AI Assistant")
        return text_file
    else:
        print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å —ç–∫—Å–ø–æ—Ä—Ç –¥–ª—è AI")
        return None

if __name__ == "__main__":
    print("üöÄ –ó–∞–ø—É—Å–∫ —Å–∏—Å—Ç–µ–º—ã —ç–∫—Å–ø–æ—Ä—Ç–∞ –æ–±—É—á–µ–Ω–∏—è")
    
    # –ë—ã—Å—Ç—Ä—ã–π —ç–∫—Å–ø–æ—Ä—Ç –¥–ª—è AI
    export_training_for_ai() 