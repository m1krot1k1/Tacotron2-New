"""
üß™ –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï Enhanced Adaptive Loss System
==============================================

–ö–æ–º–ø–ª–µ–∫—Å–Ω—ã–π —Ç–µ—Å—Ç –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ –∞–¥–∞–ø—Ç–∏–≤–Ω–æ–π —Å–∏—Å—Ç–µ–º—ã loss —Ñ—É–Ω–∫—Ü–∏–π:
1. ‚úÖ –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è Enhanced Adaptive Loss System
2. ‚úÖ –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å Tacotron2Loss  
3. ‚úÖ –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å Context-Aware Training Manager
4. ‚úÖ Dynamic Tversky Loss —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å
5. ‚úÖ –ê–¥–∞–ø—Ç–∏–≤–Ω—ã–µ –≤–µ—Å–∞ –∏ –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω–∞—è –∞–¥–∞–ø—Ç–∞—Ü–∏—è
6. ‚úÖ –î–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ –∏ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ —Å–∏—Å—Ç–µ–º—ã

–í–µ—Ä—Å–∏—è: 1.0.0
"""

import sys
import os
import torch
import torch.nn as nn
import numpy as np
import logging
from typing import Dict, Any

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(level=logging.INFO, format='%(levelname)s: %(message)s')
logger = logging.getLogger(__name__)

def test_adaptive_loss_system_import():
    """üß™ –¢–µ—Å—Ç 1: –ò–º–ø–æ—Ä—Ç Enhanced Adaptive Loss System"""
    logger.info("\nüß™ –¢–µ—Å—Ç 1: –ò–º–ø–æ—Ä—Ç Enhanced Adaptive Loss System")
    logger.info("-" * 60)
    
    try:
        from adaptive_loss_system import (
            create_adaptive_loss_system,
            DynamicTverskyLoss,
            IntelligentWeightManager,
            ContextBasedLossScaler,
            PhaseAwareLossOptimizer,
            LossPhase,
            LossContext
        )
        
        logger.info("‚úÖ –í—Å–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã Enhanced Adaptive Loss System –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω—ã —É—Å–ø–µ—à–Ω–æ")
        
        # –¢–µ—Å—Ç–∏—Ä—É–µ–º —Å–æ–∑–¥–∞–Ω–∏–µ —Å–∏—Å—Ç–µ–º—ã
        class MockHParams:
            mel_loss_weight = 1.0
            gate_loss_weight = 1.0
            guide_loss_weight = 2.0
            spectral_loss_weight = 0.3
            perceptual_loss_weight = 0.2
            style_loss_weight = 0.1
            monotonic_loss_weight = 0.1
        
        hparams = MockHParams()
        adaptive_system = create_adaptive_loss_system(hparams)
        
        logger.info("‚úÖ Enhanced Adaptive Loss System —Å–æ–∑–¥–∞–Ω–∞ —É—Å–ø–µ—à–Ω–æ")
        logger.info(f"   –ö–æ–º–ø–æ–Ω–µ–Ω—Ç—ã: DynamicTverskyLoss, IntelligentWeightManager, ContextBasedLossScaler")
        
        return True
        
    except ImportError as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∏–º–ø–æ—Ä—Ç–∞: {e}")
        return False
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è —Å–∏—Å—Ç–µ–º—ã: {e}")
        return False


def test_loss_function_integration():
    """üß™ –¢–µ—Å—Ç 2: –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å Tacotron2Loss"""
    logger.info("\nüß™ –¢–µ—Å—Ç 2: –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å Tacotron2Loss")
    logger.info("-" * 60)
    
    try:
        from loss_function import Tacotron2Loss
        from adaptive_loss_system import create_adaptive_loss_system, LossPhase, LossContext
        
        # –°–æ–∑–¥–∞–µ–º mock hparams
        class MockHParams:
            mel_loss_weight = 1.0
            gate_loss_weight = 1.0
            guide_loss_weight = 2.0
            spectral_loss_weight = 0.3
            perceptual_loss_weight = 0.2
            style_loss_weight = 0.1
            monotonic_loss_weight = 0.1
            guide_decay = 0.9999
            guide_sigma = 0.4
            adaptive_gate_threshold = True
            curriculum_teacher_forcing = True
            use_ddc = False
            ddc_consistency_weight = 0.5
            
            # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è –∞–¥–∞–ø—Ç–∏–≤–Ω–æ–π —Å–∏—Å—Ç–µ–º—ã
            weight_adaptation_rate = 0.02
            loss_stability_threshold = 2.0
            
            # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è UnifiedGuidedAttention
            guide_loss_initial_weight = 5.0
            guide_loss_min_weight = 0.1
            guide_loss_max_weight = 15.0
            guide_loss_decay_start = 2000
            guide_loss_decay_steps = 25000
            guide_loss_decay_factor = 3.0
            guide_sigma_initial = 0.1
            guide_sigma_peak = 0.4
            guide_sigma_final = 0.15
            guide_emergency_weight = 25.0
            attention_emergency_threshold = 0.02
            attention_recovery_threshold = 0.5
            use_context_aware_attention = True
        
        hparams = MockHParams()
        
        # –°–æ–∑–¥–∞–µ–º loss —Ñ—É–Ω–∫—Ü–∏—é
        loss_function = Tacotron2Loss(hparams)
        logger.info("‚úÖ Tacotron2Loss —Å–æ–∑–¥–∞–Ω")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—é –∞–¥–∞–ø—Ç–∏–≤–Ω–æ–π —Å–∏—Å—Ç–µ–º—ã
        if hasattr(loss_function, 'use_adaptive_loss') and loss_function.use_adaptive_loss:
            logger.info("‚úÖ Enhanced Adaptive Loss System –∏–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞–Ω–∞")
            
            # –¢–µ—Å—Ç–∏—Ä—É–µ–º –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
            loss_function.update_training_context(
                phase="ALIGNMENT_LEARNING",
                attention_quality=0.4,
                gate_accuracy=0.7,
                mel_consistency=0.6,
                gradient_norm=2.5,
                loss_stability=1.2,
                learning_rate=1e-3
            )
            logger.info("‚úÖ –ö–æ–Ω—Ç–µ–∫—Å—Ç –æ–±—É—á–µ–Ω–∏—è –æ–±–Ω–æ–≤–ª–µ–Ω")
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–æ–ª—É—á–µ–Ω–∏–µ –∞–¥–∞–ø—Ç–∏–≤–Ω—ã—Ö –≤–µ—Å–æ–≤
            adaptive_weights = loss_function.get_current_adaptive_weights()
            logger.info(f"‚úÖ –ü–æ–ª—É—á–µ–Ω—ã –∞–¥–∞–ø—Ç–∏–≤–Ω—ã–µ –≤–µ—Å–∞: {list(adaptive_weights.keys())}")
            
        else:
            logger.warning("‚ö†Ô∏è Enhanced Adaptive Loss System –Ω–µ –∏–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞–Ω–∞")
            
        return True
        
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ —Å loss —Ñ—É–Ω–∫—Ü–∏–µ–π: {e}")
        return False


def test_context_aware_integration():
    """üß™ –¢–µ—Å—Ç 3: –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å Context-Aware Training Manager"""
    logger.info("\nüß™ –¢–µ—Å—Ç 3: –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å Context-Aware Training Manager")
    logger.info("-" * 60)
    
    try:
        from context_aware_training_manager import create_context_aware_manager, TrainingPhase
        from loss_function import Tacotron2Loss
        
        # –°–æ–∑–¥–∞–µ–º mock hparams
        class MockHParams:
            learning_rate = 1e-3
            guide_loss_weight = 4.5
            mel_loss_weight = 1.0
            gate_loss_weight = 1.0
            spectral_loss_weight = 0.3
            perceptual_loss_weight = 0.2
            style_loss_weight = 0.1
            monotonic_loss_weight = 0.1
            guide_decay = 0.9999
            guide_sigma = 0.4
            adaptive_gate_threshold = True
            curriculum_teacher_forcing = True
            use_ddc = False
            ddc_consistency_weight = 0.5
            
            # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è –∞–¥–∞–ø—Ç–∏–≤–Ω–æ–π —Å–∏—Å—Ç–µ–º—ã
            weight_adaptation_rate = 0.02
            loss_stability_threshold = 2.0
            
            # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è UnifiedGuidedAttention
            guide_loss_initial_weight = 5.0
            guide_loss_min_weight = 0.1
            guide_loss_max_weight = 15.0
            guide_loss_decay_start = 2000
            guide_loss_decay_steps = 25000
            guide_loss_decay_factor = 3.0
            guide_sigma_initial = 0.1
            guide_sigma_peak = 0.4
            guide_sigma_final = 0.15
            guide_emergency_weight = 25.0
            attention_emergency_threshold = 0.02
            attention_recovery_threshold = 0.5
            use_context_aware_attention = True
        
        hparams = MockHParams()
        
        # –°–æ–∑–¥–∞–µ–º Context-Aware Manager
        context_manager = create_context_aware_manager(hparams)
        logger.info("‚úÖ Context-Aware Training Manager —Å–æ–∑–¥–∞–Ω")
        
        # –°–æ–∑–¥–∞–µ–º loss —Ñ—É–Ω–∫—Ü–∏—é
        loss_function = Tacotron2Loss(hparams)
        logger.info("‚úÖ Tacotron2Loss —Å–æ–∑–¥–∞–Ω")
        
        # –¢–µ—Å—Ç–∏—Ä—É–µ–º –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—é
        context_manager.integrate_with_loss_function(loss_function)
        logger.info("‚úÖ –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è Context-Aware Manager —Å loss —Ñ—É–Ω–∫—Ü–∏–µ–π –∑–∞–≤–µ—Ä—à–µ–Ω–∞")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ EnhancedLossIntegrator –ø–æ–ª—É—á–∏–ª —Å—Å—ã–ª–∫—É –Ω–∞ loss —Ñ—É–Ω–∫—Ü–∏—é
        if hasattr(context_manager.loss_controller, 'enhanced_system_available'):
            if context_manager.loss_controller.enhanced_system_available:
                logger.info("‚úÖ EnhancedLossIntegrator —É—Å–ø–µ—à–Ω–æ –ø–æ–¥–∫–ª—é—á–µ–Ω –∫ Enhanced Adaptive Loss System")
            else:
                logger.warning("‚ö†Ô∏è EnhancedLossIntegrator —Ä–∞–±–æ—Ç–∞–µ—Ç –≤ fallback —Ä–µ–∂–∏–º–µ")
        
        return True
        
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ —Å Context-Aware Manager: {e}")
        return False


def test_dynamic_tversky_loss():
    """üß™ –¢–µ—Å—Ç 4: Dynamic Tversky Loss —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å"""
    logger.info("\nüß™ –¢–µ—Å—Ç 4: Dynamic Tversky Loss —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å")
    logger.info("-" * 60)
    
    try:
        from adaptive_loss_system import DynamicTverskyLoss, LossContext, LossPhase
        
        # –°–æ–∑–¥–∞–µ–º Dynamic Tversky Loss
        tversky_loss = DynamicTverskyLoss(
            initial_alpha=0.7,
            initial_beta=0.3,
            adapt_rate=0.01
        )
        logger.info("‚úÖ DynamicTverskyLoss —Å–æ–∑–¥–∞–Ω")
        
        # –°–æ–∑–¥–∞–µ–º —Ç–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ
        predictions = torch.randn(8, 100)  # Batch size 8, 100 gate outputs
        targets = torch.randint(0, 2, (8, 100)).float()  # Binary targets
        
        # –°–æ–∑–¥–∞–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç –¥–ª—è –∞–¥–∞–ø—Ç–∞—Ü–∏–∏
        context = LossContext(
            phase=LossPhase.ALIGNMENT_LEARNING,
            global_step=1000,
            attention_quality=0.4,
            gate_accuracy=0.7,
            mel_consistency=0.6,
            gradient_norm=2.5,
            loss_stability=1.2,
            learning_rate=1e-3
        )
        
        # –¢–µ—Å—Ç–∏—Ä—É–µ–º –≤—ã—á–∏—Å–ª–µ–Ω–∏–µ loss
        loss_value = tversky_loss(predictions, targets, context)
        logger.info(f"‚úÖ Tversky loss –≤—ã—á–∏—Å–ª–µ–Ω–∞: {loss_value.item():.4f}")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∞–¥–∞–ø—Ç–∞—Ü–∏—é –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
        initial_alpha = tversky_loss.alpha
        
        # –°–∏–º—É–ª–∏—Ä—É–µ–º –Ω–µ—Å–∫–æ–ª—å–∫–æ —à–∞–≥–æ–≤ —Å –Ω–∏–∑–∫–æ–π gate accuracy
        for i in range(10):
            context.gate_accuracy = 0.5  # –ù–∏–∑–∫–∞—è accuracy
            tversky_loss(predictions, targets, context)
        
        final_alpha = tversky_loss.alpha
        
        if abs(final_alpha - initial_alpha) > 0.001:
            logger.info(f"‚úÖ –ê–¥–∞–ø—Ç–∞—Ü–∏—è –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ —Ä–∞–±–æ—Ç–∞–µ—Ç: Œ± {initial_alpha:.3f} ‚Üí {final_alpha:.3f}")
        else:
            logger.info(f"‚úÖ –ü–∞—Ä–∞–º–µ—Ç—Ä—ã —Å—Ç–∞–±–∏–ª—å–Ω—ã: Œ±={final_alpha:.3f}")
        
        return True
        
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è Dynamic Tversky Loss: {e}")
        return False


def test_adaptive_weights_and_scaling():
    """üß™ –¢–µ—Å—Ç 5: –ê–¥–∞–ø—Ç–∏–≤–Ω—ã–µ –≤–µ—Å–∞ –∏ –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω–æ–µ –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ"""
    logger.info("\nüß™ –¢–µ—Å—Ç 5: –ê–¥–∞–ø—Ç–∏–≤–Ω—ã–µ –≤–µ—Å–∞ –∏ –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω–æ–µ –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ")
    logger.info("-" * 60)
    
    try:
        from adaptive_loss_system import (
            create_adaptive_loss_system,
            LossContext,
            LossPhase
        )
        
        # –°–æ–∑–¥–∞–µ–º —Å–∏—Å—Ç–µ–º—É
        class MockHParams:
            mel_loss_weight = 1.0
            gate_loss_weight = 1.0
            guide_loss_weight = 2.0
            spectral_loss_weight = 0.3
            perceptual_loss_weight = 0.2
            style_loss_weight = 0.1
            monotonic_loss_weight = 0.1
            weight_adaptation_rate = 0.02
            loss_stability_threshold = 2.0
        
        hparams = MockHParams()
        adaptive_system = create_adaptive_loss_system(hparams)
        logger.info("‚úÖ Enhanced Adaptive Loss System —Å–æ–∑–¥–∞–Ω–∞")
        
        # –¢–µ—Å—Ç–∏—Ä—É–µ–º —Ä–∞–∑–Ω—ã–µ —Ñ–∞–∑—ã –æ–±—É—á–µ–Ω–∏—è
        phases = [
            (LossPhase.PRE_ALIGNMENT, 0.1, 0.5),      # –ü–ª–æ—Ö–æ–µ attention, —Å—Ä–µ–¥–Ω—è—è gate accuracy
            (LossPhase.ALIGNMENT_LEARNING, 0.4, 0.7), # –°—Ä–µ–¥–Ω–µ–µ attention, —Ö–æ—Ä–æ—à–∞—è gate accuracy
            (LossPhase.REFINEMENT, 0.6, 0.8),         # –•–æ—Ä–æ—à–µ–µ attention, –æ—Ç–ª–∏—á–Ω–∞—è gate accuracy
            (LossPhase.CONVERGENCE, 0.8, 0.9)         # –û—Ç–ª–∏—á–Ω–æ–µ attention, –ø—Ä–µ–≤–æ—Å—Ö–æ–¥–Ω–∞—è gate accuracy
        ]
        
        for phase, attention_quality, gate_accuracy in phases:
            context = LossContext(
                phase=phase,
                global_step=1000,
                attention_quality=attention_quality,
                gate_accuracy=gate_accuracy,
                mel_consistency=0.6,
                gradient_norm=2.0,
                loss_stability=1.0,
                learning_rate=1e-3
            )
            
            # –¢–µ—Å—Ç–æ–≤—ã–µ loss –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã
            loss_components = {
                'mel': torch.tensor(2.5),
                'gate': torch.tensor(0.8),
                'guided_attention': torch.tensor(1.2),
                'spectral': torch.tensor(0.4),
                'perceptual': torch.tensor(0.3),
                'style': torch.tensor(0.1),
                'monotonic': torch.tensor(0.1)
            }
            
            # –¢–µ—Å—Ç–∏—Ä—É–µ–º –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—é
            optimized_loss, diagnostics = adaptive_system.optimize_loss_computation(
                loss_components, context
            )
            
            logger.info(f"‚úÖ –§–∞–∑–∞ {phase.value}:")
            logger.info(f"   –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è loss: {optimized_loss.item():.4f}")
            logger.info(f"   Loss scale: {diagnostics['loss_scale']:.3f}")
            logger.info(f"   Guided attention weight: {diagnostics['adaptive_weights']['guided_attention']:.2f}")
        
        return True
        
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –∞–¥–∞–ø—Ç–∏–≤–Ω—ã—Ö –≤–µ—Å–æ–≤: {e}")
        return False


def test_system_diagnostics():
    """üß™ –¢–µ—Å—Ç 6: –î–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ –∏ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ —Å–∏—Å—Ç–µ–º—ã"""
    logger.info("\nüß™ –¢–µ—Å—Ç 6: –î–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ –∏ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ —Å–∏—Å—Ç–µ–º—ã")
    logger.info("-" * 60)
    
    try:
        from loss_function import Tacotron2Loss
        from adaptive_loss_system import LossContext, LossPhase
        
        # –°–æ–∑–¥–∞–µ–º mock hparams
        class MockHParams:
            mel_loss_weight = 1.0
            gate_loss_weight = 1.0
            guide_loss_weight = 2.0
            spectral_loss_weight = 0.3
            perceptual_loss_weight = 0.2
            style_loss_weight = 0.1
            monotonic_loss_weight = 0.1
            guide_decay = 0.9999
            guide_sigma = 0.4
            adaptive_gate_threshold = True
            curriculum_teacher_forcing = True
            use_ddc = False
            ddc_consistency_weight = 0.5
            weight_adaptation_rate = 0.02
            loss_stability_threshold = 2.0
            
            # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è UnifiedGuidedAttention
            guide_loss_initial_weight = 5.0
            guide_loss_min_weight = 0.1
            guide_loss_max_weight = 15.0
            guide_loss_decay_start = 2000
            guide_loss_decay_steps = 25000
            guide_loss_decay_factor = 3.0
            guide_sigma_initial = 0.1
            guide_sigma_peak = 0.4
            guide_sigma_final = 0.15
            guide_emergency_weight = 25.0
            attention_emergency_threshold = 0.02
            attention_recovery_threshold = 0.5
            use_context_aware_attention = True
        
        hparams = MockHParams()
        loss_function = Tacotron2Loss(hparams)
        
        if hasattr(loss_function, 'use_adaptive_loss') and loss_function.use_adaptive_loss:
            # –û–±–Ω–æ–≤–ª—è–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç –∏ –ø–æ–ª—É—á–∞–µ–º –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫—É
            loss_function.update_training_context(
                phase="REFINEMENT",
                attention_quality=0.6,
                gate_accuracy=0.8,
                gradient_norm=2.0,
                loss_stability=1.0
            )
            
            # –ü–æ–ª—É—á–∞–µ–º –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫—É –∞–¥–∞–ø—Ç–∏–≤–Ω–æ–π —Å–∏—Å—Ç–µ–º—ã
            diagnostics = loss_function.get_adaptive_loss_diagnostics()
            logger.info("‚úÖ –î–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ Enhanced Adaptive Loss System –ø–æ–ª—É—á–µ–Ω–∞:")
            
            if 'tversky_loss' in diagnostics:
                tversky_info = diagnostics['tversky_loss']
                logger.info(f"   Dynamic Tversky: Œ±={tversky_info.get('current_alpha', 0):.3f}, Œ≤={tversky_info.get('current_beta', 0):.3f}")
            
            if 'weight_manager' in diagnostics:
                weight_info = diagnostics['weight_manager']
                current_weights = weight_info.get('current_weights', {})
                logger.info(f"   –ê–¥–∞–ø—Ç–∏–≤–Ω—ã–µ –≤–µ—Å–∞: mel={current_weights.get('mel', 0):.2f}, gate={current_weights.get('gate', 0):.2f}")
            
            if 'loss_scaler' in diagnostics:
                scaler_info = diagnostics['loss_scaler']
                logger.info(f"   Loss scaler: {scaler_info.get('current_scale', 1.0):.3f}")
            
            if 'performance_summary' in diagnostics:
                perf_summary = diagnostics['performance_summary']
                logger.info(f"   –ü—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å: —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å={perf_summary.get('system_stability', 0):.3f}")
            
        else:
            logger.warning("‚ö†Ô∏è Enhanced Adaptive Loss System –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞ –¥–ª—è –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏")
        
        return True
        
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏: {e}")
        return False


def run_all_tests():
    """–ó–∞–ø—É—Å–∫ –≤—Å–µ—Ö —Ç–µ—Å—Ç–æ–≤ Enhanced Adaptive Loss System"""
    logger.info("üöÄ –ó–ê–ü–£–°–ö –ö–û–ú–ü–õ–ï–ö–°–ù–û–ì–û –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–Ø Enhanced Adaptive Loss System")
    logger.info("=" * 80)
    
    tests = [
        ("–ò–º–ø–æ—Ä—Ç —Å–∏—Å—Ç–µ–º—ã", test_adaptive_loss_system_import),
        ("–ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å Tacotron2Loss", test_loss_function_integration),
        ("–ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å Context-Aware Manager", test_context_aware_integration),
        ("Dynamic Tversky Loss", test_dynamic_tversky_loss),
        ("–ê–¥–∞–ø—Ç–∏–≤–Ω—ã–µ –≤–µ—Å–∞ –∏ –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ", test_adaptive_weights_and_scaling),
        ("–î–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ —Å–∏—Å—Ç–µ–º—ã", test_system_diagnostics)
    ]
    
    results = []
    
    for test_name, test_func in tests:
        try:
            result = test_func()
            results.append((test_name, result))
        except Exception as e:
            logger.error(f"üí• –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –≤ —Ç–µ—Å—Ç–µ '{test_name}': {e}")
            results.append((test_name, False))
    
    # –ü–æ–¥–≤–æ–¥–∏–º –∏—Ç–æ–≥–∏
    logger.info("\n" + "=" * 80)
    logger.info("üìä –†–ï–ó–£–õ–¨–¢–ê–¢–´ –ö–û–ú–ü–õ–ï–ö–°–ù–û–ì–û –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–Ø Enhanced Adaptive Loss System:")
    logger.info("=" * 80)
    
    passed = sum(1 for _, result in results if result)
    total = len(results)
    
    for test_name, result in results:
        status = "‚úÖ –ü–†–û–ô–î–ï–ù" if result else "‚ùå –ü–†–û–í–ê–õ–ï–ù"
        logger.info(f"{status}: {test_name}")
    
    logger.info(f"\nüéØ –ò–¢–û–ì–û: {passed}/{total} —Ç–µ—Å—Ç–æ–≤ –ø—Ä–æ–π–¥–µ–Ω–æ ({passed/total*100:.1f}%)")
    
    if passed == total:
        logger.info("üéâ –í–°–ï –¢–ï–°–¢–´ –ü–†–û–ô–î–ï–ù–´! Enhanced Adaptive Loss System –≥–æ—Ç–æ–≤–∞ –∫ —Ä–∞–±–æ—Ç–µ!")
        logger.info("‚ú® –°–∏—Å—Ç–µ–º–∞ –ø–æ–ª–Ω–æ—Å—Ç—å—é –∏–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞–Ω–∞ –∏ —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω–∞")
    else:
        logger.warning(f"‚ö†Ô∏è {total-passed} —Ç–µ—Å—Ç–æ–≤ –ø—Ä–æ–≤–∞–ª–µ–Ω–æ. –¢—Ä–µ–±—É–µ—Ç—Å—è –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ.")
    
    return passed == total


if __name__ == "__main__":
    success = run_all_tests()
    exit_code = 0 if success else 1
    exit(exit_code) 