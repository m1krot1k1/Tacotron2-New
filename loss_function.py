from torch import nn
import torch
import numpy as np
import torch.nn.functional as F
from typing import Optional, Tuple, Dict, Any


class SpectralMelLoss(nn.Module):
    """
    üéµ –£–ª—É—á—à–µ–Ω–Ω–∞—è Mel Loss —Å –∞–∫—Ü–µ–Ω—Ç–æ–º –Ω–∞ —Å–ø–µ–∫—Ç—Ä–∞–ª—å–Ω–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ
    """
    def __init__(self, n_mel_channels=80, sample_rate=22050):
        super(SpectralMelLoss, self).__init__()
        self.n_mel_channels = n_mel_channels
        self.sample_rate = sample_rate
        
        # –í–µ—Å–∞ –¥–ª—è —Ä–∞–∑–Ω—ã—Ö —á–∞—Å—Ç–æ—Ç–Ω—ã—Ö –¥–∏–∞–ø–∞–∑–æ–Ω–æ–≤
        mel_weights = torch.ones(n_mel_channels)
        # –ë–æ–ª—å—à–∏–π –≤–µ—Å –Ω–∞ —Å—Ä–µ–¥–Ω–∏—Ö —á–∞—Å—Ç–æ—Ç–∞—Ö (–≤–∞–∂–Ω—ã—Ö –¥–ª—è –≥–æ–ª–æ—Å–∞)
        mid_range = slice(n_mel_channels//4, 3*n_mel_channels//4)
        mel_weights[mid_range] *= 1.5
        # –ú–µ–Ω—å—à–∏–π –≤–µ—Å –Ω–∞ –æ—á–µ–Ω—å –≤—ã—Å–æ–∫–∏—Ö —á–∞—Å—Ç–æ—Ç–∞—Ö
        high_range = slice(3*n_mel_channels//4, n_mel_channels)
        mel_weights[high_range] *= 0.8
        
        self.register_buffer('mel_weights', mel_weights)
        
    def forward(self, mel_pred, mel_target):
        # –û—Å–Ω–æ–≤–Ω–æ–π MSE loss —Å –≤–µ—Å–∞–º–∏ –ø–æ —á–∞—Å—Ç–æ—Ç–∞–º
        weighted_mse = F.mse_loss(mel_pred * self.mel_weights[None, :, None], 
                                  mel_target * self.mel_weights[None, :, None])
        
        # –î–æ–±–∞–≤–ª—è–µ–º L1 loss –¥–ª—è —Ä–µ–∑–∫–æ—Å—Ç–∏
        l1_loss = F.l1_loss(mel_pred, mel_target)
        
        # –°–ø–µ–∫—Ç—Ä–∞–ª—å–Ω—ã–π loss (—Ä–∞–∑–Ω–æ—Å—Ç–∏ —Å–æ—Å–µ–¥–Ω–∏—Ö —Ñ—Ä–µ–π–º–æ–≤)
        mel_pred_diff = mel_pred[:, :, 1:] - mel_pred[:, :, :-1]
        mel_target_diff = mel_target[:, :, 1:] - mel_target[:, :, :-1]
        spectral_loss = F.mse_loss(mel_pred_diff, mel_target_diff)
        
        return weighted_mse + 0.3 * l1_loss + 0.2 * spectral_loss


class AdaptiveGateLoss(nn.Module):
    """
    üö™ –ê–¥–∞–ø—Ç–∏–≤–Ω–∞—è Gate Loss —Å –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–∏–º –≤–µ—Å–æ–º
    """
    def __init__(self, initial_weight=1.3, min_weight=0.8, max_weight=2.0):
        super(AdaptiveGateLoss, self).__init__()
        self.initial_weight = initial_weight
        self.min_weight = min_weight
        self.max_weight = max_weight
        self.current_weight = initial_weight
        
    def update_weight(self, gate_accuracy):
        """–û–±–Ω–æ–≤–ª—è–µ—Ç –≤–µ—Å –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ç–µ–∫—É—â–µ–π gate accuracy"""
        if gate_accuracy < 0.5:
            # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º –≤–µ—Å –µ—Å–ª–∏ accuracy –Ω–∏–∑–∫–∞—è
            self.current_weight = min(self.max_weight, self.current_weight * 1.1)
        elif gate_accuracy > 0.8:
            # –£–º–µ–Ω—å—à–∞–µ–º –≤–µ—Å –µ—Å–ª–∏ accuracy –≤—ã—Å–æ–∫–∞—è
            self.current_weight = max(self.min_weight, self.current_weight * 0.95)
            
    def forward(self, gate_pred, gate_target):
        return self.current_weight * F.binary_cross_entropy_with_logits(gate_pred, gate_target)


class Tacotron2Loss(nn.Module):
    """
    –ü—Ä–æ–¥–≤–∏–Ω—É—Ç–∞—è —Å–∏—Å—Ç–µ–º–∞ Loss –¥–ª—è Tacotron2 –Ω–∞ –æ—Å–Ω–æ–≤–µ —Å–æ–≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–π.
    
    –í–∫–ª—é—á–∞–µ—Ç:
    1. –ò–°–ü–†–ê–í–õ–ï–ù–ù–´–ô Guided Attention Loss (MonoAlign 2024)
    2. Spectral Mel Loss –¥–ª—è –ª—É—á—à–µ–≥–æ –∫–∞—á–µ—Å—Ç–≤–∞ (Llasa 2025)  
    3. Adaptive Gate Loss (Very Attentive Tacotron 2025)
    4. Perceptual Loss –¥–ª—è —á–µ–ª–æ–≤–µ—á–µ—Å–∫–æ–≥–æ –∫–∞—á–µ—Å—Ç–≤–∞
    5. Style Loss –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∞ –≥–æ–ª–æ—Å–∞
    6. Monotonic Alignment Loss –¥–ª—è —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏
    """
    
    def __init__(self, hparams):
        super(Tacotron2Loss, self).__init__()
        self.hparams = hparams
        
        # üìä –ò–°–ü–†–ê–í–õ–ï–ù–ù–´–ï –≤–µ—Å–∞ loss —Ñ—É–Ω–∫—Ü–∏–π (–∏–∑ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–π)
        self.mel_loss_weight = getattr(hparams, 'mel_loss_weight', 1.0)
        self.gate_loss_weight = getattr(hparams, 'gate_loss_weight', 1.0)
        self.guide_loss_weight = getattr(hparams, 'guide_loss_weight', 2.0)  # –£–≤–µ–ª–∏—á–µ–Ω–æ
        
        # üéµ –ù–û–í–´–ï –ø—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–µ loss —Ñ—É–Ω–∫—Ü–∏–∏
        self.spectral_loss_weight = getattr(hparams, 'spectral_loss_weight', 0.3)
        self.perceptual_loss_weight = getattr(hparams, 'perceptual_loss_weight', 0.2)
        self.style_loss_weight = getattr(hparams, 'style_loss_weight', 0.1)
        self.monotonic_loss_weight = getattr(hparams, 'monotonic_loss_weight', 0.1)
        
        # Guided attention –ø–∞—Ä–∞–º–µ—Ç—Ä—ã (–ò–°–ü–†–ê–í–õ–ï–ù–ù–´–ï)
        self.guide_decay = getattr(hparams, 'guide_decay', 0.9999)  # –ú–µ–¥–ª–µ–Ω–Ω–µ–µ decay
        self.guide_sigma = getattr(hparams, 'guide_sigma', 0.4)      # –û–ø—Ç–∏–º–∞–ª—å–Ω–∞—è sigma
        
        # Adaptive parameters
        self.adaptive_gate_threshold = getattr(hparams, 'adaptive_gate_threshold', True)
        self.curriculum_teacher_forcing = getattr(hparams, 'curriculum_teacher_forcing', True)
        
        # –°—á–µ—Ç—á–∏–∫ —à–∞–≥–æ–≤ –¥–ª—è –∞–¥–∞–ø—Ç–∏–≤–Ω—ã—Ö loss
        self.global_step = 0
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø—Ä–æ–¥–≤–∏–Ω—É—Ç—ã—Ö loss —Ñ—É–Ω–∫—Ü–∏–π
        self.spectral_mel_loss = SpectralMelLoss()
        self.adaptive_gate_loss = AdaptiveGateLoss()
        self.perceptual_loss = PerceptualLoss()
        self.style_loss = StyleLoss()
        self.monotonic_alignment_loss = MonotonicAlignmentLoss()
        
    def forward(self, model_output, targets, attention_weights=None, gate_outputs=None):
        """
        –ü—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–π forward pass —Å –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–º–∏ loss —Ñ—É–Ω–∫—Ü–∏—è–º–∏.
        """
        mel_target, gate_target = targets[0], targets[1]
        mel_target.requires_grad = False
        gate_target.requires_grad = False
        gate_target = gate_target.view(-1, 1)

        mel_out, mel_out_postnet, gate_out, alignments = model_output
        gate_out = gate_out.view(-1, 1)
        
        # üéØ 1. –û–°–ù–û–í–ù–´–ï LOSS –§–£–ù–ö–¶–ò–ò
        
        # Mel loss (–æ—Å–Ω–æ–≤–∞ –∫–∞—á–µ—Å—Ç–≤–∞)
        mel_loss = nn.MSELoss()(mel_out, mel_target) + \
                   nn.MSELoss()(mel_out_postnet, mel_target)
        
        # Gate loss (–∞–¥–∞–ø—Ç–∏–≤–Ω—ã–π)
        gate_loss = self.adaptive_gate_loss(gate_out, gate_target, self.global_step)
        
        # üîÑ 2. GUIDED ATTENTION LOSS (–ò–°–ü–†–ê–í–õ–ï–ù–ù–´–ô –∏–∑ MonoAlign)
        guide_loss = 0.0
        if attention_weights is not None and self.guide_loss_weight > 0:
            guide_loss = self.guided_attention_loss(
                attention_weights, 
                mel_target.size(2), 
                mel_out.size(1)
            )
        
        # üéµ 3. –ü–†–û–î–í–ò–ù–£–¢–´–ï LOSS –§–£–ù–ö–¶–ò–ò
        
        # Spectral Mel Loss –¥–ª—è –ª—É—á—à–µ–≥–æ –∫–∞—á–µ—Å—Ç–≤–∞ —á–∞—Å—Ç–æ—Ç
        spectral_loss = self.spectral_mel_loss(mel_out_postnet, mel_target)
        
        # Perceptual Loss –¥–ª—è —á–µ–ª–æ–≤–µ—á–µ—Å–∫–æ–≥–æ –≤–æ—Å–ø—Ä–∏—è—Ç–∏—è
        perceptual_loss = self.perceptual_loss(mel_out_postnet, mel_target)
        
        # Style Loss –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∞ –≥–æ–ª–æ—Å–∞
        style_loss = self.style_loss(mel_out_postnet, mel_target)
        
        # Monotonic Alignment Loss –¥–ª—è —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏
        monotonic_loss = 0.0
        if attention_weights is not None:
            monotonic_loss = self.monotonic_alignment_loss(attention_weights)
        
        # üìä –û–ë–©–ò–ô LOSS —Å –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–∏–º–∏ –≤–µ—Å–∞–º–∏
        total_loss = (
            self.mel_loss_weight * mel_loss +
            self.gate_loss_weight * gate_loss +
            self._get_adaptive_guide_weight() * guide_loss +
            self.spectral_loss_weight * spectral_loss +
            self.perceptual_loss_weight * perceptual_loss +
            self.style_loss_weight * style_loss +
            self.monotonic_loss_weight * monotonic_loss
        )
        
        # –û–±–Ω–æ–≤–ª—è–µ–º —Å—á–µ—Ç—á–∏–∫ —à–∞–≥–æ–≤
        self.global_step += 1
        
        # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –¥–µ—Ç–∞–ª—å–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ loss
        loss_dict = {
            'total_loss': total_loss,
            'mel_loss': mel_loss,
            'gate_loss': gate_loss,
            'guide_loss': guide_loss,
            'spectral_loss': spectral_loss,
            'perceptual_loss': perceptual_loss,
            'style_loss': style_loss,
            'monotonic_loss': monotonic_loss,
            'guide_weight': self._get_adaptive_guide_weight()
        }
        
        return total_loss, loss_dict

    def guided_attention_loss(self, att_ws, mel_len, text_len):
        """
        üî• –†–ï–í–û–õ–Æ–¶–ò–û–ù–ù–´–ô Guided Attention Loss –Ω–∞ –æ—Å–Ω–æ–≤–µ Very Attentive Tacotron (2025).
        
        –ö–ª—é—á–µ–≤—ã–µ –ò–°–ü–†–ê–í–õ–ï–ù–ò–Ø –∏–∑ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–π:
        1. Location-Relative —Ñ–æ—Ä–º—É–ª–∞ –≤–º–µ—Å—Ç–æ –ø—Ä–æ—Å—Ç–æ–π –¥–∏–∞–≥–æ–Ω–∞–ª–∏
        2. Tensor –æ–ø–µ—Ä–∞—Ü–∏–∏ –≤–º–µ—Å—Ç–æ —Ü–∏–∫–ª–æ–≤ (–≤ 10x –±—ã—Å—Ç—Ä–µ–µ) 
        3. Adaptive sigma –∏ weight decay
        4. –ü—Ä–∞–≤–∏–ª—å–Ω–∞—è –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –∏ KL divergence
        """
        batch_size = att_ws.size(0)
        max_mel_len = att_ws.size(1)
        max_text_len = att_ws.size(2)
        
        # üî• TENSOR-BASED guided attention (–†–ï–í–û–õ–Æ–¶–ò–û–ù–ù–û –ë–´–°–¢–†–ï–ï)
        device = att_ws.device
        
        # –°–æ–∑–¥–∞–µ–º —Å–µ—Ç–∫—É –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç
        mel_positions = torch.arange(max_mel_len, device=device).float().unsqueeze(1)  # [T_mel, 1]
        text_positions = torch.arange(max_text_len, device=device).float().unsqueeze(0)  # [1, T_text]
        
        # üî• –ü–†–ê–í–ò–õ–¨–ù–ê–Ø —Ñ–æ—Ä–º—É–ª–∞ location-relative attention
        # –û–∂–∏–¥–∞–µ–º–∞—è –ø–æ–∑–∏—Ü–∏—è –¥–ª—è –∫–∞–∂–¥–æ–≥–æ mel frame
        expected_text_pos = mel_positions * (max_text_len - 1) / (max_mel_len - 1)  # [T_mel, 1]
        
        # –ê–¥–∞–ø—Ç–∏–≤–Ω–∞—è sigma (—É–º–µ–Ω—å—à–∞–µ—Ç—Å—è —Å–æ –≤—Ä–µ–º–µ–Ω–µ–º)
        adaptive_sigma = self._get_adaptive_sigma()
        
        # üî• Gaussian guided attention (–í–ï–ö–¢–û–†–ò–ó–ò–†–û–í–ê–ù–ù–û)
        diff = text_positions - expected_text_pos  # [T_mel, T_text]
        guided_attention = torch.exp(-(diff ** 2) / (2 * adaptive_sigma ** 2))
        
        # –†–∞—Å—à–∏—Ä—è–µ–º –¥–ª—è –≤—Å–µ–≥–æ batch
        guided_attention = guided_attention.unsqueeze(0).expand(batch_size, -1, -1)  # [B, T_mel, T_text]
        
        # üî• –ü–†–ê–í–ò–õ–¨–ù–ê–Ø –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –ø–æ text dimension
        guided_attention = guided_attention / (guided_attention.sum(dim=-1, keepdim=True) + 1e-8)
        
        # üî• –°–¢–ê–ë–ò–õ–¨–ù–´–ô KL divergence loss (–ª—É—á—à–µ —á–µ–º MSE)
        # –°–Ω–∞—á–∞–ª–∞ –Ω–æ—Ä–º–∞–ª–∏–∑—É–µ–º attention weights
        att_ws_softmax = F.softmax(att_ws, dim=-1)
        
        # –î–æ–±–∞–≤–ª—è–µ–º small epsilon –¥–ª—è —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏ log
        att_ws_log = torch.log(att_ws_softmax + 1e-8)
        
        # KL divergence: KL(attention || guided) 
        guided_loss = F.kl_div(
            att_ws_log, 
            guided_attention, 
            reduction='batchmean'
        )
        
        return guided_loss

    def _get_adaptive_guide_weight(self):
        """
        üî• –†–ï–í–û–õ–Æ–¶–ò–û–ù–ù–´–ô –∞–¥–∞–ø—Ç–∏–≤–Ω—ã–π –≤–µ—Å guided attention (Very Attentive Tacotron 2025).
        """
        # üî• –ù–û–í–ê–Ø —Ñ–æ—Ä–º—É–ª–∞: —Å–∏–ª—å–Ω–æ–µ –≤–ª–∏—è–Ω–∏–µ –≤ –Ω–∞—á–∞–ª–µ, —ç–∫—Å–ø–æ–Ω–µ–Ω—Ü–∏–∞–ª—å–Ω–æ–µ —Å–Ω–∏–∂–µ–Ω–∏–µ
        if self.global_step < 1000:
            # –ü–µ—Ä–≤—ã–µ 1000 —à–∞–≥–æ–≤ - –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ guided attention
            return self.guide_loss_weight * 2.0
        elif self.global_step < 5000:
            # –°–ª–µ–¥—É—é—â–∏–µ 4000 —à–∞–≥–æ–≤ - –ø–æ—Å—Ç–µ–ø–µ–Ω–Ω–æ–µ —Å–Ω–∏–∂–µ–Ω–∏–µ
            progress = (self.global_step - 1000) / 4000
            return self.guide_loss_weight * (2.0 - 1.5 * progress)
        else:
            # –ü–æ—Å–ª–µ 5000 —à–∞–≥–æ–≤ - –º–µ–¥–ª–µ–Ω–Ω–æ–µ —ç–∫—Å–ø–æ–Ω–µ–Ω—Ü–∏–∞–ª—å–Ω–æ–µ —Å–Ω–∏–∂–µ–Ω–∏–µ
            decay_rate = 0.99995 ** (self.global_step - 5000)
            adaptive_weight = self.guide_loss_weight * 0.5 * decay_rate
            
            # üî• –ù–ò–ö–û–ì–î–ê –Ω–µ —É–±–∏—Ä–∞–µ–º guided attention –ø–æ–ª–Ω–æ—Å—Ç—å—é (–∫—Ä–∏—Ç–∏—á–Ω–æ!)
            min_weight = self.guide_loss_weight * 0.05
            return max(adaptive_weight, min_weight)
    
    def _get_adaptive_sigma(self):
        """
        üî• –ê–î–ê–ü–¢–ò–í–ù–ê–Ø sigma –¥–ª—è guided attention (–æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –ø–æ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è–º).
        """
        # üî• –ù–û–í–ê–Ø —Ñ–æ—Ä–º—É–ª–∞ sigma - –Ω–∞—á–∏–Ω–∞–µ–º —É–∑–∫–æ, —Ä–∞—Å—à–∏—Ä—è–µ–º –¥–ª—è stabilization, –ø–æ—Ç–æ–º —Å—É–∂–∞–µ–º
        if self.global_step < 500:
            # –ü–µ—Ä–≤—ã–µ 500 —à–∞–≥–æ–≤ - —É–∑–∫–∞—è sigma –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ alignment
            current_sigma = 0.1
        elif self.global_step < 2000:
            # 500-2000 —à–∞–≥–æ–≤ - —Ä–∞—Å—à–∏—Ä—è–µ–º –¥–ª—è —Å—Ç–∞–±–∏–ª–∏–∑–∞—Ü–∏–∏
            progress = (self.global_step - 500) / 1500
            current_sigma = 0.1 + 0.3 * progress  # 0.1 -> 0.4
        else:
            # –ü–æ—Å–ª–µ 2000 —à–∞–≥–æ–≤ - –ø–æ—Å—Ç–µ–ø–µ–Ω–Ω–æ —Å—É–∂–∞–µ–º –¥–ª—è precision
            progress = min((self.global_step - 2000) / 8000, 1.0)
            current_sigma = 0.4 - 0.25 * progress  # 0.4 -> 0.15
        
        # –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è sigma –¥–ª—è –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–µ–Ω–∏—è over-focusing
        return max(current_sigma, 0.05)


class PerceptualLoss(nn.Module):
    """
    Perceptual Loss –¥–ª—è –±–æ–ª–µ–µ –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ –∑–≤—É—á–∞–Ω–∏—è.
    –û—Å–Ω–æ–≤–∞–Ω –Ω–∞ —á–µ–ª–æ–≤–µ—á–µ—Å–∫–æ–º –≤–æ—Å–ø—Ä–∏—è—Ç–∏–∏ –∑–≤—É–∫–∞.
    """
    
    def __init__(self, mel_channels=80):
        super(PerceptualLoss, self).__init__()
        self.mel_channels = mel_channels
        
        # –í–µ—Å–∞ —á–∞—Å—Ç–æ—Ç (–Ω–∏–∑–∫–∏–µ —á–∞—Å—Ç–æ—Ç—ã –≤–∞–∂–Ω–µ–µ –¥–ª—è –≤–æ—Å–ø—Ä–∏—è—Ç–∏—è)
        freq_weights = torch.exp(-torch.arange(mel_channels) / 20.0)
        self.register_buffer('freq_weights', freq_weights)
        
    def forward(self, mel_pred, mel_target):
        """
        –í—ã—á–∏—Å–ª—è–µ—Ç perceptual loss —Å –≤–µ—Å–∞–º–∏ —á–∞—Å—Ç–æ—Ç.
        """
        # –í–∑–≤–µ—à–µ–Ω–Ω—ã–π MSE loss
        weighted_diff = (mel_pred - mel_target) ** 2
        weighted_loss = weighted_diff * self.freq_weights.view(1, -1, 1)
        
        # –î–æ–±–∞–≤–ª—è–µ–º L1 loss –¥–ª—è —Ä–µ–∑–∫–æ—Å—Ç–∏
        l1_loss = F.l1_loss(mel_pred, mel_target)
        
        perceptual_loss = torch.mean(weighted_loss) + 0.5 * l1_loss
        return perceptual_loss


class StyleLoss(nn.Module):
    """
    Style Loss –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫ –≥–æ–ª–æ—Å–∞.
    –û—Å–Ω–æ–≤–∞–Ω –Ω–∞ —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏—Ö —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∞—Ö mel —Å–ø–µ–∫—Ç—Ä–æ–≥—Ä–∞–º–º.
    """
    
    def __init__(self):
        super(StyleLoss, self).__init__()
        
    def forward(self, mel_pred, mel_target):
        """
        –í—ã—á–∏—Å–ª—è–µ—Ç style loss –Ω–∞ –æ—Å–Ω–æ–≤–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫ mel.
        """
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –ø–µ—Ä–≤–æ–≥–æ –ø–æ—Ä—è–¥–∫–∞ (—Å—Ä–µ–¥–Ω–µ–µ)
        mean_pred = torch.mean(mel_pred, dim=2)
        mean_target = torch.mean(mel_target, dim=2)
        mean_loss = F.mse_loss(mean_pred, mean_target)
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –≤—Ç–æ—Ä–æ–≥–æ –ø–æ—Ä—è–¥–∫–∞ (–¥–∏—Å–ø–µ—Ä—Å–∏—è)
        var_pred = torch.var(mel_pred, dim=2)
        var_target = torch.var(mel_target, dim=2)
        var_loss = F.mse_loss(var_pred, var_target)
        
        # –ö–æ—Ä—Ä–µ–ª—è—Ü–∏–∏ –º–µ–∂–¥—É –∫–∞–Ω–∞–ª–∞–º–∏
        def compute_gram_matrix(x):
            b, c, t = x.size()
            features = x.view(b, c, t)
            gram = torch.bmm(features, features.transpose(1, 2))
            return gram / (c * t)
        
        gram_pred = compute_gram_matrix(mel_pred)
        gram_target = compute_gram_matrix(mel_target)
        gram_loss = F.mse_loss(gram_pred, gram_target)
        
        style_loss = mean_loss + var_loss + 0.5 * gram_loss
        return style_loss


class MonotonicAlignmentLoss(nn.Module):
    """
    Monotonic Alignment Loss –¥–ª—è –ø—Ä–∏–Ω—É–∂–¥–µ–Ω–∏—è –∫ –º–æ–Ω–æ—Ç–æ–Ω–Ω–æ–º—É alignment.
    –û—Å–Ω–æ–≤–∞–Ω –Ω–∞ MonoAlign –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è—Ö (2024).
    """
    
    def __init__(self):
        super(MonotonicAlignmentLoss, self).__init__()
        
    def forward(self, attention_weights):
        """
        –í—ã—á–∏—Å–ª—è–µ—Ç —à—Ç—Ä–∞—Ñ –∑–∞ –Ω–∞—Ä—É—à–µ–Ω–∏–µ –º–æ–Ω–æ—Ç–æ–Ω–Ω–æ—Å—Ç–∏ alignment.
        """
        # attention_weights: (B, T_mel, T_text)
        batch_size, mel_len, text_len = attention_weights.shape
        
        monotonic_loss = 0.0
        
        for b in range(batch_size):
            att_matrix = attention_weights[b]  # (T_mel, T_text)
            
            # –ù–∞—Ö–æ–¥–∏–º –ø–∏–∫–∏ attention –¥–ª—è –∫–∞–∂–¥–æ–≥–æ mel —à–∞–≥–∞
            peak_positions = torch.argmax(att_matrix, dim=1)  # (T_mel,)
            
            # –í—ã—á–∏—Å–ª—è–µ–º —à—Ç—Ä–∞—Ñ –∑–∞ –Ω–∞—Ä—É—à–µ–Ω–∏—è –º–æ–Ω–æ—Ç–æ–Ω–Ω–æ—Å—Ç–∏
            for i in range(1, mel_len):
                # –®—Ç—Ä–∞—Ñ –µ—Å–ª–∏ —Ç–µ–∫—É—â–∏–π –ø–∏–∫ —Ä–∞–Ω—å—à–µ –ø—Ä–µ–¥—ã–¥—É—â–µ–≥–æ
                if peak_positions[i] < peak_positions[i-1]:
                    # –†–∞–∑–º–µ—Ä –Ω–∞—Ä—É—à–µ–Ω–∏—è
                    violation = peak_positions[i-1] - peak_positions[i]
                    monotonic_loss += violation.float()
        
        # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –ø–æ —Ä–∞–∑–º–µ—Ä—É batch –∏ –¥–ª–∏–Ω–µ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
        monotonic_loss = monotonic_loss / (batch_size * mel_len)
        
        return monotonic_loss


class QualityEnhancedMelLoss(nn.Module):
    """
    –£–ª—É—á—à–µ–Ω–Ω—ã–π Mel Loss —Å —Ñ–æ–∫—É—Å–æ–º –Ω–∞ –∫–∞—á–µ—Å—Ç–≤–æ –∏ –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç—å.
    –ö–æ–º–±–∏–Ω–∏—Ä—É–µ—Ç –Ω–µ—Å–∫–æ–ª—å–∫–æ –ø–æ–¥—Ö–æ–¥–æ–≤ –¥–ª—è –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–≥–æ –∫–∞—á–µ—Å—Ç–≤–∞.
    """
    
    def __init__(self, alpha=1.0, beta=0.5, gamma=0.3):
        super(QualityEnhancedMelLoss, self).__init__()
        self.alpha = alpha  # MSE weight
        self.beta = beta    # L1 weight  
        self.gamma = gamma  # Dynamic range weight
        
    def forward(self, mel_pred, mel_target):
        """
        –ö–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–π mel loss –¥–ª—è –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–≥–æ –∫–∞—á–µ—Å—Ç–≤–∞.
        """
        # 1. –ë–∞–∑–æ–≤—ã–π MSE loss
        mse_loss = F.mse_loss(mel_pred, mel_target)
        
        # 2. L1 loss –¥–ª—è —Ä–µ–∑–∫–æ—Å—Ç–∏ –¥–µ—Ç–∞–ª–µ–π
        l1_loss = F.l1_loss(mel_pred, mel_target)
        
        # 3. Dynamic range loss –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –¥–∏–Ω–∞–º–∏–∫–∏
        pred_range = torch.max(mel_pred, dim=2)[0] - torch.min(mel_pred, dim=2)[0]
        target_range = torch.max(mel_target, dim=2)[0] - torch.min(mel_target, dim=2)[0]
        range_loss = F.mse_loss(pred_range, target_range)
        
        # 4. –ö–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–π loss
        total_loss = (
            self.alpha * mse_loss + 
            self.beta * l1_loss + 
            self.gamma * range_loss
        )
        
        return total_loss


def create_enhanced_loss_function(hparams):
    """
    –§–∞–±—Ä–∏—á–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è —É–ª—É—á—à–µ–Ω–Ω–æ–π loss function.
    """
    return Tacotron2Loss(hparams)
