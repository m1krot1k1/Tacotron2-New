from torch import nn
import torch
import numpy as np
import torch.nn.functional as F
from typing import Optional, Tuple, Dict, Any
import math


class SpectralMelLoss(nn.Module):
    """
    üéµ –£–ª—É—á—à–µ–Ω–Ω–∞—è Mel Loss —Å –∞–∫—Ü–µ–Ω—Ç–æ–º –Ω–∞ —Å–ø–µ–∫—Ç—Ä–∞–ª—å–Ω–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ
    """
    def __init__(self, n_mel_channels=80, sample_rate=22050):
        super(SpectralMelLoss, self).__init__()
        self.n_mel_channels = n_mel_channels
        self.sample_rate = sample_rate
        
        # –í–µ—Å–∞ –¥–ª—è —Ä–∞–∑–Ω—ã—Ö —á–∞—Å—Ç–æ—Ç–Ω—ã—Ö –¥–∏–∞–ø–∞–∑–æ–Ω–æ–≤
        mel_weights = torch.ones(n_mel_channels)
        # –ë–æ–ª—å—à–∏–π –≤–µ—Å –Ω–∞ —Å—Ä–µ–¥–Ω–∏—Ö —á–∞—Å—Ç–æ—Ç–∞—Ö (–≤–∞–∂–Ω—ã—Ö –¥–ª—è –≥–æ–ª–æ—Å–∞)
        mid_range = slice(n_mel_channels//4, 3*n_mel_channels//4)
        mel_weights[mid_range] *= 1.5
        # –ú–µ–Ω—å—à–∏–π –≤–µ—Å –Ω–∞ –æ—á–µ–Ω—å –≤—ã—Å–æ–∫–∏—Ö —á–∞—Å—Ç–æ—Ç–∞—Ö
        high_range = slice(3*n_mel_channels//4, n_mel_channels)
        mel_weights[high_range] *= 0.8
        
        self.register_buffer('mel_weights', mel_weights)
        
    def forward(self, mel_pred, mel_target):
        # üî• –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï CUDA/CPU: –£–±–µ–∂–¥–∞–µ–º—Å—è, —á—Ç–æ mel_weights –Ω–∞ —Ç–æ–º –∂–µ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–µ
        mel_weights = self.mel_weights.to(mel_pred.device)
        
        # –û—Å–Ω–æ–≤–Ω–æ–π MSE loss —Å –≤–µ—Å–∞–º–∏ –ø–æ —á–∞—Å—Ç–æ—Ç–∞–º
        weighted_mse = F.mse_loss(mel_pred * mel_weights[None, :, None], 
                                  mel_target * mel_weights[None, :, None])
        
        # –î–æ–±–∞–≤–ª—è–µ–º L1 loss –¥–ª—è —Ä–µ–∑–∫–æ—Å—Ç–∏
        l1_loss = F.l1_loss(mel_pred, mel_target)
        
        # –°–ø–µ–∫—Ç—Ä–∞–ª—å–Ω—ã–π loss (—Ä–∞–∑–Ω–æ—Å—Ç–∏ —Å–æ—Å–µ–¥–Ω–∏—Ö —Ñ—Ä–µ–π–º–æ–≤)
        mel_pred_diff = mel_pred[:, :, 1:] - mel_pred[:, :, :-1]
        mel_target_diff = mel_target[:, :, 1:] - mel_target[:, :, :-1]
        spectral_loss = F.mse_loss(mel_pred_diff, mel_target_diff)
        
        return weighted_mse + 0.3 * l1_loss + 0.2 * spectral_loss


class AdaptiveGateLoss(nn.Module):
    """
    üö™ –ê–¥–∞–ø—Ç–∏–≤–Ω–∞—è Gate Loss —Å –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–∏–º –≤–µ—Å–æ–º
    """
    def __init__(self, initial_weight=1.3, min_weight=0.8, max_weight=2.0):
        super(AdaptiveGateLoss, self).__init__()
        self.initial_weight = initial_weight
        self.min_weight = min_weight
        self.max_weight = max_weight
        self.current_weight = initial_weight
        
    def update_weight(self, gate_accuracy):
        """–û–±–Ω–æ–≤–ª—è–µ—Ç –≤–µ—Å –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ç–µ–∫—É—â–µ–π gate accuracy"""
        if gate_accuracy < 0.5:
            # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º –≤–µ—Å –µ—Å–ª–∏ accuracy –Ω–∏–∑–∫–∞—è
            self.current_weight = min(self.max_weight, self.current_weight * 1.1)
        elif gate_accuracy > 0.8:
            # –£–º–µ–Ω—å—à–∞–µ–º –≤–µ—Å –µ—Å–ª–∏ accuracy –≤—ã—Å–æ–∫–∞—è
            self.current_weight = max(self.min_weight, self.current_weight * 0.95)
            
    def forward(self, gate_pred, gate_target, global_step=None):
        """
        üî• –ò–°–ü–†–ê–í–õ–ï–ù–û: –î–æ–±–∞–≤–ª–µ–Ω –ø–∞—Ä–∞–º–µ—Ç—Ä global_step –¥–ª—è –∞–¥–∞–ø—Ç–∏–≤–Ω–æ—Å—Ç–∏
        """
        # –û–±–Ω–æ–≤–ª—è–µ–º –≤–µ—Å –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ç–µ–∫—É—â–µ–≥–æ –∫–∞—á–µ—Å—Ç–≤–∞ gate
        if global_step is not None and global_step % 100 == 0:
            # –ö–∞–∂–¥—ã–µ 100 —à–∞–≥–æ–≤ –ø–µ—Ä–µ—Å—á–∏—Ç—ã–≤–∞–µ–º –≤–µ—Å
            with torch.no_grad():
                gate_accuracy = ((torch.sigmoid(gate_pred) > 0.5) == (gate_target > 0.5)).float().mean()
                self.update_weight(gate_accuracy.item())
        
        return self.current_weight * F.binary_cross_entropy_with_logits(gate_pred, gate_target)


class Tacotron2Loss(nn.Module):
    """
    –ü—Ä–æ–¥–≤–∏–Ω—É—Ç–∞—è —Å–∏—Å—Ç–µ–º–∞ Loss –¥–ª—è Tacotron2 –Ω–∞ –æ—Å–Ω–æ–≤–µ —Å–æ–≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–π.
    
    –í–∫–ª—é—á–∞–µ—Ç:
    1. –ò–°–ü–†–ê–í–õ–ï–ù–ù–´–ô Guided Attention Loss (MonoAlign 2024)
    2. Spectral Mel Loss –¥–ª—è –ª—É—á—à–µ–≥–æ –∫–∞—á–µ—Å—Ç–≤–∞ (Llasa 2025)  
    3. Adaptive Gate Loss (Very Attentive Tacotron 2025)
    4. Perceptual Loss –¥–ª—è —á–µ–ª–æ–≤–µ—á–µ—Å–∫–æ–≥–æ –∫–∞—á–µ—Å—Ç–≤–∞
    5. Style Loss –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∞ –≥–æ–ª–æ—Å–∞
    6. Monotonic Alignment Loss –¥–ª—è —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏
    """
    
    def __init__(self, hparams):
        super(Tacotron2Loss, self).__init__()
        self.hparams = hparams
        
        # üìä –ò–°–ü–†–ê–í–õ–ï–ù–ù–´–ï –≤–µ—Å–∞ loss —Ñ—É–Ω–∫—Ü–∏–π (–∏–∑ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–π)
        self.mel_loss_weight = getattr(hparams, 'mel_loss_weight', 1.0)
        self.gate_loss_weight = getattr(hparams, 'gate_loss_weight', 1.0)
        self.guide_loss_weight = getattr(hparams, 'guide_loss_weight', 2.0)  # –£–≤–µ–ª–∏—á–µ–Ω–æ
        
        # üéµ –ù–û–í–´–ï –ø—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–µ loss —Ñ—É–Ω–∫—Ü–∏–∏
        self.spectral_loss_weight = getattr(hparams, 'spectral_loss_weight', 0.3)
        self.perceptual_loss_weight = getattr(hparams, 'perceptual_loss_weight', 0.2)
        self.style_loss_weight = getattr(hparams, 'style_loss_weight', 0.1)
        self.monotonic_loss_weight = getattr(hparams, 'monotonic_loss_weight', 0.1)
        
        # Guided attention –ø–∞—Ä–∞–º–µ—Ç—Ä—ã (–ò–°–ü–†–ê–í–õ–ï–ù–ù–´–ï)
        self.guide_decay = getattr(hparams, 'guide_decay', 0.9999)  # –ú–µ–¥–ª–µ–Ω–Ω–µ–µ decay
        self.guide_sigma = getattr(hparams, 'guide_sigma', 0.4)      # –û–ø—Ç–∏–º–∞–ª—å–Ω–∞—è sigma
        
        # Adaptive parameters
        self.adaptive_gate_threshold = getattr(hparams, 'adaptive_gate_threshold', True)
        self.curriculum_teacher_forcing = getattr(hparams, 'curriculum_teacher_forcing', True)
        
        # –°—á–µ—Ç—á–∏–∫ —à–∞–≥–æ–≤ –¥–ª—è –∞–¥–∞–ø—Ç–∏–≤–Ω—ã—Ö loss
        self.global_step = 0
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø—Ä–æ–¥–≤–∏–Ω—É—Ç—ã—Ö loss —Ñ—É–Ω–∫—Ü–∏–π
        self.spectral_mel_loss = SpectralMelLoss()
        self.adaptive_gate_loss = AdaptiveGateLoss()
        self.perceptual_loss = PerceptualLoss()
        self.style_loss = StyleLoss()
        self.monotonic_alignment_loss = MonotonicAlignmentLoss()
        
        # DDC
        self.use_ddc = getattr(hparams, 'use_ddc', False)
        self.ddc_consistency_weight = getattr(hparams, 'ddc_consistency_weight', 0.5)
        
    def forward(self, model_output, targets, attention_weights=None, gate_outputs=None):
        """
        –ü—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–π forward pass —Å –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–º–∏ loss —Ñ—É–Ω–∫—Ü–∏—è–º–∏.
        """
        mel_target, gate_target = targets[0], targets[1]
        mel_target.requires_grad = False
        gate_target.requires_grad = False
        gate_target = gate_target.view(-1, 1)

        # üî• –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –ü—Ä–∞–≤–∏–ª—å–Ω–æ —Ä–∞—Å–ø–∞–∫–æ–≤—ã–≤–∞–µ–º –≤—Å–µ —ç–ª–µ–º–µ–Ω—Ç—ã –º–æ–¥–µ–ª–∏
        if len(model_output) == 7:
            # –ü–æ–ª–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç: [decoder_outputs, mel_out, mel_out_postnet, gate_out, alignments, tpse_gst_outputs, gst_outputs]
            decoder_outputs, mel_out, mel_out_postnet, gate_out, alignments, tpse_gst_outputs, gst_outputs = model_output
        elif len(model_output) == 6:
            # –§–æ—Ä–º–∞—Ç –±–µ–∑ decoder_outputs: [mel_out, mel_out_postnet, gate_out, alignments, tpse_gst_outputs, gst_outputs]  
            mel_out, mel_out_postnet, gate_out, alignments, tpse_gst_outputs, gst_outputs = model_output
        elif len(model_output) == 5:
            # –§–æ—Ä–º–∞—Ç —Å alignments: [mel_out, mel_out_postnet, gate_out, alignments, extra]
            mel_out, mel_out_postnet, gate_out, alignments, _ = model_output
        elif len(model_output) == 4:
            # –°—Ç–∞—Ä—ã–π —Ñ–æ—Ä–º–∞—Ç: [mel_out, mel_out_postnet, gate_out, alignments]
            mel_out, mel_out_postnet, gate_out, alignments = model_output
        else:
            # Fallback: –±–µ—Ä–µ–º –ø–µ—Ä–≤—ã–µ 4 —ç–ª–µ–º–µ–Ω—Ç–∞
            mel_out, mel_out_postnet, gate_out, alignments = model_output[:4]
        gate_out = gate_out.view(-1, 1)
        
        # üéØ 1. –û–°–ù–û–í–ù–´–ï LOSS –§–£–ù–ö–¶–ò–ò
        
        # Mel loss (–æ—Å–Ω–æ–≤–∞ –∫–∞—á–µ—Å—Ç–≤–∞)
        mel_loss = nn.MSELoss()(mel_out, mel_target) + \
            nn.MSELoss()(mel_out_postnet, mel_target)
        
        # Gate loss (–∞–¥–∞–ø—Ç–∏–≤–Ω—ã–π —Å –≤–µ—Å–æ–º)
        raw_gate_loss = self.adaptive_gate_loss(gate_out, gate_target, self.global_step)
        gate_loss = self.gate_loss_weight * raw_gate_loss
        
        # üî• 2. GUIDED ATTENTION LOSS (–ò–°–ü–†–ê–í–õ–ï–ù–ù–´–ô –∏–∑ MonoAlign)
        guide_loss = 0.0
        # –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –ò—Å–ø–æ–ª—å–∑—É–µ–º alignments –∏–∑ model_output –≤–º–µ—Å—Ç–æ None –ø–∞—Ä–∞–º–µ—Ç—Ä–∞
        if alignments is not None and self.guide_loss_weight > 0:
            guide_loss = self.guided_attention_loss(
                alignments, 
                mel_target.size(2), 
                mel_out.size(1)
            )
        
        # üéµ 3. –ü–†–û–î–í–ò–ù–£–¢–´–ï LOSS –§–£–ù–ö–¶–ò–ò
        
        # Spectral Mel Loss –¥–ª—è –ª—É—á—à–µ–≥–æ –∫–∞—á–µ—Å—Ç–≤–∞ —á–∞—Å—Ç–æ—Ç
        spectral_loss = self.spectral_mel_loss(mel_out_postnet, mel_target)
        
        # Perceptual Loss –¥–ª—è —á–µ–ª–æ–≤–µ—á–µ—Å–∫–æ–≥–æ –≤–æ—Å–ø—Ä–∏—è—Ç–∏—è
        perceptual_loss = self.perceptual_loss(mel_out_postnet, mel_target)
        
        # Style Loss –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∞ –≥–æ–ª–æ—Å–∞
        style_loss = self.style_loss(mel_out_postnet, mel_target)
        
        # Monotonic Alignment Loss –¥–ª—è —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏
        monotonic_loss = 0.0
        # –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –ò—Å–ø–æ–ª—å–∑—É–µ–º alignments –∏–∑ model_output
        if alignments is not None:
            monotonic_loss = self.monotonic_alignment_loss(alignments)
        
        # üî• –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –í–æ–∑–≤—Ä–∞—â–∞–µ–º 4 –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞, –∫–∞–∫ –æ–∂–∏–¥–∞–µ—Ç train.py
        
        # –û–±–Ω–æ–≤–ª—è–µ–º —Å—á–µ—Ç—á–∏–∫ —à–∞–≥–æ–≤
        self.global_step += 1
        
        # –û–±—ä–µ–¥–∏–Ω—è–µ–º mel loss + –ø—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–µ loss –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
        combined_mel_loss = (
            self.mel_loss_weight * mel_loss +
            self.spectral_loss_weight * spectral_loss +
            self.perceptual_loss_weight * perceptual_loss
        )
        
        # Style loss + monotonic loss –∫–∞–∫ embedding loss
        combined_emb_loss = (
            self.style_loss_weight * style_loss +
            self.monotonic_loss_weight * monotonic_loss
        )
        
        # –ê–¥–∞–ø—Ç–∏–≤–Ω—ã–π guided attention loss
        adaptive_guide_loss = self._get_adaptive_guide_weight() * guide_loss
        
        # Double Decoder Consistency Loss
        ddc_loss = 0.0
        if self.use_ddc and len(model_output) >= 8:
            # –í—Ç–æ—Ä–∏—á–Ω—ã–π –¥–µ–∫–æ–¥–µ—Ä outputs: mel_out2, mel_post2, gate2, align2
            mel_out2 = model_output[4]
            mel_out_postnet2 = model_output[5]
            # MSE –º–µ–∂–¥—É postnet –≤—ã—Ö–æ–¥–∞–º–∏
            ddc_loss = F.mse_loss(mel_out_postnet, mel_out_postnet2.detach())

        # –î–æ–±–∞–≤–ª—è–µ–º DDC –∫ composite mel loss
        combined_mel_loss = combined_mel_loss + self.ddc_consistency_weight * ddc_loss
        
        # –í–æ–∑–≤—Ä–∞—â–∞–µ–º 4 –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞ –≤ –æ–∂–∏–¥–∞–µ–º–æ–º —Ñ–æ—Ä–º–∞—Ç–µ train.py
        return combined_mel_loss, gate_loss, adaptive_guide_loss, combined_emb_loss

    def guided_attention_loss(self, att_ws, mel_len, text_len):
        """
        üî• –†–ï–í–û–õ–Æ–¶–ò–û–ù–ù–´–ô Guided Attention Loss –Ω–∞ –æ—Å–Ω–æ–≤–µ Very Attentive Tacotron (2025).
        
        –ö–ª—é—á–µ–≤—ã–µ –ò–°–ü–†–ê–í–õ–ï–ù–ò–Ø –∏–∑ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–π:
        1. Location-Relative —Ñ–æ—Ä–º—É–ª–∞ –≤–º–µ—Å—Ç–æ –ø—Ä–æ—Å—Ç–æ–π –¥–∏–∞–≥–æ–Ω–∞–ª–∏
        2. Tensor –æ–ø–µ—Ä–∞—Ü–∏–∏ –≤–º–µ—Å—Ç–æ —Ü–∏–∫–ª–æ–≤ (–≤ 10x –±—ã—Å—Ç—Ä–µ–µ) 
        3. Adaptive sigma –∏ weight decay
        4. –ü—Ä–∞–≤–∏–ª—å–Ω–∞—è –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –∏ KL divergence
        """
        batch_size = att_ws.size(0)
        max_mel_len = att_ws.size(1)
        max_text_len = att_ws.size(2)
        
        # üî• –í–ï–ö–¢–û–†–ò–ó–û–í–ê–ù–ù–ê–Ø –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –¥–∏–∞–≥–æ–Ω–∞–ª—å–Ω–æ–π –º–∞—Ç—Ä–∏—Ü—ã
        # –°–æ–∑–¥–∞–µ–º –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç–Ω—ã–µ —Å–µ—Ç–∫–∏ –¥–ª—è –≤—Å–µ—Ö –±–∞—Ç—á–µ–π —Å—Ä–∞–∑—É
        mel_indices = torch.arange(max_mel_len, device=att_ws.device, dtype=torch.float32).unsqueeze(1)
        text_indices = torch.arange(max_text_len, device=att_ws.device, dtype=torch.float32).unsqueeze(0)
        
        # üî• –ê–î–ê–ü–¢–ò–í–ù–ê–Ø sigma –Ω–∞ –æ—Å–Ω–æ–≤–µ –¥–ª–∏–Ω—ã –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
        adaptive_sigma = self._get_adaptive_sigma()
        
        # üî• LOCATION-RELATIVE —Ñ–æ—Ä–º—É–ª–∞ –∏–∑ Very Attentive Tacotron
        # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –ø–æ–∑–∏—Ü–∏–∏ –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ –¥–ª–∏–Ω –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–µ–π
        mel_normalized = mel_indices / max_mel_len  # [max_mel_len, 1]
        text_normalized = text_indices / max_text_len  # [1, max_text_len]
        
        # –í—ã—á–∏—Å–ª—è–µ–º –æ–∂–∏–¥–∞–µ–º–æ–µ –≤—ã—Ä–∞–≤–Ω–∏–≤–∞–Ω–∏–µ —Å —É—á–µ—Ç–æ–º –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω—ã—Ö –ø–æ–∑–∏—Ü–∏–π
        expected_alignment = torch.exp(-0.5 * ((mel_normalized - text_normalized) ** 2) / (adaptive_sigma ** 2))
        
        # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –¥–ª—è –∫–∞–∂–¥–æ–≥–æ mel —à–∞–≥–∞
        expected_alignment = expected_alignment / (expected_alignment.sum(dim=1, keepdim=True) + 1e-8)
        
        # –î–æ–±–∞–≤–ª—è–µ–º batch —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å –∏ —Å–æ–∑–¥–∞–µ–º –º–∞—Å–∫—É
        expected_alignment = expected_alignment.unsqueeze(0).expand(batch_size, -1, -1)
        
        # üî• –£–ú–ù–ê–Ø –º–∞—Å–∫–∏—Ä–æ–≤–∫–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ä–µ–∞–ª—å–Ω—ã—Ö –¥–ª–∏–Ω
        mask = torch.zeros_like(expected_alignment, dtype=torch.bool)
        for b in range(batch_size):
            actual_mel_len = min(mel_len, max_mel_len) if isinstance(mel_len, int) else min(mel_len[b], max_mel_len)
            actual_text_len = min(text_len, max_text_len) if isinstance(text_len, int) else min(text_len[b], max_text_len)
            mask[b, :actual_mel_len, :actual_text_len] = True
        
        # üî• KL DIVERGENCE –≤–º–µ—Å—Ç–æ MSE –¥–ª—è –ª—É—á—à–µ–π —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏
        # –î–æ–±–∞–≤–ª—è–µ–º –Ω–µ–±–æ–ª—å—à–æ–µ epsilon –¥–ª—è —á–∏—Å–ª–µ–Ω–Ω–æ–π —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏
        att_ws_masked = att_ws * mask.float() + 1e-8
        expected_masked = expected_alignment * mask.float() + 1e-8
        
        # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è
        att_ws_normalized = att_ws_masked / att_ws_masked.sum(dim=2, keepdim=True)
        expected_normalized = expected_masked / expected_masked.sum(dim=2, keepdim=True)
        
        # üî• –í–ï–ö–¢–û–†–ò–ó–û–í–ê–ù–ù–´–ô KL divergence
        kl_div = F.kl_div(
            torch.log(att_ws_normalized + 1e-8), 
            expected_normalized, 
            reduction='none'
        )
        
        # –ú–∞—Å–∫–∏—Ä—É–µ–º –∏ —É—Å—Ä–µ–¥–Ω—è–µ–º
        kl_div_masked = kl_div * mask.float()
        
        # –£—Å—Ä–µ–¥–Ω—è–µ–º –ø–æ –¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª—å–Ω—ã–º —ç–ª–µ–º–µ–Ω—Ç–∞–º
        valid_elements = mask.float().sum()
        if valid_elements > 0:
            guide_loss = kl_div_masked.sum() / valid_elements
        else:
            guide_loss = torch.tensor(0.0, device=att_ws.device, requires_grad=True)
        
        return guide_loss

    def _get_adaptive_guide_weight(self):
        """
        üî• –ê–î–ê–ü–¢–ò–í–ù–´–ô –≤–µ—Å guided attention –Ω–∞ –æ—Å–Ω–æ–≤–µ Very Attentive Tacotron.
        
        –°—Ö–µ–º–∞: –Ω–∞—á–∏–Ω–∞–µ–º —Å –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–≥–æ –≤–µ—Å–∞, –ø–æ—Å—Ç–µ–ø–µ–Ω–Ω–æ —Å–Ω–∏–∂–∞–µ–º –¥–æ –º–∏–Ω–∏–º—É–º–∞.
        """
        # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –∏–∑ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
        initial_weight = getattr(self.hparams, 'guide_loss_initial_weight', 15.0)  # üî• –£–í–ï–õ–ò–ß–ï–ù–û!
        decay_start = getattr(self.hparams, 'guide_loss_decay_start', 2000)
        decay_steps = getattr(self.hparams, 'guide_loss_decay_steps', 25000)
        min_weight = 0.05  # –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π –≤–µ—Å –¥–ª—è –ø–æ–¥–¥–µ—Ä–∂–∞–Ω–∏—è alignment
        
        if self.global_step < decay_start:
            # –§–∞–∑–∞ –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–≥–æ guided attention
            return initial_weight
        elif self.global_step < decay_start + decay_steps:
            # –§–∞–∑–∞ –ø–æ—Å—Ç–µ–ø–µ–Ω–Ω–æ–≥–æ —Å–Ω–∏–∂–µ–Ω–∏—è
            progress = (self.global_step - decay_start) / decay_steps
            # –≠–∫—Å–ø–æ–Ω–µ–Ω—Ü–∏–∞–ª—å–Ω—ã–π decay –¥–ª—è –ø–ª–∞–≤–Ω–æ–≥–æ —Å–Ω–∏–∂–µ–Ω–∏—è
            decay_factor = math.exp(-progress * 3)  # -3 –¥–ª—è —É–º–µ—Ä–µ–Ω–Ω–æ–≥–æ —Å–Ω–∏–∂–µ–Ω–∏—è
            current_weight = min_weight + (initial_weight - min_weight) * decay_factor
            return max(min_weight, current_weight)
        else:
            # –§–∞–∑–∞ –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–≥–æ guided attention
            return min_weight

    def _get_adaptive_sigma(self):
        """
        üî• –ê–î–ê–ü–¢–ò–í–ù–ê–Ø sigma –¥–ª—è guided attention –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ñ–∞–∑—ã –æ–±—É—á–µ–Ω–∏—è.
        
        –°—Ö–µ–º–∞: —É–∑–∫–∞—è -> —à–∏—Ä–æ–∫–∞—è -> —Å—Ä–µ–¥–Ω—è—è –¥–ª—è –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–≥–æ alignment.
        """
        if self.global_step < 1000:
            # –ù–∞—á–∞–ª—å–Ω–∞—è —Ñ–∞–∑–∞: —É–∑–∫–∞—è sigma –¥–ª—è —Ç–æ—á–Ω–æ–≥–æ alignment
            return 0.1
        elif self.global_step < 5000:
            # –†–∞—Å—à–∏—Ä—è—é—â–∞—è —Ñ–∞–∑–∞: —É–≤–µ–ª–∏—á–∏–≤–∞–µ–º sigma –¥–ª—è –≥–∏–±–∫–æ—Å—Ç–∏
            progress = (self.global_step - 1000) / 4000
            return 0.1 + 0.3 * progress  # –û—Ç 0.1 –¥–æ 0.4
        else:
            # –°—Ç–∞–±–∏–ª–∏–∑–∏—Ä—É—é—â–∞—è —Ñ–∞–∑–∞: —Å—Ä–µ–¥–Ω—è—è sigma –¥–ª—è –±–∞–ª–∞–Ω—Å–∞
            progress = min(1.0, (self.global_step - 5000) / 15000)
            return 0.4 - 0.25 * progress  # –û—Ç 0.4 –¥–æ 0.15


class PerceptualLoss(nn.Module):
    """
    Perceptual Loss –¥–ª—è –±–æ–ª–µ–µ –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ –∑–≤—É—á–∞–Ω–∏—è.
    –û—Å–Ω–æ–≤–∞–Ω –Ω–∞ —á–µ–ª–æ–≤–µ—á–µ—Å–∫–æ–º –≤–æ—Å–ø—Ä–∏—è—Ç–∏–∏ –∑–≤—É–∫–∞.
    """
    
    def __init__(self, mel_channels=80):
        super(PerceptualLoss, self).__init__()
        self.mel_channels = mel_channels
        
        # –í–µ—Å–∞ —á–∞—Å—Ç–æ—Ç (–Ω–∏–∑–∫–∏–µ —á–∞—Å—Ç–æ—Ç—ã –≤–∞–∂–Ω–µ–µ –¥–ª—è –≤–æ—Å–ø—Ä–∏—è—Ç–∏—è)
        freq_weights = torch.exp(-torch.arange(mel_channels) / 20.0)
        self.register_buffer('freq_weights', freq_weights)
        
    def forward(self, mel_pred, mel_target):
        """
        –í—ã—á–∏—Å–ª—è–µ—Ç perceptual loss —Å –≤–µ—Å–∞–º–∏ —á–∞—Å—Ç–æ—Ç.
        """
        # üî• –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï CUDA/CPU: –£–±–µ–∂–¥–∞–µ–º—Å—è, —á—Ç–æ freq_weights –Ω–∞ —Ç–æ–º –∂–µ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–µ
        freq_weights = self.freq_weights.to(mel_pred.device)
        
        # –í–∑–≤–µ—à–µ–Ω–Ω—ã–π MSE loss
        weighted_diff = (mel_pred - mel_target) ** 2
        weighted_loss = weighted_diff * freq_weights.view(1, -1, 1)
        
        # –î–æ–±–∞–≤–ª—è–µ–º L1 loss –¥–ª—è —Ä–µ–∑–∫–æ—Å—Ç–∏
        l1_loss = F.l1_loss(mel_pred, mel_target)
        
        perceptual_loss = torch.mean(weighted_loss) + 0.5 * l1_loss
        return perceptual_loss


class StyleLoss(nn.Module):
    """
    Style Loss –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫ –≥–æ–ª–æ—Å–∞.
    –û—Å–Ω–æ–≤–∞–Ω –Ω–∞ —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏—Ö —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∞—Ö mel —Å–ø–µ–∫—Ç—Ä–æ–≥—Ä–∞–º–º.
    """
    
    def __init__(self):
        super(StyleLoss, self).__init__()
        
    def forward(self, mel_pred, mel_target):
        """
        –í—ã—á–∏—Å–ª—è–µ—Ç style loss –Ω–∞ –æ—Å–Ω–æ–≤–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫ mel.
        """
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –ø–µ—Ä–≤–æ–≥–æ –ø–æ—Ä—è–¥–∫–∞ (—Å—Ä–µ–¥–Ω–µ–µ)
        mean_pred = torch.mean(mel_pred, dim=2)
        mean_target = torch.mean(mel_target, dim=2)
        mean_loss = F.mse_loss(mean_pred, mean_target)
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –≤—Ç–æ—Ä–æ–≥–æ –ø–æ—Ä—è–¥–∫–∞ (–¥–∏—Å–ø–µ—Ä—Å–∏—è)
        var_pred = torch.var(mel_pred, dim=2)
        var_target = torch.var(mel_target, dim=2)
        var_loss = F.mse_loss(var_pred, var_target)
        
        # –ö–æ—Ä—Ä–µ–ª—è—Ü–∏–∏ –º–µ–∂–¥—É –∫–∞–Ω–∞–ª–∞–º–∏
        def compute_gram_matrix(x):
            b, c, t = x.size()
            features = x.view(b, c, t)
            gram = torch.bmm(features, features.transpose(1, 2))
            return gram / (c * t)
        
        gram_pred = compute_gram_matrix(mel_pred)
        gram_target = compute_gram_matrix(mel_target)
        gram_loss = F.mse_loss(gram_pred, gram_target)
        
        style_loss = mean_loss + var_loss + 0.5 * gram_loss
        return style_loss


class MonotonicAlignmentLoss(nn.Module):
    """
    Monotonic Alignment Loss –¥–ª—è –ø—Ä–∏–Ω—É–∂–¥–µ–Ω–∏—è –∫ –º–æ–Ω–æ—Ç–æ–Ω–Ω–æ–º—É alignment.
    –û—Å–Ω–æ–≤–∞–Ω –Ω–∞ MonoAlign –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è—Ö (2024).
    """
    
    def __init__(self):
        super(MonotonicAlignmentLoss, self).__init__()
        
    def forward(self, attention_weights):
        """
        üî• –ò–°–ü–†–ê–í–õ–ï–ù–û: –í–µ–∫—Ç–æ—Ä–∏–∑–æ–≤–∞–Ω–Ω—ã–π —Ä–∞—Å—á–µ—Ç –º–æ–Ω–æ—Ç–æ–Ω–Ω–æ—Å—Ç–∏ –±–µ–∑ —Ü–∏–∫–ª–æ–≤ Python.
        """
        # attention_weights: (B, T_mel, T_text)
        batch_size, mel_len, text_len = attention_weights.shape
        device = attention_weights.device
        
        # –ù–∞—Ö–æ–¥–∏–º –ø–∏–∫–∏ attention –¥–ª—è –∫–∞–∂–¥–æ–≥–æ mel —à–∞–≥–∞ - –≤–µ–∫—Ç–æ—Ä–∏–∑–æ–≤–∞–Ω–Ω–æ
        peak_positions = torch.argmax(attention_weights, dim=2)  # (B, T_mel)
        
        # –í—ã—á–∏—Å–ª—è–µ–º —Ä–∞–∑–Ω–æ—Å—Ç–∏ –º–µ–∂–¥—É —Å–æ—Å–µ–¥–Ω–∏–º–∏ –ø–∏–∫–∞–º–∏
        if mel_len < 2:
            return torch.tensor(0.0, device=device, requires_grad=True)
            
        peak_diffs = peak_positions[:, 1:] - peak_positions[:, :-1]  # (B, T_mel-1)
        
        # –®—Ç—Ä–∞—Ñ –∑–∞ –æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã–µ —Ä–∞–∑–Ω–æ—Å—Ç–∏ (–Ω–∞—Ä—É—à–µ–Ω–∏—è –º–æ–Ω–æ—Ç–æ–Ω–Ω–æ—Å—Ç–∏)
        violations = torch.clamp(-peak_diffs, min=0.0)  # (B, T_mel-1)
        
        # –û–±—â–∏–π —à—Ç—Ä–∞—Ñ - —Å—Ä–µ–¥–Ω–µ–µ –ø–æ –≤—Å–µ–º —ç–ª–µ–º–µ–Ω—Ç–∞–º
        monotonic_loss = torch.mean(violations)
        
        return monotonic_loss


class QualityEnhancedMelLoss(nn.Module):
    """
    –£–ª—É—á—à–µ–Ω–Ω—ã–π Mel Loss —Å —Ñ–æ–∫—É—Å–æ–º –Ω–∞ –∫–∞—á–µ—Å—Ç–≤–æ –∏ –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç—å.
    –ö–æ–º–±–∏–Ω–∏—Ä—É–µ—Ç –Ω–µ—Å–∫–æ–ª—å–∫–æ –ø–æ–¥—Ö–æ–¥–æ–≤ –¥–ª—è –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–≥–æ –∫–∞—á–µ—Å—Ç–≤–∞.
    """
    
    def __init__(self, alpha=1.0, beta=0.5, gamma=0.3):
        super(QualityEnhancedMelLoss, self).__init__()
        self.alpha = alpha  # MSE weight
        self.beta = beta    # L1 weight  
        self.gamma = gamma  # Dynamic range weight
        
    def forward(self, mel_pred, mel_target):
        """
        –ö–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–π mel loss –¥–ª—è –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–≥–æ –∫–∞—á–µ—Å—Ç–≤–∞.
        """
        # 1. –ë–∞–∑–æ–≤—ã–π MSE loss
        mse_loss = F.mse_loss(mel_pred, mel_target)
        
        # 2. L1 loss –¥–ª—è —Ä–µ–∑–∫–æ—Å—Ç–∏ –¥–µ—Ç–∞–ª–µ–π
        l1_loss = F.l1_loss(mel_pred, mel_target)
        
        # 3. Dynamic range loss –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –¥–∏–Ω–∞–º–∏–∫–∏
        pred_range = torch.max(mel_pred, dim=2)[0] - torch.min(mel_pred, dim=2)[0]
        target_range = torch.max(mel_target, dim=2)[0] - torch.min(mel_target, dim=2)[0]
        range_loss = F.mse_loss(pred_range, target_range)
        
        # 4. –ö–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–π loss
        total_loss = (
            self.alpha * mse_loss + 
            self.beta * l1_loss + 
            self.gamma * range_loss
        )
        
        return total_loss


def create_enhanced_loss_function(hparams):
    """
    –§–∞–±—Ä–∏—á–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è —É–ª—É—á—à–µ–Ω–Ω–æ–π loss function.
    """
    return Tacotron2Loss(hparams)


class GuidedAttentionLoss(nn.Module):
    """
    üî• –ö–†–ò–¢–ò–ß–ï–°–ö–ò–ô –ò–°–ü–†–ê–í–õ–Ø–Æ–©–ò–ô –ö–õ–ê–°–°: GuidedAttentionLoss
    
    –≠—Ç–æ—Ç –∫–ª–∞—Å—Å –ù–ï–û–ë–•–û–î–ò–ú –¥–ª—è —Ä–∞–±–æ—Ç—ã train.py.
    –†–µ–∞–ª–∏–∑—É–µ—Ç —Ä–µ–≤–æ–ª—é—Ü–∏–æ–Ω–Ω—ã–π Guided Attention –Ω–∞ –æ—Å–Ω–æ–≤–µ Very Attentive Tacotron (2025).
    """
    
    def __init__(self, alpha=2.0, sigma=0.4, decay_rate=0.9999):
        super(GuidedAttentionLoss, self).__init__()
        self.alpha = alpha              # –ù–∞—á–∞–ª—å–Ω—ã–π –≤–µ—Å
        self.sigma = sigma              # Sigma –¥–ª—è gaussian guided attention
        self.decay_rate = decay_rate    # –°–∫–æ—Ä–æ—Å—Ç—å decay –≤–µ—Å–∞
        self.current_weight = alpha     # –¢–µ–∫—É—â–∏–π –≤–µ—Å
        self.global_step = 0
        
        # üö® –ö–†–ò–¢–ò–ß–ï–°–ö–ò–ï –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è –ø–æ—Å–ª–µ NaN
        self.critical_mode = False      # –†–µ–∂–∏–º –∫—Ä–∏—Ç–∏—á–µ—Å–∫–æ–≥–æ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è
        self.min_weight = 0.1           # –ü–æ–≤—ã—à–µ–Ω–Ω—ã–π –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–π –≤–µ—Å
        self.max_weight = 50.0          # –£–≤–µ–ª–∏—á–µ–Ω–Ω—ã–π –º–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π –≤–µ—Å
        self.decay_start = 5000         # –û—Ç–ª–æ–∂–µ–Ω–Ω—ã–π decay –¥–ª—è —Å—Ç–∞–±–∏–ª–∏–∑–∞—Ü–∏–∏
        self.decay_steps = 40000        # –£–≤–µ–ª–∏—á–µ–Ω–Ω–∞—è –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å decay
        
        # üõ°Ô∏è –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è —ç–∫—Å—Ç—Ä–µ–Ω–Ω–æ–≥–æ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è –¥–∏–∞–≥–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏
        self.emergency_weight = 25.0    # –≠–∫—Å—Ç—Ä–µ–Ω–Ω—ã–π –≤–µ—Å –ø—Ä–∏ –Ω–∏–∑–∫–æ–π –¥–∏–∞–≥–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏
        
    def forward(self, model_output):
        """
        –í—ã—á–∏—Å–ª—è–µ—Ç guided attention loss –¥–ª—è –º–æ–¥–µ–ª–∏.
        
        Args:
            model_output: –í—ã—Ö–æ–¥ –º–æ–¥–µ–ª–∏ [mel_out, mel_out_postnet, gate_out, alignments]
            
        Returns:
            torch.Tensor: Guided attention loss
        """
        if len(model_output) < 4:
            # –ù–µ—Ç alignments, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º 0
            return torch.tensor(0.0, requires_grad=True)
            
        # üî• –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –ü—Ä–∞–≤–∏–ª—å–Ω–æ —Ä–∞—Å–ø–∞–∫–æ–≤—ã–≤–∞–µ–º —ç–ª–µ–º–µ–Ω—Ç—ã –º–æ–¥–µ–ª–∏ –≤ GuidedAttentionLoss
        if len(model_output) == 7:
            # –ü–æ–ª–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç: [decoder_outputs, mel_out, mel_out_postnet, gate_out, alignments, tpse_gst_outputs, gst_outputs]
            decoder_outputs, mel_out, mel_out_postnet, gate_out, alignments, tpse_gst_outputs, gst_outputs = model_output
        elif len(model_output) == 6:
            # –§–æ—Ä–º–∞—Ç –±–µ–∑ decoder_outputs: [mel_out, mel_out_postnet, gate_out, alignments, tpse_gst_outputs, gst_outputs]  
            mel_out, mel_out_postnet, gate_out, alignments, tpse_gst_outputs, gst_outputs = model_output
        elif len(model_output) == 5:
            # –§–æ—Ä–º–∞—Ç —Å alignments: [mel_out, mel_out_postnet, gate_out, alignments, extra]
            mel_out, mel_out_postnet, gate_out, alignments, _ = model_output
        elif len(model_output) == 4:
            # –°—Ç–∞—Ä—ã–π —Ñ–æ—Ä–º–∞—Ç: [mel_out, mel_out_postnet, gate_out, alignments]
            mel_out, mel_out_postnet, gate_out, alignments = model_output
        else:
            # Fallback: –±–µ—Ä–µ–º –ø–µ—Ä–≤—ã–µ 4 —ç–ª–µ–º–µ–Ω—Ç–∞
            mel_out, mel_out_postnet, gate_out, alignments = model_output[:4]
            
        if alignments is None:
            return torch.tensor(0.0, requires_grad=True)
            
        # –í—ã—á–∏—Å–ª—è–µ–º guided attention loss
        batch_size, mel_len, text_len = alignments.shape
        
        # –°–æ–∑–¥–∞–µ–º –¥–∏–∞–≥–æ–Ω–∞–ª—å–Ω—É—é –º–∞—Ç—Ä–∏—Ü—É —Ü–µ–ª–µ–≤–æ–≥–æ alignment
        device = alignments.device
        
        # –ò–Ω–¥–µ–∫—Å—ã –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –¥–∏–∞–≥–æ–Ω–∞–ª—å–Ω–æ–≥–æ alignment
        mel_indices = torch.arange(mel_len, device=device).float()
        text_indices = torch.arange(text_len, device=device).float()
        
        # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –∏–Ω–¥–µ–∫—Å—ã
        mel_indices_norm = mel_indices / (mel_len - 1) if mel_len > 1 else mel_indices
        text_indices_norm = text_indices / (text_len - 1) if text_len > 1 else text_indices
        
        # –°–æ–∑–¥–∞–µ–º meshgrid –¥–ª—è –≤—ã—á–∏—Å–ª–µ–Ω–∏—è —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–π
        mel_grid = mel_indices_norm.unsqueeze(1).expand(mel_len, text_len)
        text_grid = text_indices_norm.unsqueeze(0).expand(mel_len, text_len)
        
        # –î–∏–∞–≥–æ–Ω–∞–ª—å–Ω–∞—è –º–∞—Ç—Ä–∏—Ü–∞ (–∏–¥–µ–∞–ª—å–Ω—ã–π alignment)
        distances = (mel_grid - text_grid) ** 2
        
        # Gaussian guided attention —Å –∞–¥–∞–ø—Ç–∏–≤–Ω–æ–π sigma
        current_sigma = self._get_adaptive_sigma()
        guided_attention = torch.exp(-distances / (2 * current_sigma ** 2))
        
        # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º guided attention
        guided_attention = guided_attention / guided_attention.sum(dim=1, keepdim=True).clamp(min=1e-6)
        
        # –ü—Ä–∏–º–µ–Ω—è–µ–º –∫ –∫–∞–∂–¥–æ–º—É —ç–ª–µ–º–µ–Ω—Ç—É batch
        loss = 0.0
        for i in range(batch_size):
            # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º attention –≤–µ—Å–∞
            att_norm = alignments[i] / alignments[i].sum(dim=1, keepdim=True).clamp(min=1e-6)
            
            # KL divergence loss –º–µ–∂–¥—É predicted –∏ guided attention
            kl_loss = F.kl_div(
                torch.log(att_norm + 1e-6),
                guided_attention,
                reduction='none'
            )
            
            # –ú–∞—Å–∫–∏—Ä—É–µ–º –≤–∞–ª–∏–¥–Ω—ã–µ —ç–ª–µ–º–µ–Ω—Ç—ã
            mask = (alignments[i].sum(dim=1) > 0).float().unsqueeze(1)
            kl_loss_masked = kl_loss * mask
            
            loss += kl_loss_masked.sum()
        
        # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –ø–æ batch size –∏ sequence length
        loss = loss / (batch_size * mel_len)
        
        # –ü—Ä–∏–º–µ–Ω—è–µ–º –∞–¥–∞–ø—Ç–∏–≤–Ω—ã–π –≤–µ—Å
        weighted_loss = self.get_weight() * loss
        
        # –û–±–Ω–æ–≤–ª—è–µ–º –≥–ª–æ–±–∞–ª—å–Ω—ã–π —Å—á–µ—Ç—á–∏–∫
        self.global_step += 1
        self._update_weight()
        
        return weighted_loss
    
    def get_weight(self):
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ç–µ–∫—É—â–∏–π –≤–µ—Å guided attention loss."""
        # üö® –í –∫—Ä–∏—Ç–∏—á–µ—Å–∫–æ–º —Ä–µ–∂–∏–º–µ –∏—Å–ø–æ–ª—å–∑—É–µ–º —ç–∫—Å—Ç—Ä–µ–Ω–Ω—ã–π –≤–µ—Å
        if self.critical_mode:
            return self.emergency_weight
        return self.current_weight

    def activate_critical_mode(self):
        """
        üö® –ê–∫—Ç–∏–≤–∏—Ä—É–µ—Ç –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏–π —Ä–µ–∂–∏–º –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è –¥–∏–∞–≥–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏.
        –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –ø—Ä–∏ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏–∏ NaN –∏–ª–∏ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏ –Ω–∏–∑–∫–æ–π –¥–∏–∞–≥–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏.
        """
        self.critical_mode = True
        self.current_weight = self.emergency_weight
        print(f"üõ°Ô∏è GuidedAttentionLoss: –ö–†–ò–¢–ò–ß–ï–°–ö–ò–ô –†–ï–ñ–ò–ú –∞–∫—Ç–∏–≤–∏—Ä–æ–≤–∞–Ω! –í–µ—Å: {self.emergency_weight}")

    def deactivate_critical_mode(self):
        """–î–µ–∞–∫—Ç–∏–≤–∏—Ä—É–µ—Ç –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏–π —Ä–µ–∂–∏–º."""
        self.critical_mode = False
        print(f"‚úÖ GuidedAttentionLoss: –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏–π —Ä–µ–∂–∏–º –¥–µ–∞–∫—Ç–∏–≤–∏—Ä–æ–≤–∞–Ω")

    def check_diagonality_and_adapt(self, alignments):
        """
        –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –¥–∏–∞–≥–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å attention –∏ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –∞–¥–∞–ø—Ç–∏—Ä—É–µ—Ç —Ä–µ–∂–∏–º.
        
        Args:
            alignments: Attention –≤–µ—Å–∞ [batch, mel_len, text_len]
        """
        if alignments is None or alignments.numel() == 0:
            return
        
        # –ë—ã—Å—Ç—Ä–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –¥–∏–∞–≥–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏ –¥–ª—è –ø–µ—Ä–≤–æ–≥–æ —ç–ª–µ–º–µ–Ω—Ç–∞ –±–∞—Ç—á–∞
        attention = alignments[0].detach().cpu().numpy()
        batch_size, mel_len, text_len = attention.shape if len(attention.shape) == 3 else (1, *attention.shape)
        
        if len(attention.shape) == 2:
            attention = attention.reshape(1, *attention.shape)
            
        diagonality = self._calculate_quick_diagonality(attention[0] if len(attention.shape) == 3 else attention)
        
        # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –∞–∫—Ç–∏–≤–∞—Ü–∏—è –∫—Ä–∏—Ç–∏—á–µ—Å–∫–æ–≥–æ —Ä–µ–∂–∏–º–∞ –ø—Ä–∏ –Ω–∏–∑–∫–æ–π –¥–∏–∞–≥–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏
        if diagonality < 0.2 and not self.critical_mode:
            self.activate_critical_mode()
        elif diagonality > 0.5 and self.critical_mode:
            self.deactivate_critical_mode()

    def _calculate_quick_diagonality(self, attention_matrix):
        """–ë—ã—Å—Ç—Ä–æ–µ –≤—ã—á–∏—Å–ª–µ–Ω–∏–µ –¥–∏–∞–≥–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏."""
        try:
            if attention_matrix.size == 0:
                return 0.0
            
            mel_len, text_len = attention_matrix.shape
            
            # –°–æ–∑–¥–∞–µ–º –∏–¥–µ–∞–ª—å–Ω—É—é –¥–∏–∞–≥–æ–Ω–∞–ª—å
            diagonal_sum = 0.0
            total_sum = attention_matrix.sum()
            
            if total_sum == 0:
                return 0.0
            
            # –°—É–º–º–∏—Ä—É–µ–º –≤–µ—Å–∞ –ø–æ –¥–∏–∞–≥–æ–Ω–∞–ª–∏
            for i in range(mel_len):
                diagonal_pos = int(i * text_len / mel_len)
                if diagonal_pos < text_len:
                    diagonal_sum += attention_matrix[i, diagonal_pos]
            
            # –î–∏–∞–≥–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å = –¥–æ–ª—è –≤–µ—Å–æ–≤ –Ω–∞ –¥–∏–∞–≥–æ–Ω–∞–ª–∏
            return diagonal_sum / total_sum if total_sum > 0 else 0.0
            
        except Exception:
            return 0.0
    
    def _update_weight(self):
        """–û–±–Ω–æ–≤–ª—è–µ—Ç –≤–µ—Å guided attention –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ä–∞—Å–ø–∏—Å–∞–Ω–∏—è."""
        if self.global_step < self.decay_start:
            # –§–∞–∑–∞ –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–≥–æ guided attention
            return
        elif self.global_step < self.decay_start + self.decay_steps:
            # –§–∞–∑–∞ –ø–æ—Å—Ç–µ–ø–µ–Ω–Ω–æ–≥–æ —Å–Ω–∏–∂–µ–Ω–∏—è
            progress = (self.global_step - self.decay_start) / self.decay_steps
            # –≠–∫—Å–ø–æ–Ω–µ–Ω—Ü–∏–∞–ª—å–Ω—ã–π decay
            decay_factor = math.exp(-progress * 3)
            self.current_weight = self.min_weight + (self.alpha - self.min_weight) * decay_factor
            self.current_weight = max(self.min_weight, self.current_weight)
        else:
            # –§–∞–∑–∞ –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–≥–æ guided attention
            self.current_weight = self.min_weight
    
    def _get_adaptive_sigma(self):
        """–í—ã—á–∏—Å–ª—è–µ—Ç –∞–¥–∞–ø—Ç–∏–≤–Ω—É—é sigma –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ñ–∞–∑—ã –æ–±—É—á–µ–Ω–∏—è."""
        if self.global_step < 1000:
            # –ù–∞—á–∞–ª—å–Ω–∞—è —Ñ–∞–∑–∞: —É–∑–∫–∞—è sigma –¥–ª—è —Ç–æ—á–Ω–æ–≥–æ alignment
            return 0.1
        elif self.global_step < 5000:
            # –†–∞—Å—à–∏—Ä—è—é—â–∞—è —Ñ–∞–∑–∞: —É–≤–µ–ª–∏—á–∏–≤–∞–µ–º sigma –¥–ª—è –≥–∏–±–∫–æ—Å—Ç–∏
            progress = (self.global_step - 1000) / 4000
            return 0.1 + 0.3 * progress  # –û—Ç 0.1 –¥–æ 0.4
        else:
            # –°—Ç–∞–±–∏–ª–∏–∑–∏—Ä—É—é—â–∞—è —Ñ–∞–∑–∞: —Å—Ä–µ–¥–Ω—è—è sigma –¥–ª—è –±–∞–ª–∞–Ω—Å–∞
            progress = min(1.0, (self.global_step - 5000) / 15000)
            return 0.4 - 0.25 * progress  # –û—Ç 0.4 –¥–æ 0.15
