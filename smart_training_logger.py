#!/usr/bin/env python3
"""
üß† SMART TRAINING LOGGER - –ò–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è TTS
–ü–æ–ª–Ω–æ—Ü–µ–Ω–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è –¥–ª—è Smart Tuner —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π MLflow, TensorBoard –∏ —Ñ–∞–π–ª–æ–≤.
"""

import os
import json
import logging
import time
from typing import Dict, Any, Optional, List
from datetime import datetime
from pathlib import Path
from dataclasses import dataclass

try:
    import mlflow
    import mlflow.pytorch
    MLFLOW_AVAILABLE = True
except ImportError:
    MLFLOW_AVAILABLE = False

try:
    from torch.utils.tensorboard import SummaryWriter
    TENSORBOARD_AVAILABLE = True
except ImportError:
    TENSORBOARD_AVAILABLE = False


@dataclass
class TrainingMetrics:
    """–°—Ç—Ä—É–∫—Ç—É—Ä–∞ –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è –º–µ—Ç—Ä–∏–∫ –æ–±—É—á–µ–Ω–∏—è"""
    step: int
    epoch: int
    total_loss: float
    mel_loss: float = 0.0
    gate_loss: float = 0.0
    guide_loss: float = 0.0
    learning_rate: float = 0.0
    timestamp: str = ""
    
    def __post_init__(self):
        if not self.timestamp:
            self.timestamp = datetime.now().isoformat()


class SmartTrainingLogger:
    """
    üß† –ò–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è –¥–ª—è TTS –æ–±—É—á–µ–Ω–∏—è
    """
    
    def __init__(self, 
                 log_dir: str = "logs",
                 experiment_name: str = "TTS_Training",
                 enable_mlflow: bool = True,
                 enable_tensorboard: bool = True,
                 enable_file_logging: bool = True):
        
        self.log_dir = Path(log_dir)
        self.log_dir.mkdir(exist_ok=True)
        self.experiment_name = experiment_name
        self.enable_mlflow = enable_mlflow and MLFLOW_AVAILABLE
        self.enable_tensorboard = enable_tensorboard and TENSORBOARD_AVAILABLE
        self.enable_file_logging = enable_file_logging
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤
        self.logger = self._setup_file_logger()
        self.tensorboard_writer = self._setup_tensorboard() if self.enable_tensorboard else None
        self.mlflow_run = self._setup_mlflow() if self.enable_mlflow else None
        
        # –•—Ä–∞–Ω–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫
        self.metrics_history: List[TrainingMetrics] = []
        self.best_loss = float('inf')
        self.start_time = time.time()
        
        self.logger.info(f"üß† SmartTrainingLogger –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
        self.logger.info(f"üìä MLflow: {'‚úÖ' if self.enable_mlflow else '‚ùå'}")
        self.logger.info(f"üìà TensorBoard: {'‚úÖ' if self.enable_tensorboard else '‚ùå'}")
        self.logger.info(f"üìù File logging: {'‚úÖ' if self.enable_file_logging else '‚ùå'}")
    
    def _setup_file_logger(self) -> logging.Logger:
        """–ù–∞—Å—Ç—Ä–æ–π–∫–∞ —Ñ–∞–π–ª–æ–≤–æ–≥–æ –ª–æ–≥–≥–µ—Ä–∞"""
        logger = logging.getLogger('SmartTrainingLogger')
        logger.setLevel(logging.INFO)
        
        # –£–¥–∞–ª—è–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ handlers
        for handler in logger.handlers[:]:
            logger.removeHandler(handler)
        
        # –§–∞–π–ª–æ–≤—ã–π handler
        if self.enable_file_logging:
            log_file = self.log_dir / f"training_{datetime.now().strftime('%Y%m%d_%H%M%S')}.log"
            file_handler = logging.FileHandler(log_file, encoding='utf-8')
            file_formatter = logging.Formatter(
                '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
            )
            file_handler.setFormatter(file_formatter)
            logger.addHandler(file_handler)
        
        # –ö–æ–Ω—Å–æ–ª—å–Ω—ã–π handler
        console_handler = logging.StreamHandler()
        console_formatter = logging.Formatter(
            '%(asctime)s - %(levelname)s - %(message)s'
        )
        console_handler.setFormatter(console_formatter)
        logger.addHandler(console_handler)
        
        return logger
    
    def _setup_tensorboard(self) -> Optional[SummaryWriter]:
        """–ù–∞—Å—Ç—Ä–æ–π–∫–∞ TensorBoard"""
        if not TENSORBOARD_AVAILABLE:
            return None
            
        try:
            tb_dir = self.log_dir / "tensorboard" / f"{self.experiment_name}_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
            writer = SummaryWriter(str(tb_dir))
            self.logger.info(f"üìà TensorBoard –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω: {tb_dir}")
            return writer
        except Exception as e:
            self.logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ TensorBoard: {e}")
            return None
    
    def _setup_mlflow(self) -> Optional[str]:
        """–ù–∞—Å—Ç—Ä–æ–π–∫–∞ MLflow"""
        if not MLFLOW_AVAILABLE:
            return None
            
        try:
            # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ tracking URI
            mlflow_dir = self.log_dir / "mlflow"
            mlflow_dir.mkdir(exist_ok=True)
            mlflow.set_tracking_uri(f"file://{mlflow_dir.absolute()}")
            
            # –°–æ–∑–¥–∞–Ω–∏–µ/–ø–æ–ª—É—á–µ–Ω–∏–µ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞
            mlflow.set_experiment(self.experiment_name)
            
            # –ó–∞–ø—É—Å–∫ run
            run = mlflow.start_run()
            run_id = run.info.run_id
            self.logger.info(f"üìä MLflow –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω: Run ID {run_id}")
            return run_id
        except Exception as e:
            self.logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ MLflow: {e}")
            return None
    
    def log_training_step(self, metrics: TrainingMetrics) -> None:
        """
        –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –æ–¥–Ω–æ–≥–æ —à–∞–≥–∞ –æ–±—É—á–µ–Ω–∏—è
        
        Args:
            metrics: –ú–µ—Ç—Ä–∏–∫–∏ –¥–ª—è –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
        """
        try:
            # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ –∏—Å—Ç–æ—Ä–∏—é
            self.metrics_history.append(metrics)
            
            # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –ª—É—á—à–µ–≥–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
            if metrics.total_loss < self.best_loss:
                self.best_loss = metrics.total_loss
                self.logger.info(f"üéØ –ù–æ–≤—ã–π –ª—É—á—à–∏–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç! Loss: {self.best_loss:.6f}")
            
            # –§–∞–π–ª–æ–≤–æ–µ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ
            if self.enable_file_logging:
                self._log_to_file(metrics)
            
            # TensorBoard –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ
            if self.tensorboard_writer:
                self._log_to_tensorboard(metrics)
            
            # MLflow –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ
            if self.mlflow_run:
                self._log_to_mlflow(metrics)
            
            # –ü—Ä–æ–≥—Ä–µ—Å—Å –æ–±—É—á–µ–Ω–∏—è
            self._log_progress(metrics)
            
        except Exception as e:
            self.logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è —à–∞–≥–∞: {e}")
    
    def _log_to_file(self, metrics: TrainingMetrics) -> None:
        """–õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –≤ —Ñ–∞–π–ª"""
        elapsed_time = time.time() - self.start_time
        self.logger.info(
            f"Step {metrics.step} | Epoch {metrics.epoch} | "
            f"Loss: {metrics.total_loss:.6f} | "
            f"Mel: {metrics.mel_loss:.6f} | "
            f"Gate: {metrics.gate_loss:.6f} | "
            f"Guide: {metrics.guide_loss:.6f} | "
            f"LR: {metrics.learning_rate:.2e} | "
            f"Time: {elapsed_time:.1f}s"
        )
    
    def _log_to_tensorboard(self, metrics: TrainingMetrics) -> None:
        """–õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –≤ TensorBoard"""
        try:
            self.tensorboard_writer.add_scalar('Loss/Total', metrics.total_loss, metrics.step)
            self.tensorboard_writer.add_scalar('Loss/Mel', metrics.mel_loss, metrics.step)
            self.tensorboard_writer.add_scalar('Loss/Gate', metrics.gate_loss, metrics.step)
            self.tensorboard_writer.add_scalar('Loss/Guide', metrics.guide_loss, metrics.step)
            self.tensorboard_writer.add_scalar('Learning_Rate', metrics.learning_rate, metrics.step)
            
            # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏
            elapsed_time = time.time() - self.start_time
            self.tensorboard_writer.add_scalar('Training/Elapsed_Time', elapsed_time, metrics.step)
            self.tensorboard_writer.add_scalar('Training/Best_Loss', self.best_loss, metrics.step)
            
            # Flush –¥–ª—è –Ω–µ–º–µ–¥–ª–µ–Ω–Ω–æ–π –∑–∞–ø–∏—Å–∏
            self.tensorboard_writer.flush()
            
        except Exception as e:
            self.logger.error(f"‚ùå –û—à–∏–±–∫–∞ TensorBoard –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è: {e}")
    
    def _log_to_mlflow(self, metrics: TrainingMetrics) -> None:
        """–õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –≤ MLflow"""
        try:
            mlflow.log_metric('total_loss', metrics.total_loss, step=metrics.step)
            mlflow.log_metric('mel_loss', metrics.mel_loss, step=metrics.step)
            mlflow.log_metric('gate_loss', metrics.gate_loss, step=metrics.step)
            mlflow.log_metric('guide_loss', metrics.guide_loss, step=metrics.step)
            mlflow.log_metric('learning_rate', metrics.learning_rate, step=metrics.step)
            mlflow.log_metric('best_loss', self.best_loss, step=metrics.step)
            
        except Exception as e:
            self.logger.error(f"‚ùå –û—à–∏–±–∫–∞ MLflow –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è: {e}")
    
    def _log_progress(self, metrics: TrainingMetrics) -> None:
        """–õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –ø—Ä–æ–≥—Ä–µ—Å—Å–∞ –æ–±—É—á–µ–Ω–∏—è"""
        # –ö–∞–∂–¥—ã–µ 100 —à–∞–≥–æ–≤ –≤—ã–≤–æ–¥–∏–º –¥–µ—Ç–∞–ª—å–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é
        if metrics.step % 100 == 0:
            elapsed_time = time.time() - self.start_time
            avg_loss = sum(m.total_loss for m in self.metrics_history[-100:]) / min(100, len(self.metrics_history))
            
            self.logger.info(f"üìä –ü—Ä–æ–≥—Ä–µ—Å—Å –æ–±—É—á–µ–Ω–∏—è:")
            self.logger.info(f"   –®–∞–≥: {metrics.step}")
            self.logger.info(f"   –≠–ø–æ—Ö–∞: {metrics.epoch}")
            self.logger.info(f"   –¢–µ–∫—É—â–∏–π Loss: {metrics.total_loss:.6f}")
            self.logger.info(f"   –°—Ä–µ–¥–Ω–∏–π Loss (100 —à–∞–≥–æ–≤): {avg_loss:.6f}")
            self.logger.info(f"   –õ—É—á—à–∏–π Loss: {self.best_loss:.6f}")
            self.logger.info(f"   –í—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è: {elapsed_time:.1f}s")
    
    def log_epoch_summary(self, epoch: int, avg_loss: float, epoch_time: float) -> None:
        """–õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –∏—Ç–æ–≥–æ–≤ —ç–ø–æ—Ö–∏"""
        self.logger.info(f"üéâ –≠–ø–æ—Ö–∞ {epoch} –∑–∞–≤–µ—Ä—à–µ–Ω–∞:")
        self.logger.info(f"   –°—Ä–µ–¥–Ω–∏–π Loss: {avg_loss:.6f}")
        self.logger.info(f"   –í—Ä–µ–º—è —ç–ø–æ—Ö–∏: {epoch_time:.1f}s")
        self.logger.info(f"   –õ—É—á—à–∏–π Loss –∑–∞ –≤—Å–µ –≤—Ä–µ–º—è: {self.best_loss:.6f}")
        
        # –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –≤ —Å–∏—Å—Ç–µ–º—ã
        if self.tensorboard_writer:
            self.tensorboard_writer.add_scalar('Epoch/Average_Loss', avg_loss, epoch)
            self.tensorboard_writer.add_scalar('Epoch/Time', epoch_time, epoch)
        
        if self.mlflow_run:
            mlflow.log_metric('epoch_avg_loss', avg_loss, step=epoch)
            mlflow.log_metric('epoch_time', epoch_time, step=epoch)
    
    def log_hyperparameters(self, hparams: Dict[str, Any]) -> None:
        """–õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤"""
        self.logger.info("‚öôÔ∏è –ì–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä—ã –æ–±—É—á–µ–Ω–∏—è:")
        for key, value in hparams.items():
            self.logger.info(f"   {key}: {value}")
        
        # MLflow –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
        if self.mlflow_run:
            for key, value in hparams.items():
                if isinstance(value, (int, float, str, bool)):
                    mlflow.log_param(key, value)
        
        # TensorBoard –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ (–∫–∞–∫ —Ç–µ–∫—Å—Ç)
        if self.tensorboard_writer:
            hparams_text = '\n'.join([f"{k}: {v}" for k, v in hparams.items()])
            self.tensorboard_writer.add_text('Hyperparameters', hparams_text, 0)
    
    def save_metrics_history(self, filepath: Optional[str] = None) -> str:
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∏—Å—Ç–æ—Ä–∏–∏ –º–µ—Ç—Ä–∏–∫ –≤ JSON —Ñ–∞–π–ª"""
        if filepath is None:
            filepath = self.log_dir / f"metrics_history_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        
        try:
            metrics_data = []
            for m in self.metrics_history:
                metrics_data.append({
                    'step': m.step,
                    'epoch': m.epoch,
                    'total_loss': m.total_loss,
                    'mel_loss': m.mel_loss,
                    'gate_loss': m.gate_loss,
                    'guide_loss': m.guide_loss,
                    'learning_rate': m.learning_rate,
                    'timestamp': m.timestamp
                })
            
            with open(filepath, 'w', encoding='utf-8') as f:
                json.dump(metrics_data, f, indent=2, ensure_ascii=False)
            
            self.logger.info(f"üìä –ò—Å—Ç–æ—Ä–∏—è –º–µ—Ç—Ä–∏–∫ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: {filepath}")
            return str(filepath)
            
        except Exception as e:
            self.logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –∏—Å—Ç–æ—Ä–∏–∏ –º–µ—Ç—Ä–∏–∫: {e}")
            return ""
    
    def close(self) -> None:
        """–ó–∞–∫—Ä—ã—Ç–∏–µ –≤—Å–µ—Ö –ª–æ–≥–≥–µ—Ä–æ–≤"""
        try:
            # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ñ–∏–Ω–∞–ª—å–Ω—ã—Ö –º–µ—Ç—Ä–∏–∫
            self.save_metrics_history()
            
            # –ó–∞–∫—Ä—ã—Ç–∏–µ TensorBoard
            if self.tensorboard_writer:
                self.tensorboard_writer.close()
                self.logger.info("üìà TensorBoard –∑–∞–∫—Ä—ã—Ç")
            
            # –ó–∞–∫—Ä—ã—Ç–∏–µ MLflow
            if self.mlflow_run:
                mlflow.end_run()
                self.logger.info("üìä MLflow run –∑–∞–≤–µ—Ä—à–µ–Ω")
            
            self.logger.info("üèÅ SmartTrainingLogger –∑–∞–≤–µ—Ä—à–∏–ª —Ä–∞–±–æ—Ç—É")
            
        except Exception as e:
            self.logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–∫—Ä—ã—Ç–∏—è –ª–æ–≥–≥–µ—Ä–∞: {e}")
    
    def get_training_summary(self) -> Dict[str, Any]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –∏—Ç–æ–≥–æ–≤–æ–π —Å–≤–æ–¥–∫–∏ –æ–±—É—á–µ–Ω–∏—è"""
        if not self.metrics_history:
            return {}
        
        total_time = time.time() - self.start_time
        total_steps = len(self.metrics_history)
        
        return {
            'total_steps': total_steps,
            'total_time_seconds': total_time,
            'best_loss': self.best_loss,
            'final_loss': self.metrics_history[-1].total_loss if self.metrics_history else 0,
            'average_loss': sum(m.total_loss for m in self.metrics_history) / total_steps,
            'total_epochs': self.metrics_history[-1].epoch if self.metrics_history else 0,
            'steps_per_second': total_steps / total_time if total_time > 0 else 0
        }


def create_smart_logger(log_dir: str = "logs", 
                       experiment_name: str = "TTS_Training",
                       **kwargs) -> SmartTrainingLogger:
    """
    –§–∞–±—Ä–∏—á–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è —É–º–Ω–æ–≥–æ –ª–æ–≥–≥–µ—Ä–∞
    """
    return SmartTrainingLogger(
        log_dir=log_dir,
        experiment_name=experiment_name,
        **kwargs
    )


def get_training_logger(log_dir: str = "logs", 
                       experiment_name: str = "TTS_Training",
                       **kwargs) -> SmartTrainingLogger:
    """
    ü§ñ –ù–ï–î–û–°–¢–ê–Æ–©–ê–Ø –§–£–ù–ö–¶–ò–Ø: –ü–æ–ª—É—á–µ–Ω–∏–µ –ª–æ–≥–≥–µ—Ä–∞ –¥–ª—è —Ç—Ä–µ–Ω–∏—Ä–æ–≤–∫–∏
    
    –≠—Ç–∞ —Ñ—É–Ω–∫—Ü–∏—è –Ω—É–∂–Ω–∞ –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ —Å–æ Smart Tuner —Å–∏—Å—Ç–µ–º–æ–π.
    –Ø–≤–ª—è–µ—Ç—Å—è –∞–ª–∏–∞—Å–æ–º –¥–ª—è create_smart_logger.
    """
    return create_smart_logger(log_dir, experiment_name, **kwargs)


def log_training_start(experiment_name: str = "TTS_Training", 
                      hparams: Dict[str, Any] = None, 
                      **kwargs) -> None:
    """
    ü§ñ –ù–ï–î–û–°–¢–ê–Æ–©–ê–Ø –§–£–ù–ö–¶–ò–Ø: –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –Ω–∞—á–∞–ª–∞ –æ–±—É—á–µ–Ω–∏—è
    
    –≠—Ç–∞ —Ñ—É–Ω–∫—Ü–∏—è –Ω—É–∂–Ω–∞ –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ —Å–æ Smart Tuner —Å–∏—Å—Ç–µ–º–æ–π.
    """
    try:
        logger = get_training_logger(experiment_name=experiment_name)
        
        if hparams:
            logger.log_hyperparameters(hparams)
            
        # –õ–æ–≥–∏—Ä—É–µ–º –Ω–∞—á–∞–ª–æ –æ–±—É—á–µ–Ω–∏—è
        import logging
        logging.info(f"üöÄ –ù–∞—á–∞—Ç–æ –æ–±—É—á–µ–Ω–∏–µ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞: {experiment_name}")
        
        if hparams:
            logging.info(f"üìä –ì–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä—ã: {hparams}")
            
    except Exception as e:
        import logging
        logging.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è –Ω–∞—á–∞–ª–∞ –æ–±—É—á–µ–Ω–∏—è: {e}")


def log_training_metrics(metrics: Dict[str, Any], step: int = None, **kwargs) -> None:
    """
    ü§ñ –ù–ï–î–û–°–¢–ê–Æ–©–ê–Ø –§–£–ù–ö–¶–ò–Ø: –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –º–µ—Ç—Ä–∏–∫ –æ–±—É—á–µ–Ω–∏—è
    
    –≠—Ç–∞ —Ñ—É–Ω–∫—Ü–∏—è –Ω—É–∂–Ω–∞ –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ —Å–æ Smart Tuner —Å–∏—Å—Ç–µ–º–æ–π.
    """
    try:
        # –õ–æ–≥–∏—Ä—É–µ–º —á–µ—Ä–µ–∑ –æ–±—ã—á–Ω—ã–π logging
        import logging
        
        if step is not None:
            logging.info(f"üìä –ú–µ—Ç—Ä–∏–∫–∏ (—à–∞–≥ {step}): {metrics}")
        else:
            logging.info(f"üìä –ú–µ—Ç—Ä–∏–∫–∏: {metrics}")
        
        # –ü—ã—Ç–∞–µ–º—Å—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å MLflow –µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–µ–Ω
        try:
            import mlflow
            for metric_name, metric_value in metrics.items():
                if isinstance(metric_value, (int, float)):
                    mlflow.log_metric(metric_name, metric_value, step=step)
                    
        except ImportError:
            pass  # MLflow –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω
        except Exception as e:
            logging.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ MLflow –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è: {e}")
            
    except Exception as e:
        import logging
        logging.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è –º–µ—Ç—Ä–∏–∫: {e}")


def log_param_change(param_name: str, old_value: Any, new_value: Any, reason: str = "", **kwargs) -> None:
    """
    ü§ñ –ù–ï–î–û–°–¢–ê–Æ–©–ê–Ø –§–£–ù–ö–¶–ò–Ø: –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –∏–∑–º–µ–Ω–µ–Ω–∏–π –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
    
    –≠—Ç–∞ —Ñ—É–Ω–∫—Ü–∏—è –Ω—É–∂–Ω–∞ –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ —Å–æ Smart Tuner —Å–∏—Å—Ç–µ–º–æ–π.
    """
    try:
        import logging
        
        # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ –æ–± –∏–∑–º–µ–Ω–µ–Ω–∏–∏
        if reason:
            message = f"üîß –ü–∞—Ä–∞–º–µ—Ç—Ä –∏–∑–º–µ–Ω–µ–Ω: {param_name} = {old_value} ‚Üí {new_value} (–ø—Ä–∏—á–∏–Ω–∞: {reason})"
        else:
            message = f"üîß –ü–∞—Ä–∞–º–µ—Ç—Ä –∏–∑–º–µ–Ω–µ–Ω: {param_name} = {old_value} ‚Üí {new_value}"
            
        logging.info(message)
        
        # –ü—ã—Ç–∞–µ–º—Å—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å MLflow –µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–µ–Ω
        try:
            import mlflow
            # –õ–æ–≥–∏—Ä—É–µ–º –∫–∞–∫ –ø–∞—Ä–∞–º–µ—Ç—Ä
            mlflow.log_param(f"{param_name}_change", f"{old_value}_to_{new_value}")
            
        except ImportError:
            pass  # MLflow –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω
        except Exception as e:
            logging.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ MLflow –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è –∏–∑–º–µ–Ω–µ–Ω–∏—è –ø–∞—Ä–∞–º–µ—Ç—Ä–∞: {e}")
            
    except Exception as e:
        import logging
        logging.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è –∏–∑–º–µ–Ω–µ–Ω–∏—è –ø–∞—Ä–∞–º–µ—Ç—Ä–∞: {e}")


def log_training_warning(message: str, **kwargs) -> None:
    """
    ü§ñ –ù–ï–î–û–°–¢–ê–Æ–©–ê–Ø –§–£–ù–ö–¶–ò–Ø: –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–π –æ–±—É—á–µ–Ω–∏—è
    
    –≠—Ç–∞ —Ñ—É–Ω–∫—Ü–∏—è –Ω—É–∂–Ω–∞ –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ —Å–æ Smart Tuner —Å–∏—Å—Ç–µ–º–æ–π.
    """
    try:
        import logging
        logging.warning(f"‚ö†Ô∏è {message}")
        
    except Exception as e:
        import logging
        logging.error(f"‚ùå –û—à–∏–±–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è: {e}")


if __name__ == "__main__":
    # –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Å–∏—Å—Ç–µ–º—ã –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
    logger = create_smart_logger(experiment_name="Test_TTS")
    
    # –¢–µ—Å—Ç–æ–≤—ã–µ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä—ã
    test_hparams = {
        'batch_size': 12,
        'learning_rate': 1e-5,
        'epochs': 1000
    }
    logger.log_hyperparameters(test_hparams)
    
    # –¢–µ—Å—Ç–æ–≤—ã–µ –º–µ—Ç—Ä–∏–∫–∏
    for step in range(5):
        metrics = TrainingMetrics(
            step=step,
            epoch=0,
            total_loss=1.0 - step * 0.1,
            mel_loss=0.5 - step * 0.05,
            gate_loss=0.3 - step * 0.03,
            guide_loss=0.2 - step * 0.02,
            learning_rate=1e-5
        )
        logger.log_training_step(metrics)
    
    # –ò—Ç–æ–≥–∏ —ç–ø–æ—Ö–∏
    logger.log_epoch_summary(0, 0.7, 120.0)
    
    # –°–≤–æ–¥–∫–∞ –∏ –∑–∞–∫—Ä—ã—Ç–∏–µ
    summary = logger.get_training_summary()
    print(f"üìä –ò—Ç–æ–≥–æ–≤–∞—è —Å–≤–æ–¥–∫–∞: {summary}")
    
    logger.close()
    print("‚úÖ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ SmartTrainingLogger –∑–∞–≤–µ—Ä—à–µ–Ω–æ!") 