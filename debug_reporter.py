#!/usr/bin/env python3
"""
üîç DEBUG REPORTER - –°–∏—Å—Ç–µ–º–∞ —Å–±–æ—Ä–∞ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–æ–π –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏
–°–æ–±–∏—Ä–∞–µ—Ç –ø–æ–¥—Ä–æ–±–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –¥–ª—è –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏ –ø—Ä–æ–±–ª–µ–º –æ–±—É—á–µ–Ω–∏—è

–ê–≤—Ç–æ—Ä: Smart Assistant
–í–µ—Ä—Å–∏—è: 1.0
"""

import os
import json
import time
import psutil
import torch
import numpy as np
from datetime import datetime
from typing import Dict, List, Any, Optional
from pathlib import Path
import traceback


class DebugReporter:
    """
    üîç –°–∏—Å—Ç–µ–º–∞ —Å–±–æ—Ä–∞ –∏ –æ—Ç–ø—Ä–∞–≤–∫–∏ –ø–æ–¥—Ä–æ–±–Ω–æ–π —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–æ–π –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏
    """
    
    def __init__(self, telegram_monitor=None):
        self.telegram_monitor = telegram_monitor
        self.debug_data = []
        self.start_time = time.time()
        self.last_report_step = 0
        self.report_interval = 250  # —É–º–µ–Ω—å—à–µ–Ω–æ —Å 1000 –¥–ª—è –±–æ–ª–µ–µ —á–∞—Å—Ç–æ–≥–æ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞
        
        # –ò—Å—Ç–æ—Ä–∏—è –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Ç—Ä–µ–Ω–¥–æ–≤
        self.loss_history = []
        self.attention_history = []
        self.gradient_history = []
        self.restart_history = []
        self.warning_history = []
        
        print("üîç Debug Reporter –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
    
    def collect_step_data(self, step: int, metrics: Dict[str, Any], 
                         model=None, y_pred=None, loss_components=None,
                         hparams=None, smart_tuner_decisions=None):
        """
        üìä –°–æ–±–∏—Ä–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –¥–ª—è –æ–¥–Ω–æ–≥–æ —à–∞–≥–∞ –æ–±—É—á–µ–Ω–∏—è
        """
        try:
            step_data = {
                'timestamp': datetime.now().isoformat(),
                'step': step,
                'training_time_hours': (time.time() - self.start_time) / 3600,
                
                # === üî• LOSS –ê–ù–ê–õ–ò–ó ===
                'loss_analysis': self._analyze_loss(loss_components, metrics),
                
                # === üéØ ATTENTION –ê–ù–ê–õ–ò–ó ===
                'attention_analysis': self._analyze_attention(y_pred),
                
                # === üìà –ì–†–ê–î–ò–ï–ù–¢–´ ===
                'gradient_analysis': self._analyze_gradients(model),
                
                # === ‚öôÔ∏è –ì–ò–ü–ï–†–ü–ê–†–ê–ú–ï–¢–†–´ ===
                'hyperparameters': self._collect_hyperparameters(hparams),
                
                # === üñ•Ô∏è –°–ò–°–¢–ï–ú–ù–ê–Ø –ò–ù–§–û–†–ú–ê–¶–ò–Ø ===
                'system_info': self._collect_system_info(),
                
                # === ü§ñ SMART TUNER –†–ï–®–ï–ù–ò–Ø ===
                'smart_tuner_decisions': smart_tuner_decisions or {},
                
                # === ‚ö†Ô∏è –ü–†–û–ë–õ–ï–ú–´ –ò –ü–†–ï–î–£–ü–†–ï–ñ–î–ï–ù–ò–Ø ===
                'issues_detected': self._detect_issues(metrics, loss_components, y_pred),
                
                # === üìä –¢–†–ï–ù–î–´ ===
                'trends': self._analyze_trends(step, metrics)
            }
            
            self.debug_data.append(step_data)
            
            # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º —Ä–∞–∑–º–µ—Ä –∏—Å—Ç–æ—Ä–∏–∏ –¥–ª—è —ç–∫–æ–Ω–æ–º–∏–∏ –ø–∞–º—è—Ç–∏
            if len(self.debug_data) > 5000:
                self.debug_data = self.debug_data[-3000:]  # –û—Å—Ç–∞–≤–ª—è–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ 3000
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ –ø—Ä–æ–±–ª–µ–º—ã –∫–∞–∂–¥—ã–µ 10 —à–∞–≥–æ–≤
            if step % 10 == 0:
                self._check_critical_issues(step, metrics, loss_components)
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω—É–∂–Ω–æ –ª–∏ –æ—Ç–ø—Ä–∞–≤–∏—Ç—å –æ—Ç—á–µ—Ç
            if step - self.last_report_step >= self.report_interval:
                self.send_debug_report(step)
                self.last_report_step = step
                
        except Exception as e:
            print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ —Å–±–æ—Ä–∞ debug –¥–∞–Ω–Ω—ã—Ö: {e}")
    
    def _check_critical_issues(self, step: int, metrics: Dict, loss_components: Dict):
        """
        –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏—Ö –ø—Ä–æ–±–ª–µ–º –∫–∞–∂–¥—ã–µ 10 —à–∞–≥–æ–≤ —Å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–º –ø–µ—Ä–µ–∑–∞–ø—É—Å–∫–æ–º.
        –†–µ–∞–ª–∏–∑—É–µ—Ç —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –∏–∑ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–æ–≥–æ –∑–∞–¥–∞–Ω–∏—è.
        """
        try:
            critical_issues = []
            
            # 1. –ü—Ä–æ–≤–µ—Ä–∫–∞ NaN –≤ loss –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞—Ö
            if loss_components:
                for name, value in loss_components.items():
                    if isinstance(value, (int, float)):
                        if np.isnan(value):
                            critical_issues.append(f"NaN –≤ {name}")
                        elif np.isinf(value):
                            critical_issues.append(f"Inf –≤ {name}")
            
            # 2. –ü—Ä–æ–≤–µ—Ä–∫–∞ NaN –≤ –æ—Å–Ω–æ–≤–Ω—ã—Ö –º–µ—Ç—Ä–∏–∫–∞—Ö
            nan_metrics = []
            for key, value in metrics.items():
                if isinstance(value, (int, float)) and np.isnan(value):
                    nan_metrics.append(key)
            
            if nan_metrics:
                critical_issues.append(f"NaN –≤ –º–µ—Ç—Ä–∏–∫–∞—Ö: {', '.join(nan_metrics)}")
            
            # 3. –ü—Ä–æ–≤–µ—Ä–∫–∞ —ç–∫—Å—Ç—Ä–µ–º–∞–ª—å–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π
            total_loss = metrics.get('loss', 0)
            if isinstance(total_loss, (int, float)):
                if total_loss > 1000:
                    critical_issues.append(f"–≠–∫—Å—Ç—Ä–µ–º–∞–ª—å–Ω–æ –≤—ã—Å–æ–∫–∏–π loss: {total_loss:.2f}")
                elif total_loss < 0:
                    critical_issues.append(f"–û—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã–π loss: {total_loss:.2f}")
            
            # 4. –ü—Ä–æ–≤–µ—Ä–∫–∞ –≥—Ä–∞–¥–∏–µ–Ω—Ç–æ–≤
            grad_norm = metrics.get('grad_norm', 0)
            if isinstance(grad_norm, (int, float)):
                if grad_norm > 1000:
                    critical_issues.append(f"–í–∑—Ä—ã–≤ –≥—Ä–∞–¥–∏–µ–Ω—Ç–æ–≤: {grad_norm:.2f}")
                elif grad_norm < 1e-8:
                    critical_issues.append(f"–ò—Å—á–µ–∑–Ω–æ–≤–µ–Ω–∏–µ –≥—Ä–∞–¥–∏–µ–Ω—Ç–æ–≤: {grad_norm:.2e}")
            
            # 5. –ï—Å–ª–∏ –µ—Å—Ç—å –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ –ø—Ä–æ–±–ª–µ–º—ã, –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ
            if critical_issues:
                self._handle_critical_issues(step, critical_issues)
                
        except Exception as e:
            print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏—Ö –ø—Ä–æ–±–ª–µ–º: {e}")
    
    def _handle_critical_issues(self, step: int, issues: List[str]):
        """
        –û–±—Ä–∞–±–æ—Ç–∫–∞ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏—Ö –ø—Ä–æ–±–ª–µ–º —Å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–º–∏ –¥–µ–π—Å—Ç–≤–∏—è–º–∏.
        """
        try:
            # –õ–æ–≥–∏—Ä—É–µ–º –ø—Ä–æ–±–ª–µ–º—ã
            issues_text = "; ".join(issues)
            print(f"üö® –ö–†–ò–¢–ò–ß–ï–°–ö–ò–ï –ü–†–û–ë–õ–ï–ú–´ –Ω–∞ —à–∞–≥–µ {step}: {issues_text}")
            
            # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —ç–∫—Å—Ç—Ä–µ–Ω–Ω–æ–µ —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ –≤ Telegram
            if self.telegram_monitor:
                try:
                    self.telegram_monitor.send_critical_alert(
                        title="üö® –ö–†–ò–¢–ò–ß–ï–°–ö–ò–ï –ü–†–û–ë–õ–ï–ú–´ –û–ë–£–ß–ï–ù–ò–Ø",
                        message=f"–®–∞–≥ {step}: {issues_text}",
                        severity="critical"
                    )
                except Exception as e:
                    print(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –æ—Ç–ø—Ä–∞–≤–∏—Ç—å –∫—Ä–∏—Ç–∏—á–µ—Å–∫–æ–µ —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ: {e}")
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –∏—Å—Ç–æ—Ä–∏—é –ø—Ä–æ–±–ª–µ–º
            self.warning_history.append({
                'step': step,
                'timestamp': time.time(),
                'issues': issues,
                'severity': 'critical'
            })
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω—É–∂–µ–Ω –ª–∏ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –ø–µ—Ä–µ–∑–∞–ø—É—Å–∫
            if self._should_trigger_restart(issues):
                self._trigger_emergency_restart(step, issues)
                
        except Exception as e:
            print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏—Ö –ø—Ä–æ–±–ª–µ–º: {e}")
    
    def _should_trigger_restart(self, issues: List[str]) -> bool:
        """
        –û–ø—Ä–µ–¥–µ–ª—è–µ—Ç, –Ω—É–∂–µ–Ω –ª–∏ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –ø–µ—Ä–µ–∑–∞–ø—É—Å–∫ –Ω–∞ –æ—Å–Ω–æ–≤–µ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏—Ö –ø—Ä–æ–±–ª–µ–º.
        """
        # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –ø–µ—Ä–µ–∑–∞–ø—É—Å–∫ –ø—Ä–∏ NaN –∏–ª–∏ Inf
        for issue in issues:
            if "NaN" in issue or "Inf" in issue:
                return True
            if "–í–∑—Ä—ã–≤ –≥—Ä–∞–¥–∏–µ–Ω—Ç–æ–≤" in issue:
                return True
        return False
    
    def _trigger_emergency_restart(self, step: int, issues: List[str]):
        """
        –ó–∞–ø—É—Å–∫–∞–µ—Ç –ø—Ä–æ—Ü–µ–¥—É—Ä—É —ç–∫—Å—Ç—Ä–µ–Ω–Ω–æ–≥–æ –ø–µ—Ä–µ–∑–∞–ø—É—Å–∫–∞.
        """
        try:
            print(f"üîÑ –≠–ö–°–¢–†–ï–ù–ù–´–ô –ü–ï–†–ï–ó–ê–ü–£–°–ö –Ω–∞ —à–∞–≥–µ {step}")
            
            # –ó–∞–ø–∏—Å—ã–≤–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –ø–µ—Ä–µ–∑–∞–ø—É—Å–∫–µ
            restart_info = {
                'step': step,
                'timestamp': time.time(),
                'reason': 'critical_issues',
                'issues': issues
            }
            
            self.restart_history.append(restart_info)
            
            # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ –æ –ø–µ—Ä–µ–∑–∞–ø—É—Å–∫–µ
            if self.telegram_monitor:
                try:
                    self.telegram_monitor.send_restart_notification(
                        reason=f"–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ –ø—Ä–æ–±–ª–µ–º—ã: {'; '.join(issues)}",
                        step=step
                    )
                except Exception as e:
                    print(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –æ—Ç–ø—Ä–∞–≤–∏—Ç—å —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ –æ –ø–µ—Ä–µ–∑–∞–ø—É—Å–∫–µ: {e}")
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –ø–µ—Ä–µ–∑–∞–ø—É—Å–∫–µ –≤ —Ñ–∞–π–ª
            import json
            restart_file = f"emergency_restart_step_{step}.json"
            with open(restart_file, 'w') as f:
                json.dump(restart_info, f, indent=2)
            
            print(f"üíæ –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –ø–µ—Ä–µ–∑–∞–ø—É—Å–∫–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤ {restart_file}")
            
        except Exception as e:
            print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –∑–∞–ø—É—Å–∫–∞ —ç–∫—Å—Ç—Ä–µ–Ω–Ω–æ–≥–æ –ø–µ—Ä–µ–∑–∞–ø—É—Å–∫–∞: {e}")
    
    def _analyze_loss(self, loss_components: Dict, metrics: Dict) -> Dict:
        """üî• –ê–Ω–∞–ª–∏–∑ loss –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤"""
        analysis = {
            'components': {},
            'total_loss': metrics.get('loss', 0),
            'nan_detected': False,
            'inf_detected': False,
            'problematic_components': [],
            'loss_trend': 'stable',
            'loss_magnitude': 'normal'
        }
        
        if loss_components:
            for name, value in loss_components.items():
                if isinstance(value, (int, float)):
                    analysis['components'][name] = float(value)
                    
                    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ NaN/Inf
                    if np.isnan(value):
                        analysis['nan_detected'] = True
                        analysis['problematic_components'].append(f"{name}: NaN")
                    elif np.isinf(value):
                        analysis['inf_detected'] = True
                        analysis['problematic_components'].append(f"{name}: Inf")
                    elif abs(value) > 100:
                        analysis['problematic_components'].append(f"{name}: {value:.2f} (–æ—á–µ–Ω—å –≤—ã—Å–æ–∫–∏–π)")
        
        # –ê–Ω–∞–ª–∏–∑ —Ç—Ä–µ–Ω–¥–∞ loss
        self.loss_history.append(analysis['total_loss'])
        if len(self.loss_history) > 50:
            self.loss_history = self.loss_history[-50:]
            
        if len(self.loss_history) >= 10:
            recent_trend = np.polyfit(range(len(self.loss_history[-10:])), self.loss_history[-10:], 1)[0]
            if recent_trend > 0.001:
                analysis['loss_trend'] = 'increasing'
            elif recent_trend < -0.001:
                analysis['loss_trend'] = 'decreasing'
        
        # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –º–∞—Å—à—Ç–∞–±–∞ loss
        if analysis['total_loss'] > 10:
            analysis['loss_magnitude'] = 'very_high'
        elif analysis['total_loss'] > 5:
            analysis['loss_magnitude'] = 'high'
        elif analysis['total_loss'] < 0.1:
            analysis['loss_magnitude'] = 'very_low'
        
        return analysis
    
    def _analyze_attention(self, y_pred) -> Dict:
        """üéØ –ê–Ω–∞–ª–∏–∑ attention –º–∞—Ç—Ä–∏—Ü—ã"""
        analysis = {
            'diagonality_score': 0.0,
            'monotonicity_score': 0.0,
            'focus_score': 0.0,
            'entropy_score': 0.0,
            'attention_shape': None,
            'attention_problems': [],
            'alignment_quality': 'unknown'
        }
        
        try:
            if y_pred and len(y_pred) >= 4:
                alignments = y_pred[3] if len(y_pred) == 4 else y_pred[4]
                
                if alignments is not None and alignments.numel() > 0:
                    # –ë–µ—Ä–µ–º –ø–µ—Ä–≤—ã–π —ç–ª–µ–º–µ–Ω—Ç –±–∞—Ç—á–∞
                    attention = alignments[0].detach().cpu().numpy()
                    analysis['attention_shape'] = list(attention.shape)
                    
                    # –î–∏–∞–≥–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å
                    analysis['diagonality_score'] = self._calculate_diagonality(attention)
                    
                    # –ú–æ–Ω–æ—Ç–æ–Ω–Ω–æ—Å—Ç—å
                    analysis['monotonicity_score'] = self._calculate_monotonicity(attention)
                    
                    # –§–æ–∫—É—Å–∏—Ä–æ–≤–∫–∞
                    analysis['focus_score'] = self._calculate_focus(attention)
                    
                    # –≠–Ω—Ç—Ä–æ–ø–∏—è
                    analysis['entropy_score'] = self._calculate_entropy(attention)
                    
                    # –ü—Ä–æ–±–ª–µ–º—ã
                    if analysis['diagonality_score'] < 0.2:
                        analysis['attention_problems'].append("–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏ –Ω–∏–∑–∫–∞—è –¥–∏–∞–≥–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å")
                    if analysis['monotonicity_score'] < 0.3:
                        analysis['attention_problems'].append("–ü–ª–æ—Ö–∞—è –º–æ–Ω–æ—Ç–æ–Ω–Ω–æ—Å—Ç—å")
                    if analysis['focus_score'] < 0.4:
                        analysis['attention_problems'].append("–†–∞–∑–º—ã—Ç—ã–π —Ñ–æ–∫—É—Å")
                    
                    # –û–±—â–∞—è –æ—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞
                    avg_score = (analysis['diagonality_score'] + analysis['monotonicity_score'] + analysis['focus_score']) / 3
                    if avg_score > 0.7:
                        analysis['alignment_quality'] = 'excellent'
                    elif avg_score > 0.5:
                        analysis['alignment_quality'] = 'good'
                    elif avg_score > 0.3:
                        analysis['alignment_quality'] = 'poor'
                    else:
                        analysis['alignment_quality'] = 'critical'
                    
                    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –∏—Å—Ç–æ—Ä–∏—é
                    self.attention_history.append({
                        'diagonality': analysis['diagonality_score'],
                        'monotonicity': analysis['monotonicity_score'],
                        'focus': analysis['focus_score']
                    })
                    
                    if len(self.attention_history) > 100:
                        self.attention_history = self.attention_history[-100:]
                        
        except Exception as e:
            analysis['attention_problems'].append(f"–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞: {str(e)}")
        
        return analysis
    
    def _analyze_gradients(self, model) -> Dict:
        """üìà –ê–Ω–∞–ª–∏–∑ –≥—Ä–∞–¥–∏–µ–Ω—Ç–æ–≤ –º–æ–¥–µ–ª–∏"""
        analysis = {
            'total_grad_norm': 0.0,
            'layer_grad_norms': {},
            'grad_problems': [],
            'grad_status': 'normal',
            'max_grad': 0.0,
            'min_grad': 0.0,
            'nan_gradients': False,
            'zero_gradients': 0
        }
        
        try:
            if model:
                total_norm = 0.0
                grad_values = []
                zero_count = 0
                
                for name, param in model.named_parameters():
                    if param.grad is not None:
                        param_norm = param.grad.data.norm(2).item()
                        analysis['layer_grad_norms'][name] = param_norm
                        total_norm += param_norm ** 2
                        
                        grad_flat = param.grad.data.flatten()
                        grad_values.extend(grad_flat.cpu().numpy().tolist())
                        
                        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ NaN
                        if torch.isnan(param.grad.data).any():
                            analysis['nan_gradients'] = True
                            analysis['grad_problems'].append(f"NaN –≤ {name}")
                        
                        # –ü–æ–¥—Å—á–µ—Ç –Ω—É–ª–µ–≤—ã—Ö –≥—Ä–∞–¥–∏–µ–Ω—Ç–æ–≤
                        zero_count += (param.grad.data == 0).sum().item()
                
                analysis['total_grad_norm'] = total_norm ** 0.5
                analysis['zero_gradients'] = zero_count
                
                if grad_values:
                    analysis['max_grad'] = float(np.max(np.abs(grad_values)))
                    analysis['min_grad'] = float(np.min(np.abs(grad_values)))
                
                # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Å—Ç–∞—Ç—É—Å–∞ –≥—Ä–∞–¥–∏–µ–Ω—Ç–æ–≤
                if analysis['total_grad_norm'] > 10.0:
                    analysis['grad_status'] = 'explosion'
                    analysis['grad_problems'].append("–í–∑—Ä—ã–≤ –≥—Ä–∞–¥–∏–µ–Ω—Ç–æ–≤")
                elif analysis['total_grad_norm'] < 1e-6:
                    analysis['grad_status'] = 'vanishing'
                    analysis['grad_problems'].append("–ó–∞—Ç—É—Ö–∞–Ω–∏–µ –≥—Ä–∞–¥–∏–µ–Ω—Ç–æ–≤")
                elif analysis['nan_gradients']:
                    analysis['grad_status'] = 'nan'
                
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –∏—Å—Ç–æ—Ä–∏—é
                self.gradient_history.append(analysis['total_grad_norm'])
                if len(self.gradient_history) > 100:
                    self.gradient_history = self.gradient_history[-100:]
                    
        except Exception as e:
            analysis['grad_problems'].append(f"–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ –≥—Ä–∞–¥–∏–µ–Ω—Ç–æ–≤: {str(e)}")
        
        return analysis
    
    def _collect_hyperparameters(self, hparams) -> Dict:
        """‚öôÔ∏è –°–±–æ—Ä —Ç–µ–∫—É—â–∏—Ö –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤"""
        params = {}
        
        if hparams:
            key_params = [
                'learning_rate', 'batch_size', 'grad_clip_thresh',
                'use_guided_attn', 'guide_loss_weight', 'guide_loss_initial_weight',
                'p_attention_dropout', 'p_decoder_dropout', 'gate_threshold',
                'use_mmi', 'fp16_run', 'epochs'
            ]
            
            for param in key_params:
                if hasattr(hparams, param):
                    params[param] = getattr(hparams, param)
                    
        return params
    
    def _collect_system_info(self) -> Dict:
        """üñ•Ô∏è –°–±–æ—Ä —Å–∏—Å—Ç–µ–º–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏"""
        info = {
            'cpu_percent': psutil.cpu_percent(),
            'memory_percent': psutil.virtual_memory().percent,
            'memory_available_gb': psutil.virtual_memory().available / (1024**3),
            'gpu_info': {},
            'disk_usage_percent': psutil.disk_usage('/').percent
        }
        
        try:
            if torch.cuda.is_available():
                for i in range(torch.cuda.device_count()):
                    gpu_mem = torch.cuda.get_device_properties(i).total_memory / (1024**3)
                    gpu_mem_used = torch.cuda.memory_allocated(i) / (1024**3)
                    info['gpu_info'][f'gpu_{i}'] = {
                        'total_memory_gb': gpu_mem,
                        'used_memory_gb': gpu_mem_used,
                        'memory_percent': (gpu_mem_used / gpu_mem) * 100,
                        'name': torch.cuda.get_device_name(i)
                    }
        except Exception as e:
            info['gpu_info']['error'] = str(e)
        
        return info
    
    def _detect_issues(self, metrics: Dict, loss_components: Dict, y_pred) -> List[str]:
        """‚ö†Ô∏è –û–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ –ø—Ä–æ–±–ª–µ–º"""
        issues = []
        
        # –ü—Ä–æ–±–ª–µ–º—ã —Å loss
        if metrics.get('loss', 0) != metrics.get('loss', 0):  # NaN check
            issues.append("üö® –ö–†–ò–¢–ò–ß–ù–û: Loss —Å—Ç–∞–ª NaN")
        elif metrics.get('loss', 0) == float('inf'):
            issues.append("üö® –ö–†–ò–¢–ò–ß–ù–û: Loss —Å—Ç–∞–ª –±–µ—Å–∫–æ–Ω–µ—á–Ω—ã–º")
        elif metrics.get('loss', 0) > 50:
            issues.append("‚ö†Ô∏è –í–´–°–û–ö–ò–ô: Loss –æ—á–µ–Ω—å –±–æ–ª—å—à–æ–π")
        
        # –ü—Ä–æ–±–ª–µ–º—ã —Å attention
        try:
            if y_pred and len(y_pred) >= 4:
                alignments = y_pred[3] if len(y_pred) == 4 else y_pred[4]
                if alignments is not None:
                    diag = self._calculate_diagonality(alignments[0].detach().cpu().numpy())
                    if diag < 0.1:
                        issues.append("üö® –ö–†–ò–¢–ò–ß–ù–û: Attention –¥–∏–∞–≥–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å <10%")
                    elif diag < 0.3:
                        issues.append("‚ö†Ô∏è –ù–ò–ó–ö–ê–Ø: Attention –¥–∏–∞–≥–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å <30%")
        except:
            issues.append("‚ùì –ù–ï–ò–ó–í–ï–°–¢–ù–û: –ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å attention")
        
        # –ü—Ä–æ–±–ª–µ–º—ã —Å –ø–∞–º—è—Ç—å—é
        if psutil.virtual_memory().percent > 90:
            issues.append("üñ•Ô∏è –ü–ê–ú–Ø–¢–¨: –í—ã—Å–æ–∫–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –û–ó–£")
        
        # –ü—Ä–æ–±–ª–µ–º—ã —Å GPU
        try:
            if torch.cuda.is_available():
                for i in range(torch.cuda.device_count()):
                    mem_used = torch.cuda.memory_allocated(i) / torch.cuda.get_device_properties(i).total_memory
                    if mem_used > 0.95:
                        issues.append(f"üéÆ GPU {i}: –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏ –º–∞–ª–æ –ø–∞–º—è—Ç–∏")
        except:
            pass
        
        return issues
    
    def _analyze_trends(self, step: int, metrics: Dict) -> Dict:
        """üìä –ê–Ω–∞–ª–∏–∑ —Ç—Ä–µ–Ω–¥–æ–≤"""
        trends = {
            'loss_trend_last_100': 'stable',
            'attention_trend': 'stable',
            'gradient_trend': 'stable',
            'performance_degrading': False
        }
        
        try:
            # –¢—Ä–µ–Ω–¥ loss
            if len(self.loss_history) >= 20:
                recent_losses = self.loss_history[-20:]
                trend_coef = np.polyfit(range(len(recent_losses)), recent_losses, 1)[0]
                if trend_coef > 0.01:
                    trends['loss_trend_last_100'] = 'worsening'
                elif trend_coef < -0.01:
                    trends['loss_trend_last_100'] = 'improving'
            
            # –¢—Ä–µ–Ω–¥ attention
            if len(self.attention_history) >= 10:
                recent_diag = [h['diagonality'] for h in self.attention_history[-10:]]
                trend_coef = np.polyfit(range(len(recent_diag)), recent_diag, 1)[0]
                if trend_coef > 0.01:
                    trends['attention_trend'] = 'improving'
                elif trend_coef < -0.01:
                    trends['attention_trend'] = 'degrading'
            
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–µ–≥—Ä–∞–¥–∞—Ü–∏–∏ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
            if (trends['loss_trend_last_100'] == 'worsening' and 
                trends['attention_trend'] == 'degrading'):
                trends['performance_degrading'] = True
                
        except Exception as e:
            trends['analysis_error'] = str(e)
        
        return trends
    
    def _calculate_diagonality(self, attention_matrix) -> float:
        """–ë—ã—Å—Ç—Ä—ã–π —Ä–∞—Å—á–µ—Ç –¥–∏–∞–≥–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏"""
        try:
            if attention_matrix.size == 0:
                return 0.0
            
            mel_len, text_len = attention_matrix.shape
            diagonal_sum = 0.0
            total_sum = attention_matrix.sum()
            
            if total_sum == 0:
                return 0.0
            
            for i in range(mel_len):
                diagonal_pos = int(i * text_len / mel_len)
                if diagonal_pos < text_len:
                    diagonal_sum += attention_matrix[i, diagonal_pos]
            
            return diagonal_sum / total_sum if total_sum > 0 else 0.0
        except:
            return 0.0
    
    def _calculate_monotonicity(self, attention_matrix) -> float:
        """–†–∞—Å—á–µ—Ç –º–æ–Ω–æ—Ç–æ–Ω–Ω–æ—Å—Ç–∏"""
        try:
            peaks = np.argmax(attention_matrix, axis=1)
            monotonic = sum(1 for i in range(1, len(peaks)) if peaks[i] >= peaks[i-1])
            return monotonic / max(1, len(peaks) - 1)
        except:
            return 0.0
    
    def _calculate_focus(self, attention_matrix) -> float:
        """–†–∞—Å—á–µ—Ç —Ñ–æ–∫—É—Å–∏—Ä–æ–≤–∫–∏"""
        try:
            entropies = []
            for i in range(attention_matrix.shape[0]):
                attention_step = attention_matrix[i] + 1e-8
                # üî• –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞ –Ω—É–ª–∏ –∏ –Ω–æ—Ä–º–∞–ª–∏–∑—É–µ–º
                attention_step = attention_step / (attention_step.sum() + 1e-8)
                # –ú–∞—Å–∫–∏—Ä—É–µ–º –Ω—É–ª–∏ –¥–ª—è –∏–∑–±–µ–∂–∞–Ω–∏—è log(0)
                mask = attention_step > 1e-8
                if mask.any():
                    entropy = -np.sum(attention_step[mask] * np.log(attention_step[mask]))
                else:
                    entropy = 0.0
                entropies.append(entropy)
            
            max_entropy = np.log(attention_matrix.shape[1])
            avg_entropy = np.mean(entropies) if entropies else 0.0
            return 1.0 - (avg_entropy / max_entropy) if max_entropy > 0 else 0.0
        except:
            return 0.0
    
    def _calculate_entropy(self, attention_matrix) -> float:
        """–†–∞—Å—á–µ—Ç —ç–Ω—Ç—Ä–æ–ø–∏–∏"""
        try:
            # üî• –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –º–∞—Ç—Ä–∏—Ü—É –∏ –∏–∑–±–µ–≥–∞–µ–º log(0)
            attention_matrix = attention_matrix + 1e-8
            attention_matrix = attention_matrix / (attention_matrix.sum() + 1e-8)
            
            # –ú–∞—Å–∫–∏—Ä—É–µ–º –æ—á–µ–Ω—å –º–∞–ª–µ–Ω—å–∫–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è
            mask = attention_matrix > 1e-8
            if mask.any():
                entropy = -np.sum(attention_matrix[mask] * np.log(attention_matrix[mask]))
            else:
                entropy = 0.0
                
            max_entropy = np.log(attention_matrix.size)
            return entropy / max_entropy if max_entropy > 0 else 0.0
        except:
            return 0.0
    
    def send_debug_report(self, step: int):
        """üì± –û—Ç–ø—Ä–∞–≤–∫–∞ debug –æ—Ç—á–µ—Ç–∞ –≤ Telegram"""
        try:
            if not self.telegram_monitor:
                return
            
            # –°–æ–∑–¥–∞–µ–º debug —Ñ–∞–π–ª
            debug_filename = f"debug_step_{step}.txt"
            debug_content = self._generate_debug_content(step)
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤–æ –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
            with open(debug_filename, 'w', encoding='utf-8') as f:
                f.write(debug_content)
            
            # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —Ñ–∞–π–ª
            caption = f"üîç **Debug Report - –®–∞–≥ {step}**\n"
            caption += f"üìä **–ê–Ω–∞–ª–∏–∑ –ø–æ—Å–ª–µ–¥–Ω–∏—Ö {len(self.debug_data)} —à–∞–≥–æ–≤**\n"
            caption += f"‚è∞ **–í—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è:** {(time.time() - self.start_time) / 3600:.1f}—á"
            
            success = self._send_file_to_telegram(debug_filename, caption)
            
            if success:
                print(f"‚úÖ Debug –æ—Ç—á–µ—Ç –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω: {debug_filename}")
            else:
                print(f"‚ùå –û—à–∏–±–∫–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏ debug –æ—Ç—á–µ—Ç–∞")
            
            # –£–¥–∞–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
            try:
                os.remove(debug_filename)
            except:
                pass
                
        except Exception as e:
            print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è debug –æ—Ç—á–µ—Ç–∞: {e}")
    
    def _generate_debug_content(self, step: int) -> str:
        """üìù –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ debug —Ñ–∞–π–ª–∞"""
        content = f"""üîç TECHNICAL DEBUG REPORT - –®–∞–≥ {step}
{'='*80}
üìÖ –í—Ä–µ–º—è —Å–æ–∑–¥–∞–Ω–∏—è: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
‚è∞ –í—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è: {(time.time() - self.start_time) / 3600:.2f} —á–∞—Å–æ–≤
üìä –í—Å–µ–≥–æ –¥–∞–Ω–Ω—ã—Ö: {len(self.debug_data)} —à–∞–≥–æ–≤

{'='*80}
üî• SUMMARY - –ö–†–ò–¢–ò–ß–ï–°–ö–ò–ï –ü–†–û–ë–õ–ï–ú–´
{'='*80}
"""
        
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è summary
        if self.debug_data:
            latest = self.debug_data[-1]
            
            content += f"üéØ –¢–µ–∫—É—â–∏–π —à–∞–≥: {latest['step']}\n"
            content += f"üìâ Loss: {latest['loss_analysis']['total_loss']:.6f}\n"
            content += f"üéØ Attention –¥–∏–∞–≥–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å: {latest['attention_analysis']['diagonality_score']:.1%}\n"
            content += f"üìà –ì—Ä–∞–¥–∏–µ–Ω—Ç –Ω–æ—Ä–º–∞: {latest['gradient_analysis']['total_grad_norm']:.6f}\n"
            content += f"üíæ –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –ø–∞–º—è—Ç–∏: {latest['system_info']['memory_percent']:.1f}%\n"
            
            # –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ –ø—Ä–æ–±–ª–µ–º—ã
            if latest['issues_detected']:
                content += f"\nüö® –ö–†–ò–¢–ò–ß–ï–°–ö–ò–ï –ü–†–û–ë–õ–ï–ú–´:\n"
                for issue in latest['issues_detected']:
                    content += f"  ‚Ä¢ {issue}\n"
            
            # –¢—Ä–µ–Ω–¥—ã
            trends = latest['trends']
            content += f"\nüìä –¢–†–ï–ù–î–´:\n"
            content += f"  ‚Ä¢ Loss: {trends['loss_trend_last_100']}\n"
            content += f"  ‚Ä¢ Attention: {trends['attention_trend']}\n"
            content += f"  ‚Ä¢ –î–µ–≥—Ä–∞–¥–∞—Ü–∏—è: {'–î–ê' if trends['performance_degrading'] else '–ù–ï–¢'}\n"
        
        content += f"\n{'='*80}\n"
        content += f"üìä –î–ï–¢–ê–õ–¨–ù–´–ï –î–ê–ù–ù–´–ï\n"
        content += f"{'='*80}\n"
        
        # –î–æ–±–∞–≤–ª—è–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ 50 —à–∞–≥–æ–≤ –ø–æ–¥—Ä–æ–±–Ω–æ
        recent_data = self.debug_data[-50:] if len(self.debug_data) > 50 else self.debug_data
        
        for i, data in enumerate(recent_data):
            content += f"\n--- –®–ê–ì {data['step']} ---\n"
            content += f"–í—Ä–µ–º—è: {data['timestamp']}\n"
            
            # Loss –∞–Ω–∞–ª–∏–∑
            loss_info = data['loss_analysis']
            content += f"Loss: {loss_info['total_loss']:.6f} ({loss_info['loss_trend']}, {loss_info['loss_magnitude']})\n"
            if loss_info['problematic_components']:
                content += f"–ü—Ä–æ–±–ª–µ–º—ã —Å loss: {', '.join(loss_info['problematic_components'])}\n"
            
            # Attention –∞–Ω–∞–ª–∏–∑
            att_info = data['attention_analysis']
            content += f"Attention: –¥–∏–∞–≥={att_info['diagonality_score']:.3f}, –º–æ–Ω–æ—Ç={att_info['monotonicity_score']:.3f}, —Ñ–æ–∫—É—Å={att_info['focus_score']:.3f}\n"
            if att_info['attention_problems']:
                content += f"–ü—Ä–æ–±–ª–µ–º—ã attention: {', '.join(att_info['attention_problems'])}\n"
            
            # –ì—Ä–∞–¥–∏–µ–Ω—Ç—ã
            grad_info = data['gradient_analysis']
            content += f"–ì—Ä–∞–¥–∏–µ–Ω—Ç—ã: –Ω–æ—Ä–º–∞={grad_info['total_grad_norm']:.6f}, —Å—Ç–∞—Ç—É—Å={grad_info['grad_status']}\n"
            
            # Smart Tuner —Ä–µ—à–µ–Ω–∏—è
            if data['smart_tuner_decisions']:
                content += f"Smart Tuner: {json.dumps(data['smart_tuner_decisions'], ensure_ascii=False, indent=2)}\n"
            
            # –°–∏—Å—Ç–µ–º–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è
            sys_info = data['system_info']
            content += f"–°–∏—Å—Ç–µ–º–∞: CPU={sys_info['cpu_percent']:.1f}%, RAM={sys_info['memory_percent']:.1f}%\n"
            
            # –ü—Ä–æ–±–ª–µ–º—ã
            if data['issues_detected']:
                content += f"–ü–†–û–ë–õ–ï–ú–´: {', '.join(data['issues_detected'])}\n"
            
            content += "\n"
        
        # –ò—Å—Ç–æ—Ä–∏—è –ø–µ—Ä–µ–∑–∞–ø—É—Å–∫–æ–≤
        if self.restart_history:
            content += f"\n{'='*80}\n"
            content += f"üîÑ –ò–°–¢–û–†–ò–Ø –ü–ï–†–ï–ó–ê–ü–£–°–ö–û–í\n"
            content += f"{'='*80}\n"
            for restart in self.restart_history:
                content += f"{restart}\n"
        
        content += f"\n{'='*80}\n"
        content += f"üìà –°–¢–ê–¢–ò–°–¢–ò–ö–ê –ò –¢–†–ï–ù–î–´\n"
        content += f"{'='*80}\n"
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ loss
        if self.loss_history:
            content += f"Loss –∏—Å—Ç–æ—Ä–∏—è ({len(self.loss_history)} —Ç–æ—á–µ–∫):\n"
            content += f"  –ú–∏–Ω: {min(self.loss_history):.6f}\n"
            content += f"  –ú–∞–∫—Å: {max(self.loss_history):.6f}\n"
            content += f"  –¢–µ–∫—É—â–∏–π: {self.loss_history[-1]:.6f}\n"
            content += f"  –°—Ä–µ–¥–Ω–µ–µ (–ø–æ—Å–ª–µ–¥–Ω–∏–µ 20): {np.mean(self.loss_history[-20:]):.6f}\n"
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ attention
        if self.attention_history:
            recent_diag = [h['diagonality'] for h in self.attention_history[-20:]]
            content += f"Attention –¥–∏–∞–≥–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å (–ø–æ—Å–ª–µ–¥–Ω–∏–µ 20):\n"
            content += f"  –ú–∏–Ω: {min(recent_diag):.3f}\n"
            content += f"  –ú–∞–∫—Å: {max(recent_diag):.3f}\n"
            content += f"  –°—Ä–µ–¥–Ω–µ–µ: {np.mean(recent_diag):.3f}\n"
        
        content += f"\n{'='*80}\n"
        content += f"üéØ –ö–û–ù–ï–¶ –û–¢–ß–ï–¢–ê\n"
        content += f"{'='*80}\n"
        
        return content
    
    def _send_file_to_telegram(self, filename: str, caption: str) -> bool:
        """üì± –û—Ç–ø—Ä–∞–≤–∫–∞ —Ñ–∞–π–ª–∞ –≤ Telegram"""
        try:
            if hasattr(self.telegram_monitor, '_send_document'):
                return self.telegram_monitor._send_document(filename, caption)
            elif hasattr(self.telegram_monitor, 'bot_token') and hasattr(self.telegram_monitor, 'chat_id'):
                # –ü—Ä—è–º–∞—è –æ—Ç–ø—Ä–∞–≤–∫–∞ —á–µ—Ä–µ–∑ API
                import requests
                
                url = f"https://api.telegram.org/bot{self.telegram_monitor.bot_token}/sendDocument"
                
                with open(filename, 'rb') as f:
                    files = {'document': f}
                    data = {
                        'chat_id': self.telegram_monitor.chat_id,
                        'caption': caption,
                        'parse_mode': 'Markdown'
                    }
                    
                    response = requests.post(url, files=files, data=data, timeout=30)
                    response.raise_for_status()
                    return True
            else:
                print("‚ö†Ô∏è Telegram monitor –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –æ—Ç–ø—Ä–∞–≤–∫—É —Ñ–∞–π–ª–æ–≤")
                return False
                
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏ —Ñ–∞–π–ª–∞ –≤ Telegram: {e}")
            return False
    
    def add_restart_info(self, restart_info: str):
        """üîÑ –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –ø–µ—Ä–µ–∑–∞–ø—É—Å–∫–µ"""
        timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        self.restart_history.append(f"[{timestamp}] {restart_info}")
    
    def add_warning(self, warning: str):
        """‚ö†Ô∏è –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è"""
        timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        self.warning_history.append(f"[{timestamp}] {warning}")


# –ì–ª–æ–±–∞–ª—å–Ω—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –≤ train.py
debug_reporter = None

def initialize_debug_reporter(telegram_monitor=None):
    """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –≥–ª–æ–±–∞–ª—å–Ω–æ–≥–æ debug reporter"""
    global debug_reporter
    debug_reporter = DebugReporter(telegram_monitor)
    return debug_reporter

def get_debug_reporter():
    """–ü–æ–ª—É—á–µ–Ω–∏–µ –≥–ª–æ–±–∞–ª—å–Ω–æ–≥–æ debug reporter"""
    return debug_reporter
