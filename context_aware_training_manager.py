#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Context-Aware Training Manager - –ò–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω—ã–π –º–µ–Ω–µ–¥–∂–µ—Ä –æ–±—É—á–µ–Ω–∏—è
–ó–∞–º–µ–Ω–∞ –¥–µ—Å—Ç—Ä—É–∫—Ç–∏–≤–Ω–æ–≥–æ AutoFixManager –Ω–∞ —É–º–Ω—É—é —Å–∏—Å—Ç–µ–º—É —Å –ø–æ–Ω–∏–º–∞–Ω–∏–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞

üéØ –û—Å–Ω–æ–≤–Ω—ã–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏:
- Bayesian Phase Classification –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Ñ–∞–∑—ã –æ–±—É—á–µ–Ω–∏—è
- –ê–¥–∞–ø—Ç–∏–≤–Ω–æ–µ —É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ loss —Ñ—É–Ω–∫—Ü–∏—è–º–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
- –£–º–Ω–æ–µ —É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ learning rate —Å —É—á–µ—Ç–æ–º —Å–æ—Å—Ç–æ—è–Ω–∏—è –º–æ–¥–µ–ª–∏
- –ü–ª–∞–≤–Ω—ã–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –≤–º–µ—Å—Ç–æ –∞–≥—Ä–µ—Å—Å–∏–≤–Ω—ã—Ö —Å–∫–∞—á–∫–æ–≤
- –ú–µ—Ö–∞–Ω–∏–∑–º—ã rollback –∏ –æ—Ü–µ–Ω–∫–∏ —Ä–∏—Å–∫–æ–≤

üîÑ –ó–∞–º–µ–Ω—è–µ—Ç: AutoFixManager (–¥–µ—Å—Ç—Ä—É–∫—Ç–∏–≤–Ω–æ–µ –ø–æ–≤–µ–¥–µ–Ω–∏–µ)
‚úÖ –û–±–µ—Å–ø–µ—á–∏–≤–∞–µ—Ç: –°—Ç–∞–±–∏–ª—å–Ω–æ–µ –∏ –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω–æ-–æ—Å–æ–∑–Ω–∞–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ
"""

import torch
import torch.nn as nn
import numpy as np
from typing import Dict, List, Tuple, Optional, Any
from dataclasses import dataclass
from enum import Enum
import logging
from collections import deque
import pickle
import time

class TrainingPhase(Enum):
    """–§–∞–∑—ã –æ–±—É—á–µ–Ω–∏—è TTS –º–æ–¥–µ–ª–∏ —Å —á–µ—Ç–∫–æ–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–µ–π"""
    PRE_ALIGNMENT = "pre_alignment"      # –ù–∞—á–∞–ª—å–Ω–æ–µ –≤—ã—Ä–∞–≤–Ω–∏–≤–∞–Ω–∏–µ (attention_diag < 0.1)
    ALIGNMENT_LEARNING = "alignment"     # –ò–∑—É—á–µ–Ω–∏–µ –≤—ã—Ä–∞–≤–Ω–∏–≤–∞–Ω–∏—è (0.1 ‚â§ attention_diag < 0.5)
    REFINEMENT = "refinement"           # –£–ª—É—á—à–µ–Ω–∏–µ –∫–∞—á–µ—Å—Ç–≤–∞ (0.5 ‚â§ attention_diag < 0.7)
    CONVERGENCE = "convergence"         # –§–∏–Ω–∞–ª—å–Ω–∞—è –∫–æ–Ω–≤–µ—Ä–≥–µ–Ω—Ü–∏—è (attention_diag ‚â• 0.7)

@dataclass
class TrainingContext:
    """–ö–æ–Ω—Ç–µ–∫—Å—Ç —Ç–µ–∫—É—â–µ–≥–æ —Å–æ—Å—Ç–æ—è–Ω–∏—è –æ–±—É—á–µ–Ω–∏—è - –ø–æ–ª–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –¥–ª—è –ø—Ä–∏–Ω—è—Ç–∏—è —Ä–µ—à–µ–Ω–∏–π"""
    phase: TrainingPhase
    step: int
    epoch: int
    loss_trend: float
    attention_quality: float
    gradient_health: float
    learning_rate: float
    convergence_score: float
    stability_index: float
    time_since_improvement: int
    
    # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏ –¥–ª—è Tacotron2
    attention_diagonality: float = 0.0
    gate_accuracy: float = 0.0
    mel_loss: float = 0.0
    gate_loss: float = 0.0
    guided_attention_loss: float = 0.0

class ContextAnalyzer:
    """–ê–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –æ–±—É—á–µ–Ω–∏—è –Ω–∞ –æ—Å–Ω–æ–≤–µ Bayesian classification"""

    def __init__(self, history_size: int = 100):
        self.history_size = history_size
        self.loss_history = deque(maxlen=history_size)
        self.attention_history = deque(maxlen=history_size) 
        self.gradient_history = deque(maxlen=history_size)
        self.gate_accuracy_history = deque(maxlen=history_size)

        # Gaussian Mixture Model –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ —Ñ–∞–∑
        self.phase_classifier = None
        self.trend_analyzer = None
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –¥–ª—è –ª—É—á—à–µ–≥–æ –∞–Ω–∞–ª–∏–∑–∞
        self.improvement_tracker = deque(maxlen=20)
        self.last_improvement_step = 0

    def update_metrics(self, loss: float, attention_diag: float, grad_norm: float, 
                      gate_accuracy: float = 0.0):
        """–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Ç—Ä–µ–Ω–¥–∞ –æ–±—É—á–µ–Ω–∏—è"""
        self.loss_history.append(loss)
        self.attention_history.append(attention_diag)
        self.gradient_history.append(grad_norm)
        self.gate_accuracy_history.append(gate_accuracy)
        
        # –û—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏–µ —É–ª—É—á—à–µ–Ω–∏–π
        if len(self.loss_history) > 1 and loss < min(list(self.loss_history)[-10:]):
            self.improvement_tracker.append(True)
            self.last_improvement_step = len(self.loss_history)
        else:
            self.improvement_tracker.append(False)

    def analyze_phase(self) -> TrainingPhase:
        """–û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ç–µ–∫—É—â–µ–π —Ñ–∞–∑—ã –æ–±—É—á–µ–Ω–∏—è –Ω–∞ –æ—Å–Ω–æ–≤–µ –∞–Ω–∞–ª–∏–∑–∞ —Ç—Ä–µ–Ω–¥–æ–≤"""
        if len(self.loss_history) < 10:
            return TrainingPhase.PRE_ALIGNMENT

        # –ê–Ω–∞–ª–∏–∑ –∫–ª—é—á–µ–≤—ã—Ö –º–µ—Ç—Ä–∏–∫
        attention_mean = np.mean(list(self.attention_history)[-20:])  # –ü–æ—Å–ª–µ–¥–Ω–∏–µ 20 –∑–Ω–∞—á–µ–Ω–∏–π
        loss_trend = self._calculate_trend(list(self.loss_history))
        gradient_stability = np.std(list(self.gradient_history)[-10:])

        # üéØ –£–ú–ù–ê–Ø –ª–æ–≥–∏–∫–∞ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ —Ñ–∞–∑ (–≤–º–µ—Å—Ç–æ —Ö–∞–æ—Ç–∏—á–Ω—ã—Ö –∏–∑–º–µ–Ω–µ–Ω–∏–π AutoFixManager)
        if attention_mean < 0.1:
            return TrainingPhase.PRE_ALIGNMENT
        elif 0.1 <= attention_mean < 0.5:
            return TrainingPhase.ALIGNMENT_LEARNING
        elif 0.5 <= attention_mean < 0.7 and loss_trend < 0:
            return TrainingPhase.REFINEMENT
        elif attention_mean >= 0.7:
            return TrainingPhase.CONVERGENCE
        else:
            # Fallback –Ω–∞ –æ—Å–Ω–æ–≤–µ loss —Ç—Ä–µ–Ω–¥–∞
            return TrainingPhase.ALIGNMENT_LEARNING

    def _calculate_trend(self, values: List[float], window: int = 10) -> float:
        """–†–∞—Å—á–µ—Ç —Ç—Ä–µ–Ω–¥–∞ –∏—Å–ø–æ–ª—å–∑—É—è –ª–∏–Ω–µ–π–Ω—É—é —Ä–µ–≥—Ä–µ—Å—Å–∏—é –¥–ª—è smooth –∞–Ω–∞–ª–∏–∑–∞"""
        if len(values) < window:
            return 0.0
        recent_values = values[-window:]
        x = np.arange(len(recent_values))
        slope = np.polyfit(x, recent_values, 1)[0]
        return slope
    
    def get_stability_index(self) -> float:
        """–í—ã—á–∏—Å–ª–µ–Ω–∏–µ –∏–Ω–¥–µ–∫—Å–∞ —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏ –æ–±—É—á–µ–Ω–∏—è"""
        if len(self.loss_history) < 10:
            return 0.5
        
        # –ê–Ω–∞–ª–∏–∑ –≤–∞—Ä–∏–∞—Ç–∏–≤–Ω–æ—Å—Ç–∏ –ø–æ—Å–ª–µ–¥–Ω–∏—Ö 20 —à–∞–≥–æ–≤
        recent_losses = list(self.loss_history)[-20:]
        recent_gradients = list(self.gradient_history)[-20:]
        
        loss_stability = 1.0 / (1.0 + np.std(recent_losses))
        gradient_stability = 1.0 / (1.0 + np.std(recent_gradients))
        
        return (loss_stability + gradient_stability) / 2.0

class EnhancedLossIntegrator:
    """
    üéØ Enhanced Loss Integrator - –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å Enhanced Adaptive Loss System
    –ó–∞–º–µ–Ω—è–µ—Ç –ø—Ä–æ—Å—Ç–æ–π AdaptiveLossController –Ω–∞ –ø–æ–ª–Ω—É—é –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—é —Å –∞–¥–∞–ø—Ç–∏–≤–Ω–æ–π —Å–∏—Å—Ç–µ–º–æ–π
    """

    def __init__(self, initial_guided_weight: float = 4.5):
        # üîß –ë–ê–ó–û–í–´–ï –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è fallback —Ä–µ–∂–∏–º–∞
        self.guided_attention_weight = initial_guided_weight
        self.mel_weight = 1.0
        self.gate_weight = 1.0

        # –ò—Å—Ç–æ—Ä–∏—è –¥–ª—è –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞
        self.integration_history = []
        self.performance_metrics = []
        
        # –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏ (—Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å —Å –ø—Ä–µ–¥—ã–¥—É—â–µ–π –≤–µ—Ä—Å–∏–µ–π)
        self.min_guided_weight = 1.0
        self.max_guided_weight = 15.0
        
        # –§–ª–∞–≥ –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ —Å Enhanced Adaptive Loss System
        self.enhanced_system_available = False
        self.loss_function_ref = None
        
        print("üéØ EnhancedLossIntegrator –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω - –≥–æ—Ç–æ–≤ –∫ –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ —Å –∞–¥–∞–ø—Ç–∏–≤–Ω–æ–π —Å–∏—Å—Ç–µ–º–æ–π")

    def update_guided_attention_weight(self, context: TrainingContext) -> float:
        """üéØ –£–ú–ù–û–ï –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ guided attention weight –Ω–∞ –æ—Å–Ω–æ–≤–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ (–≤–º–µ—Å—Ç–æ *10 –≤ AutoFixManager)"""
        
        current_weight = self.guided_attention_weight
        
        # –ü–ª–∞–≤–Ω–∞—è –∞–¥–∞–ø—Ç–∞—Ü–∏—è –Ω–∞ –æ—Å–Ω–æ–≤–µ –∫–∞—á–µ—Å—Ç–≤–∞ attention
        if context.attention_quality < 0.1:
            # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º –ø–ª–∞–≤–Ω–æ (–Ω–µ –≤ 10 —Ä–∞–∑ –∫–∞–∫ AutoFixManager!)
            target_weight = min(current_weight * 1.5, self.max_guided_weight)
        elif context.attention_quality > 0.7:
            # –°–Ω–∏–∂–∞–µ–º –ø—Ä–∏ —Ö–æ—Ä–æ—à–µ–º alignment
            target_weight = max(current_weight * 0.8, self.min_guided_weight)
        else:
            # –ü–ª–∞–≤–Ω–∞—è –∏–Ω—Ç–µ—Ä–ø–æ–ª—è—Ü–∏—è –º–µ–∂–¥—É —Å–æ—Å—Ç–æ—è–Ω–∏—è–º–∏
            factor = 1.5 - (context.attention_quality - 0.1) / 0.6 * 1.0
            target_weight = current_weight * factor
            target_weight = np.clip(target_weight, self.min_guided_weight, self.max_guided_weight)
        
        # üîí –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º —Å–∫–æ—Ä–æ—Å—Ç—å –∏–∑–º–µ–Ω–µ–Ω–∏—è (–ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–µ–Ω–∏–µ —Ä–µ–∑–∫–∏—Ö —Å–∫–∞—á–∫–æ–≤)
        max_change = current_weight * 0.2  # –ú–∞–∫—Å–∏–º—É–º 20% –∏–∑–º–µ–Ω–µ–Ω–∏–µ –∑–∞ —à–∞–≥
        if abs(target_weight - current_weight) > max_change:
            if target_weight > current_weight:
                target_weight = current_weight + max_change
            else:
                target_weight = current_weight - max_change
        
        self.guided_attention_weight = target_weight
        return target_weight

    def set_loss_function_reference(self, loss_function):
        """
        üîó –£—Å—Ç–∞–Ω–æ–≤–∫–∞ —Å—Å—ã–ª–∫–∏ –Ω–∞ loss —Ñ—É–Ω–∫—Ü–∏—é –¥–ª—è –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ —Å Enhanced Adaptive Loss System
        
        Args:
            loss_function: –≠–∫–∑–µ–º–ø–ª—è—Ä Tacotron2Loss —Å –∞–¥–∞–ø—Ç–∏–≤–Ω–æ–π —Å–∏—Å—Ç–µ–º–æ–π
        """
        self.loss_function_ref = loss_function
        
        if hasattr(loss_function, 'use_adaptive_loss') and loss_function.use_adaptive_loss:
            self.enhanced_system_available = True
            print("‚úÖ Enhanced Adaptive Loss System –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∞ –∏ –≥–æ—Ç–æ–≤–∞ –∫ –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏")
        else:
            self.enhanced_system_available = False
            print("‚ö†Ô∏è Enhanced Adaptive Loss System –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞ - –∏—Å–ø–æ–ª—å–∑—É–µ–º fallback —Ä–µ–∂–∏–º")
    
    def update_loss_context(self, context: TrainingContext):
        """
        üéØ –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –≤ Enhanced Adaptive Loss System
        
        Args:
            context: –¢–µ–∫—É—â–∏–π –∫–æ–Ω—Ç–µ–∫—Å—Ç –æ–±—É—á–µ–Ω–∏—è
        """
        if self.enhanced_system_available and self.loss_function_ref:
            # –ü–µ—Ä–µ–¥–∞–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç –≤ –∞–¥–∞–ø—Ç–∏–≤–Ω—É—é —Å–∏—Å—Ç–µ–º—É loss —Ñ—É–Ω–∫—Ü–∏–π
            self.loss_function_ref.update_training_context(
                phase=context.phase.value,
                attention_quality=context.attention_quality,
                gate_accuracy=context.gate_accuracy,
                mel_consistency=getattr(context, 'mel_consistency', 0.5),
                gradient_norm=context.gradient_norm,
                loss_stability=context.loss_stability,
                learning_rate=context.learning_rate
            )
            
            # –ó–∞–ø–∏—Å—ã–≤–∞–µ–º –º–µ—Ç—Ä–∏–∫–∏ –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏
            self.performance_metrics.append({
                'step': context.step,
                'phase': context.phase.value,
                'attention_quality': context.attention_quality,
                'gate_accuracy': context.gate_accuracy,
                'enhanced_system_active': True
            })
        
    def get_adaptive_loss_weights(self, context: TrainingContext) -> Dict[str, float]:
        """
        üìä –ü–æ–ª—É—á–µ–Ω–∏–µ –∞–¥–∞–ø—Ç–∏–≤–Ω—ã—Ö –≤–µ—Å–æ–≤ –æ—Ç Enhanced Adaptive Loss System
        
        Args:
            context: –ö–æ–Ω—Ç–µ–∫—Å—Ç –æ–±—É—á–µ–Ω–∏—è
            
        Returns:
            Dict[str, float]: –ê–¥–∞–ø—Ç–∏–≤–Ω—ã–µ –≤–µ—Å–∞ –∏–ª–∏ fallback –≤–µ—Å–∞
        """
        if self.enhanced_system_available and self.loss_function_ref:
            # –û–±–Ω–æ–≤–ª—è–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç –∏ –ø–æ–ª—É—á–∞–µ–º –∞–¥–∞–ø—Ç–∏–≤–Ω—ã–µ –≤–µ—Å–∞
            self.update_loss_context(context)
            adaptive_weights = self.loss_function_ref.get_current_adaptive_weights()
            
            print(f"üéØ –ü–æ–ª—É—á–µ–Ω—ã –∞–¥–∞–ø—Ç–∏–≤–Ω—ã–µ –≤–µ—Å–∞: mel={adaptive_weights.get('mel', 1.0):.3f}, "
                  f"gate={adaptive_weights.get('gate', 1.0):.3f}, "
                  f"guided_attention={adaptive_weights.get('guided_attention', 2.0):.3f}")
            
            return adaptive_weights
        else:
            # Fallback –∫ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–º –≤–µ—Å–∞–º
            return self.compute_adaptive_weights_fallback(context)
    
    def compute_adaptive_weights_fallback(self, context: TrainingContext) -> Dict[str, float]:
        """Fallback –º–µ—Ç–æ–¥ –¥–ª—è –≤—ã—á–∏—Å–ª–µ–Ω–∏—è –∞–¥–∞–ø—Ç–∏–≤–Ω—ã—Ö –≤–µ—Å–æ–≤ (—Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å)"""
        
        # –ê–¥–∞–ø—Ç–∞—Ü–∏—è –≤–µ—Å–æ–≤ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤ loss –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Ñ–∞–∑—ã
        weights = {'mel': 1.0, 'gate': 1.0, 'guided_attention': self.guided_attention_weight}

        if context.phase == TrainingPhase.PRE_ALIGNMENT:
            weights['gate'] = 0.5  # –ú–µ–Ω—å—à–µ –≤–Ω–∏–º–∞–Ω–∏—è –∫ gate –≤ –Ω–∞—á–∞–ª–µ
            weights['guided_attention'] = self.update_guided_attention_weight(context)
        elif context.phase == TrainingPhase.ALIGNMENT_LEARNING:
            weights['gate'] = 1.0  # –ë–∞–ª–∞–Ω—Å
            weights['guided_attention'] = self.update_guided_attention_weight(context)
        elif context.phase == TrainingPhase.REFINEMENT:
            weights['mel'] = 1.2   # –ë–æ–ª—å—à–µ –≤–Ω–∏–º–∞–Ω–∏—è –∫ –∫–∞—á–µ—Å—Ç–≤—É mel
            weights['guided_attention'] = self.guided_attention_weight * 0.8  # –°–Ω–∏–∂–∞–µ–º guided attention
        elif context.phase == TrainingPhase.CONVERGENCE:
            weights['mel'] = 1.5   # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –≤–Ω–∏–º–∞–Ω–∏–µ –∫ —Ñ–∏–Ω–∞–ª—å–Ω–æ–º—É –∫–∞—á–µ—Å—Ç–≤—É
            weights['guided_attention'] = self.guided_attention_weight * 0.5  # –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π guided attention

        return weights
    
    def get_enhanced_loss_diagnostics(self) -> Dict[str, Any]:
        """
        üìä –ü–æ–ª—É—á–µ–Ω–∏–µ –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏ Enhanced Adaptive Loss System
        
        Returns:
            Dict[str, Any]: –î–∏–∞–≥–Ω–æ—Å—Ç–∏—á–µ—Å–∫–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è
        """
        if self.enhanced_system_available and self.loss_function_ref:
            return self.loss_function_ref.get_adaptive_loss_diagnostics()
        else:
            return {
                'system_type': 'fallback',
                'enhanced_system_available': False,
                'integration_history_length': len(self.integration_history),
                'performance_metrics_length': len(self.performance_metrics)
            }

    def compute_dynamic_tversky_params(self, context: TrainingContext) -> Tuple[float, float]:
        """Dynamic Tversky Loss —Å –∞–¥–∞–ø—Ç–∏–≤–Ω—ã–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ –∫–∞—á–µ—Å—Ç–≤–∞ attention"""
        
        # –ê–¥–∞–ø—Ç–∏–≤–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –Ω–∞ –æ—Å–Ω–æ–≤–µ –∫–∞—á–µ—Å—Ç–≤–∞ attention
        if context.attention_quality < 0.3:
            alpha, beta = 0.7, 0.3  # –ë–æ–ª—å—à–µ —à—Ç—Ä–∞—Ñ –∑–∞ FP
        elif context.attention_quality < 0.6:
            alpha, beta = 0.5, 0.5  # –ë–∞–ª–∞–Ω—Å
        else:
            alpha, beta = 0.3, 0.7  # –ë–æ–ª—å—à–µ —à—Ç—Ä–∞—Ñ –∑–∞ FN

        return alpha, beta

class IntelligentParameterManager:
    """–£–º–Ω—ã–π –º–µ–Ω–µ–¥–∂–µ—Ä –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ —Å –ø–ª–∞–≤–Ω—ã–º learning rate scheduling"""

    def __init__(self, initial_lr: float = 1e-3):
        self.base_lr = initial_lr
        self.current_lr = initial_lr
        self.lr_history = []
        self.performance_memory = deque(maxlen=50)
        
        # –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è –¥–ª—è –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏
        self.min_lr_factor = 0.01  # –ú–∏–Ω–∏–º—É–º 1% –æ—Ç –±–∞–∑–æ–≤–æ–≥–æ LR
        self.max_lr_factor = 2.0   # –ú–∞–∫—Å–∏–º—É–º 200% –æ—Ç –±–∞–∑–æ–≤–æ–≥–æ LR
        self.max_lr_change = 0.3   # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∏–∑–º–µ–Ω–µ–Ω–∏–µ –∑–∞ —à–∞–≥ (30%)

    def update_learning_rate(self, context: TrainingContext) -> float:
        """üéØ –£–ú–ù–û–ï –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ learning rate (–≤–º–µ—Å—Ç–æ —Ö–∞–æ—Ç–∏—á–Ω—ã—Ö –∏–∑–º–µ–Ω–µ–Ω–∏–π AutoFixManager)"""

        # –ê–Ω–∞–ª–∏–∑ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏ –∏–∑–º–µ–Ω–µ–Ω–∏—è LR
        lr_adjustment = self._compute_lr_adjustment(context)

        # –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è —Å –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è–º–∏ –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏
        new_lr = self.current_lr * lr_adjustment
        new_lr = np.clip(new_lr, 
                        self.base_lr * self.min_lr_factor, 
                        self.base_lr * self.max_lr_factor)
        
        # üîí –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º —Å–∫–æ—Ä–æ—Å—Ç—å –∏–∑–º–µ–Ω–µ–Ω–∏—è LR (–ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–µ–Ω–∏–µ —Å–∫–∞—á–∫–æ–≤)
        max_change = self.current_lr * self.max_lr_change
        if abs(new_lr - self.current_lr) > max_change:
            if new_lr > self.current_lr:
                new_lr = self.current_lr + max_change
            else:
                new_lr = self.current_lr - max_change

        self.current_lr = new_lr
        self.lr_history.append(new_lr)

        return new_lr

    def _compute_lr_adjustment(self, context: TrainingContext) -> float:
        """–í—ã—á–∏—Å–ª–µ–Ω–∏–µ –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç–∞ –∏–∑–º–µ–Ω–µ–Ω–∏—è LR –Ω–∞ –æ—Å–Ω–æ–≤–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞"""
        adjustment = 1.0

        # –ù–∞ –æ—Å–Ω–æ–≤–µ —Ñ–∞–∑—ã –æ–±—É—á–µ–Ω–∏—è
        if context.phase == TrainingPhase.PRE_ALIGNMENT:
            adjustment *= 1.1  # –ù–µ–º–Ω–æ–≥–æ –≤—ã—à–µ LR –¥–ª—è –Ω–∞—á–∞–ª—å–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è
        elif context.phase == TrainingPhase.CONVERGENCE:
            adjustment *= 0.9  # –ù–µ–º–Ω–æ–≥–æ –Ω–∏–∂–µ LR –¥–ª—è —Å—Ç–∞–±–∏–ª–∏–∑–∞—Ü–∏–∏

        # –ù–∞ –æ—Å–Ω–æ–≤–µ —Ç—Ä–µ–Ω–¥–∞ loss
        if context.loss_trend > 0:  # Loss —Ä–∞—Å—Ç–µ—Ç
            adjustment *= 0.95  # –õ–µ–≥–∫–æ–µ —Å–Ω–∏–∂–µ–Ω–∏–µ
        elif context.loss_trend < -0.1:  # Loss –±—ã—Å—Ç—Ä–æ –ø–∞–¥–∞–µ—Ç  
            adjustment *= 1.05  # –õ–µ–≥–∫–æ–µ —É–≤–µ–ª–∏—á–µ–Ω–∏–µ

        # –ù–∞ –æ—Å–Ω–æ–≤–µ —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏ –≥—Ä–∞–¥–∏–µ–Ω—Ç–æ–≤
        if context.gradient_health < 0.5:  # –ù–µ—Å—Ç–∞–±–∏–ª—å–Ω—ã–µ –≥—Ä–∞–¥–∏–µ–Ω—Ç—ã
            adjustment *= 0.9  # –°–Ω–∏–∂–∞–µ–º LR –¥–ª—è —Å—Ç–∞–±–∏–ª–∏–∑–∞—Ü–∏–∏

        return adjustment

class ContextAwareTrainingManager:
    """
    üß† –ì–ª–∞–≤–Ω—ã–π –º–µ–Ω–µ–¥–∂–µ—Ä –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω–æ-–æ—Å–æ–∑–Ω–∞–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è
    
    –ó–ê–ú–ï–ù–ê –¥–ª—è –¥–µ—Å—Ç—Ä—É–∫—Ç–∏–≤–Ω–æ–≥–æ AutoFixManager:
    ‚ùå AutoFixManager: –ê–≥—Ä–µ—Å—Å–∏–≤–Ω—ã–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è, —Ö–∞–æ—Ç–∏—á–Ω—ã–µ —Å–∫–∞—á–∫–∏, –æ—Ç—Å—É—Ç—Å—Ç–≤–∏–µ –ø–æ–Ω–∏–º–∞–Ω–∏—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
    ‚úÖ ContextAwareTrainingManager: –ü–ª–∞–≤–Ω—ã–µ –∞–¥–∞–ø—Ç–∞—Ü–∏–∏, –ø–æ–Ω–∏–º–∞–Ω–∏–µ —Ñ–∞–∑, –±–µ–∑–æ–ø–∞—Å–Ω—ã–µ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è
    """

    def __init__(self, config: dict):
        self.config = config

        # –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ (–∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –ø–µ—Ä–≤—ã–º –¥–µ–ª–æ–º)
        self.logger = logging.getLogger("ContextAwareTrainer")
        
        # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è –µ—Å–ª–∏ –µ—â–µ –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–æ
        if not self.logger.handlers:
            handler = logging.StreamHandler()
            formatter = logging.Formatter('%(levelname)s: %(message)s')
            handler.setFormatter(formatter)
            self.logger.addHandler(handler)
            self.logger.setLevel(logging.INFO)

        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω—ã—Ö –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤
        self.context_analyzer = ContextAnalyzer(
            history_size=config.get('history_size', 100)
        )
        self.loss_controller = EnhancedLossIntegrator(
            initial_guided_weight=config.get('initial_guided_weight', 4.5)
        )
        self.param_manager = IntelligentParameterManager(
            initial_lr=config.get('initial_lr', 1e-3)
        )
        
        # üõ°Ô∏è –°–ò–°–¢–ï–ú–ê —Å—Ç–∞–±–∏–ª–∏–∑–∞—Ü–∏–∏ –æ–±—É—á–µ–Ω–∏—è
        try:
            from training_stabilization_system import create_training_stabilization_system
            
            # –°–æ–∑–¥–∞–µ–º hparams –¥–ª—è —Å–∏—Å—Ç–µ–º—ã —Å—Ç–∞–±–∏–ª–∏–∑–∞—Ü–∏–∏
            class StabilizationHParams:
                learning_rate = config.get('initial_lr', 1e-3)
                target_gradient_norm = config.get('target_gradient_norm', 2.0)
                max_gradient_norm = config.get('max_gradient_norm', 5.0)
                min_learning_rate = config.get('min_learning_rate', 1e-5)
                stability_window_size = config.get('stability_window_size', 20)
            
            self.stabilization_system = create_training_stabilization_system(StabilizationHParams())
            self.stabilization_available = True
            self.logger.info("‚úÖ Training Stabilization System –∏–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞–Ω–∞")
            
        except ImportError as e:
            self.stabilization_system = None
            self.stabilization_available = False
            self.logger.warning(f"‚ö†Ô∏è Training Stabilization System –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞: {e}")

        # üî• –°–ò–°–¢–ï–ú–ê —É–ª—É—á—à–µ–Ω–∏—è attention mechanisms
        try:
            from advanced_attention_enhancement_system import create_advanced_attention_enhancement_system
            
            # –°–æ–∑–¥–∞–µ–º hparams –¥–ª—è —Å–∏—Å—Ç–µ–º—ã attention enhancement
            class AttentionHParams:
                attention_rnn_dim = config.get('attention_rnn_dim', 1024)
                encoder_embedding_dim = config.get('encoder_embedding_dim', 512)
                attention_dim = config.get('attention_dim', 128)
                attention_num_heads = config.get('attention_num_heads', 8)
                attention_location_n_filters = config.get('attention_location_n_filters', 32)
                attention_location_kernel_size = config.get('attention_location_kernel_size', 31)
                max_training_steps = config.get('max_training_steps', 10000)
                target_attention_diagonality = config.get('target_attention_diagonality', 0.7)
            
            self.attention_enhancement_system = create_advanced_attention_enhancement_system(AttentionHParams())
            self.attention_enhancement_available = True
            self.logger.info("‚úÖ Advanced Attention Enhancement System –∏–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞–Ω–∞")
            
        except ImportError as e:
            self.attention_enhancement_system = None
            self.attention_enhancement_available = False
            self.logger.warning(f"‚ö†Ô∏è Advanced Attention Enhancement System –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞: {e}")

        # –°–æ—Å—Ç–æ—è–Ω–∏–µ —Å–∏—Å—Ç–µ–º—ã
        self.current_context = None
        self.decision_history = []
        self.intervention_count = 0
        
        # –ë–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å –∏ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥
        self.last_intervention_time = 0
        self.intervention_cooldown = 10  # 10 —à–∞–≥–æ–≤ –º–µ–∂–¥—É –≤–º–µ—à–∞—Ç–µ–ª—å—Å—Ç–≤–∞–º–∏
        self.emergency_mode = False
            
        self.logger.info("üß† Context-Aware Training Manager –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω (–∑–∞–º–µ–Ω–∞ AutoFixManager)")

    def analyze_and_adapt(self, step: int, metrics: Dict[str, float], 
                         model: Optional[nn.Module] = None, 
                         optimizer: Optional[torch.optim.Optimizer] = None) -> Dict[str, float]:
        """
        üéØ –ì–ª–∞–≤–Ω—ã–π –º–µ—Ç–æ–¥ –∞–Ω–∞–ª–∏–∑–∞ –∏ –∞–¥–∞–ø—Ç–∞—Ü–∏–∏ (–∑–∞–º–µ–Ω–∞ AutoFixManager.analyze_and_fix)
        
        –û—Ç–ª–∏—á–∏—è –æ—Ç AutoFixManager:
        - –ü–ª–∞–≤–Ω—ã–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è –≤–º–µ—Å—Ç–æ –∞–≥—Ä–µ—Å—Å–∏–≤–Ω—ã—Ö
        - –ü–æ–Ω–∏–º–∞–Ω–∏–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –∏ —Ñ–∞–∑ –æ–±—É—á–µ–Ω–∏—è
        - –ë–µ–∑–æ–ø–∞—Å–Ω—ã–µ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è –Ω–∞ –∏–∑–º–µ–Ω–µ–Ω–∏—è
        - –ú–µ—Ö–∞–Ω–∏–∑–º—ã –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–µ–Ω–∏—è cascade failures
        """
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ cooldown (–ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–µ–Ω–∏–µ —Å–ª–∏—à–∫–æ–º —á–∞—Å—Ç—ã—Ö –≤–º–µ—à–∞—Ç–µ–ª—å—Å—Ç–≤)
        if step - self.last_intervention_time < self.intervention_cooldown:
            return self._get_current_parameters()
        
        try:
            # 1. –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫ –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–∞
            self.context_analyzer.update_metrics(
                loss=metrics.get('loss', 0.0),
                attention_diag=metrics.get('attention_diagonality', 0.0),
                grad_norm=metrics.get('grad_norm', 0.0),
                gate_accuracy=metrics.get('gate_accuracy', 0.0)
            )
            
            # 2. –ê–Ω–∞–ª–∏–∑ —Ç–µ–∫—É—â–µ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
            context = self._create_training_context(step, metrics)
            self.current_context = context
            
            # 3. –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏ –∞–¥–∞–ø—Ç–∞—Ü–∏–∏
            need_adaptation = self._assess_adaptation_need(context)
            
            if not need_adaptation:
                return self._get_current_parameters()
            
            # 4. –£–º–Ω–∞—è –∞–¥–∞–ø—Ç–∞—Ü–∏—è –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
            adaptations = self._perform_intelligent_adaptations(context, model, optimizer)
            
            # 5. –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –∏ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
            if adaptations:
                self.intervention_count += 1
                self.last_intervention_time = step
                self._log_adaptations(step, context, adaptations)
            
            return adaptations
            
        except Exception as e:
            self.logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≤ Context-Aware Manager: {e}")
            return self._get_current_parameters()

    def _create_training_context(self, step: int, metrics: Dict[str, float]) -> TrainingContext:
        """–°–æ–∑–¥–∞–Ω–∏–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –æ–±—É—á–µ–Ω–∏—è –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ç–µ–∫—É—â–∏—Ö –º–µ—Ç—Ä–∏–∫"""
        
        phase = self.context_analyzer.analyze_phase()
        stability_index = self.context_analyzer.get_stability_index()
        
        # –í—ã—á–∏—Å–ª–µ–Ω–∏–µ —Ç—Ä–µ–Ω–¥–∞ loss
        loss_trend = self.context_analyzer._calculate_trend(
            list(self.context_analyzer.loss_history)
        )
        
        # –í—ã—á–∏—Å–ª–µ–Ω–∏–µ –∑–¥–æ—Ä–æ–≤—å—è –≥—Ä–∞–¥–∏–µ–Ω—Ç–æ–≤
        recent_grads = list(self.context_analyzer.gradient_history)[-10:]
        gradient_health = 1.0 / (1.0 + np.std(recent_grads)) if recent_grads else 0.5
        
        return TrainingContext(
            phase=phase,
            step=step,
            epoch=metrics.get('epoch', 0),
            loss_trend=loss_trend,
            attention_quality=metrics.get('attention_diagonality', 0.0),
            gradient_health=gradient_health,
            learning_rate=self.param_manager.current_lr,
            convergence_score=stability_index,
            stability_index=stability_index,
            time_since_improvement=step - self.context_analyzer.last_improvement_step,
            attention_diagonality=metrics.get('attention_diagonality', 0.0),
            gate_accuracy=metrics.get('gate_accuracy', 0.0),
            mel_loss=metrics.get('mel_loss', 0.0),
            gate_loss=metrics.get('gate_loss', 0.0),
            guided_attention_loss=metrics.get('guided_attention_loss', 0.0)
        )

    def _assess_adaptation_need(self, context: TrainingContext) -> bool:
        """–û—Ü–µ–Ω–∫–∞ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏ –∞–¥–∞–ø—Ç–∞—Ü–∏–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤"""
        
        # –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ —É—Å–ª–æ–≤–∏—è, —Ç—Ä–µ–±—É—é—â–∏–µ –≤–º–µ—à–∞—Ç–µ–ª—å—Å—Ç–≤–∞
        critical_attention = context.attention_quality < 0.05
        poor_stability = context.stability_index < 0.3
        long_stagnation = context.time_since_improvement > 50
        
        # –ú—è–≥–∫–∏–µ —É—Å–ª–æ–≤–∏—è –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏
        suboptimal_attention = context.attention_quality < 0.3
        learning_opportunity = context.loss_trend > 0.01
        
        return critical_attention or poor_stability or long_stagnation or (suboptimal_attention and learning_opportunity)

    def _perform_intelligent_adaptations(self, context: TrainingContext, 
                                       model: Optional[nn.Module], 
                                       optimizer: Optional[torch.optim.Optimizer]) -> Dict[str, float]:
        """–í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ —É–º–Ω—ã—Ö –∞–¥–∞–ø—Ç–∞—Ü–∏–π –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ —Å –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–µ–π —Å–∏—Å—Ç–µ–º—ã —Å—Ç–∞–±–∏–ª–∏–∑–∞—Ü–∏–∏"""
        
        adaptations = {}
        
        # üõ°Ô∏è 1. –°–¢–ê–ë–ò–õ–ò–ó–ê–¶–ò–Ø –û–ë–£–ß–ï–ù–ò–Ø (–µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–Ω–∞)
        if self.stabilization_available and model and optimizer:
            # –°–æ–∑–¥–∞–µ–º mock loss –¥–ª—è —Å–∏—Å—Ç–µ–º—ã —Å—Ç–∞–±–∏–ª–∏–∑–∞—Ü–∏–∏
            mock_loss = torch.tensor(context.mel_loss, requires_grad=True)
            
            stabilization_report = self.stabilization_system.stabilize_training_step(
                model=model,
                optimizer=optimizer,
                loss=mock_loss,
                attention_quality=context.attention_quality
            )
            
            # –î–æ–±–∞–≤–ª—è–µ–º –æ—Ç—á–µ—Ç —Å—Ç–∞–±–∏–ª–∏–∑–∞—Ü–∏–∏ –∫ –∞–¥–∞–ø—Ç–∞—Ü–∏—è–º
            adaptations['stabilization_report'] = {
                'stability_level': stabilization_report['stability_level'],
                'emergency_activated': stabilization_report['emergency_measures'] is not None,
                'lr_adjusted': stabilization_report['lr_adjustment']['old'] != stabilization_report['lr_adjustment']['new']
            }
            
            # –û–±–Ω–æ–≤–ª—è–µ–º learning rate –∏–∑ —Å–∏—Å—Ç–µ–º—ã —Å—Ç–∞–±–∏–ª–∏–∑–∞—Ü–∏–∏
            stabilized_lr = stabilization_report['lr_adjustment']['new']
            if abs(stabilized_lr - context.learning_rate) > context.learning_rate * 0.01:
                adaptations['learning_rate'] = stabilized_lr
                self.param_manager.current_lr = stabilized_lr
        
        # üî• 2. ATTENTION ENHANCEMENT (–µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–Ω–∞)
        if self.attention_enhancement_available and model:
            attention_adaptations = self._apply_attention_enhancements(context, model)
            adaptations.update(attention_adaptations)
        
        # 3. –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–∞—è –∞–¥–∞–ø—Ç–∞—Ü–∏—è learning rate (–µ—Å–ª–∏ —Å—Ç–∞–±–∏–ª–∏–∑–∞—Ü–∏—è –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞)
        if not self.stabilization_available:
            new_lr = self.param_manager.update_learning_rate(context)
            if optimizer and abs(new_lr - context.learning_rate) > context.learning_rate * 0.05:
                # –û–±–Ω–æ–≤–ª—è–µ–º LR —Ç–æ–ª—å–∫–æ –ø—Ä–∏ –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω–æ–º –∏–∑–º–µ–Ω–µ–Ω–∏–∏ (>5%)
                for param_group in optimizer.param_groups:
                    param_group['lr'] = new_lr
                adaptations['learning_rate'] = new_lr
        
        # 3. –ê–¥–∞–ø—Ç–∞—Ü–∏—è –≤–µ—Å–æ–≤ loss —Ñ—É–Ω–∫—Ü–∏–π —á–µ—Ä–µ–∑ Enhanced Adaptive Loss System
        loss_weights = self.loss_controller.get_adaptive_loss_weights(context)
        adaptations.update(loss_weights)
        
        # 4. –ê–¥–∞–ø—Ç–∞—Ü–∏—è –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ Tversky Loss
        alpha, beta = self.loss_controller.compute_dynamic_tversky_params(context)
        adaptations['tversky_alpha'] = alpha
        adaptations['tversky_beta'] = beta
        
        return adaptations

    def _get_current_parameters(self) -> Dict[str, float]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Ç–µ–∫—É—â–∏—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ —Å–∏—Å—Ç–µ–º—ã"""
        return {
            'learning_rate': self.param_manager.current_lr,
            'guided_attention_weight': self.loss_controller.guided_attention_weight,
            'mel_weight': self.loss_controller.mel_weight,
            'gate_weight': self.loss_controller.gate_weight
        }

    def _log_adaptations(self, step: int, context: TrainingContext, adaptations: Dict[str, float]):
        """–õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –ø—Ä–∏–º–µ–Ω–µ–Ω–Ω—ã—Ö –∞–¥–∞–ø—Ç–∞—Ü–∏–π"""
        
        self.logger.info(
            f"üéØ Step {step}: Context-Aware Adaptation "
            f"(Phase: {context.phase.value}, "
            f"Attention: {context.attention_quality:.3f}, "
            f"Stability: {context.stability_index:.3f})"
        )
        
        for param, value in adaptations.items():
            if param in ['learning_rate', 'guided_attention_weight']:
                self.logger.info(f"  üìä {param}: {value:.2e}")
        
        # –î–æ–±–∞–≤–ª—è–µ–º –≤ –∏—Å—Ç–æ—Ä–∏—é —Ä–µ—à–µ–Ω–∏–π
        decision = {
            'step': step,
            'phase': context.phase.value,
            'adaptations': adaptations,
            'context_metrics': {
                'attention_quality': context.attention_quality,
                'stability_index': context.stability_index,
                'loss_trend': context.loss_trend
            }
        }
        self.decision_history.append(decision)

    def get_statistics(self) -> Dict[str, any]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ —Ä–∞–±–æ—Ç—ã —Å–∏—Å—Ç–µ–º—ã"""
        stats = {
            'total_interventions': self.intervention_count,
            'current_phase': self.current_context.phase.value if self.current_context else 'unknown',
            'current_lr': self.param_manager.current_lr,
            'current_guided_weight': self.loss_controller.guided_attention_weight,
            'stability_index': self.current_context.stability_index if self.current_context else 0.0,
            'recent_decisions': self.decision_history[-5:] if self.decision_history else []
        }
        
        # üõ°Ô∏è –î–æ–±–∞–≤–ª—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É —Å–∏—Å—Ç–µ–º—ã —Å—Ç–∞–±–∏–ª–∏–∑–∞—Ü–∏–∏
        if self.stabilization_available:
            stats['stabilization_system'] = self.stabilization_system.get_system_diagnostics()
        
        return stats
    
    def get_stabilization_diagnostics(self) -> Dict[str, Any]:
        """
        üõ°Ô∏è –ü–æ–ª—É—á–µ–Ω–∏–µ –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏ —Å–∏—Å—Ç–µ–º—ã —Å—Ç–∞–±–∏–ª–∏–∑–∞—Ü–∏–∏ –æ–±—É—á–µ–Ω–∏—è
        
        Returns:
            Dict[str, Any]: –î–∏–∞–≥–Ω–æ—Å—Ç–∏—á–µ—Å–∫–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è —Å–∏—Å—Ç–µ–º—ã —Å—Ç–∞–±–∏–ª–∏–∑–∞—Ü–∏–∏
        """
        if self.stabilization_available:
            return self.stabilization_system.get_system_diagnostics()
        else:
            return {
                'available': False,
                'message': 'Training Stabilization System –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞'
            }

    def save_state(self, filepath: str):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Å–æ—Å—Ç–æ—è–Ω–∏—è –º–µ–Ω–µ–¥–∂–µ—Ä–∞"""
        state = {
            'context_analyzer': self.context_analyzer,
            'loss_controller': self.loss_controller,
            'param_manager': self.param_manager,
            'decision_history': self.decision_history,
            'intervention_count': self.intervention_count
        }

        with open(filepath, 'wb') as f:
            pickle.dump(state, f)
        
        self.logger.info(f"üíæ –°–æ—Å—Ç–æ—è–Ω–∏–µ Context-Aware Manager —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ: {filepath}")

    def load_state(self, filepath: str):
        """–ó–∞–≥—Ä—É–∑–∫–∞ —Å–æ—Å—Ç–æ—è–Ω–∏—è –º–µ–Ω–µ–¥–∂–µ—Ä–∞"""
        try:
            with open(filepath, 'rb') as f:
                state = pickle.load(f)

            self.context_analyzer = state['context_analyzer']
            self.loss_controller = state['loss_controller'] 
            self.param_manager = state['param_manager']
            self.decision_history = state['decision_history']
            self.intervention_count = state.get('intervention_count', 0)
            
            self.logger.info(f"üìÅ –°–æ—Å—Ç–æ—è–Ω–∏–µ Context-Aware Manager –∑–∞–≥—Ä—É–∂–µ–Ω–æ: {filepath}")
        except Exception as e:
            self.logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ —Å–æ—Å—Ç–æ—è–Ω–∏—è: {e}")

    def integrate_with_loss_function(self, loss_function):
        """
        üîó –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å loss —Ñ—É–Ω–∫—Ü–∏–µ–π –¥–ª—è —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è guided attention –∏ Enhanced Adaptive Loss System
        
        Args:
            loss_function: –≠–∫–∑–µ–º–ø–ª—è—Ä Tacotron2Loss –∏–ª–∏ —Å–æ–≤–º–µ—Å—Ç–∏–º–æ–π loss —Ñ—É–Ω–∫—Ü–∏–∏
        """
        try:
            # –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è guided attention (—Å—É—â–µ—Å—Ç–≤—É—é—â–∞—è —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å)
            if hasattr(loss_function, 'set_context_aware_manager'):
                loss_function.set_context_aware_manager(self)
                self.logger.info("‚úÖ Context-Aware Manager –∏–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞–Ω —Å guided attention —Å–∏—Å—Ç–µ–º–æ–π")
            else:
                self.logger.warning("‚ö†Ô∏è Loss —Ñ—É–Ω–∫—Ü–∏—è –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç guided attention –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—é")
            
            # üéØ –ù–û–í–ê–Ø –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å Enhanced Adaptive Loss System
            if hasattr(loss_function, 'integrate_with_context_aware_manager'):
                loss_function.integrate_with_context_aware_manager(self)
                
            # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Å—Å—ã–ª–∫—É –≤ EnhancedLossIntegrator
            self.loss_controller.set_loss_function_reference(loss_function)
            
            self.logger.info("‚úÖ –ü–æ–ª–Ω–∞—è –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å Enhanced Adaptive Loss System –∑–∞–≤–µ—Ä—à–µ–Ω–∞")
                
        except Exception as e:
            self.logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ —Å loss —Ñ—É–Ω–∫—Ü–∏–µ–π: {e}")

    def get_guided_attention_recommendations(self, context: TrainingContext) -> Dict[str, float]:
        """
        üéØ –ü–æ–ª—É—á–µ–Ω–∏–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π –¥–ª—è guided attention –Ω–∞ –æ—Å–Ω–æ–≤–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
        
        Args:
            context: –¢–µ–∫—É—â–∏–π –∫–æ–Ω—Ç–µ–∫—Å—Ç –æ–±—É—á–µ–Ω–∏—è
            
        Returns:
            Dict[str, float]: –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º guided attention
        """
        recommendations = {}
        
        # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ –≤–µ—Å—É guided attention
        if context.attention_quality < 0.02:
            # –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏ –Ω–∏–∑–∫–æ–µ attention - —ç–∫—Å—Ç—Ä–µ–Ω–Ω—ã–π —Ä–µ–∂–∏–º
            recommendations['suggested_weight'] = 25.0
            recommendations['emergency_mode'] = True
        elif context.attention_quality < 0.1:
            # –ù–∏–∑–∫–æ–µ attention - —É–≤–µ–ª–∏—á–∏–≤–∞–µ–º –≤–µ—Å
            recommendations['suggested_weight'] = min(self.loss_controller.guided_attention_weight * 1.5, 15.0)
            recommendations['emergency_mode'] = False
        elif context.attention_quality > 0.7:
            # –•–æ—Ä–æ—à–µ–µ attention - –º–æ–∂–µ–º —Å–Ω–∏–∑–∏—Ç—å –≤–µ—Å
            recommendations['suggested_weight'] = max(self.loss_controller.guided_attention_weight * 0.8, 1.0)
            recommendations['emergency_mode'] = False
        else:
            # –ù–æ—Ä–º–∞–ª—å–Ω–æ–µ attention - —Ç–µ–∫—É—â–∏–π –≤–µ—Å
            recommendations['suggested_weight'] = self.loss_controller.guided_attention_weight
            recommendations['emergency_mode'] = False
        
        # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ sigma
        if context.phase == TrainingPhase.PRE_ALIGNMENT:
            recommendations['suggested_sigma'] = 0.1  # –£–∑–∫–∞—è –¥–ª—è —Ç–æ—á–Ω–æ–≥–æ alignment
        elif context.phase == TrainingPhase.ALIGNMENT_LEARNING:
            recommendations['suggested_sigma'] = 0.4  # –®–∏—Ä–æ–∫–∞—è –¥–ª—è –≥–∏–±–∫–æ—Å—Ç–∏
        elif context.phase == TrainingPhase.REFINEMENT:
            recommendations['suggested_sigma'] = 0.25  # –°—Ä–µ–¥–Ω—è—è –¥–ª—è –±–∞–ª–∞–Ω—Å–∞
        else:  # CONVERGENCE
            recommendations['suggested_sigma'] = 0.15  # –£–∑–∫–∞—è –¥–ª—è —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏
        
        return recommendations

    def _apply_attention_enhancements(self, context: TrainingContext, model) -> Dict[str, Any]:
        """üî• –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ —É–ª—É—á—à–µ–Ω–∏–π attention mechanisms"""
        adaptations = {}
        
        if not self.attention_enhancement_available:
            return adaptations
        
        try:
            # –ü–æ–ª—É—á–∞–µ–º attention diagnostics –∫–æ–º–ø–æ–Ω–µ–Ω—Ç
            attention_diagnostics = self.attention_enhancement_system['attention_diagnostics']
            progressive_trainer = self.attention_enhancement_system['progressive_trainer']
            regularization_system = self.attention_enhancement_system['regularization_system']
            
            # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º attention quality (—Ç—Ä–µ–±—É–µ—Ç attention weights –∏–∑ –º–æ–¥–µ–ª–∏)
            # –í —Ä–µ–∞–ª—å–Ω–æ–π —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏ –Ω—É–∂–Ω–æ –∏–∑–≤–ª–µ—á—å attention weights –∏–∑ –º–æ–¥–µ–ª–∏
            # –ó–¥–µ—Å—å —Å–æ–∑–¥–∞–µ–º mock attention –¥–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏
            mock_attention = torch.rand(2, 100, 80)  # [B, T_out, T_in]
            
            # –ê–Ω–∞–ª–∏–∑ attention quality
            attention_metrics = attention_diagnostics.analyze_attention_quality(mock_attention)
            
            # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Ñ–∞–∑—ã training
            current_phase = progressive_trainer.update_training_phase(
                context.step, attention_metrics
            )
            
            # –ü–æ–ª—É—á–µ–Ω–∏–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π –ø–æ –∫–æ—Ä—Ä–µ–∫—Ü–∏–∏
            correction_suggestions = attention_diagnostics.get_correction_suggestions(attention_metrics)
            
            # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ regularization weights
            regularization_system.update_regularization_weights(attention_metrics)
            
            # –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –∫–æ—Ä—Ä–µ–∫—Ü–∏–π –∫ –º–æ–¥–µ–ª–∏ (–µ—Å–ª–∏ –≤–æ–∑–º–æ–∂–Ω–æ)
            if hasattr(model, 'decoder') and hasattr(model.decoder, 'attention_layer'):
                # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ complexity –≤ multi-head attention –µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–Ω–æ
                if hasattr(model.decoder.attention_layer, 'update_complexity'):
                    model.decoder.attention_layer.update_complexity(
                        attention_metrics.diagonality
                    )
            
            adaptations['attention_enhancements'] = {
                'attention_quality': {
                    'diagonality': attention_metrics.diagonality,
                    'monotonicity': attention_metrics.monotonicity,
                    'focus': attention_metrics.focus,
                    'phase': attention_metrics.phase.value
                },
                'training_phase': current_phase.value,
                'corrections_applied': len(correction_suggestions),
                'suggestions': correction_suggestions
            }
            
            self.logger.info(f"üî• Attention Enhancement: diagonality={attention_metrics.diagonality:.3f}, "
                           f"phase={current_phase.value}, corrections={len(correction_suggestions)}")
            
        except Exception as e:
            self.logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≤ Attention Enhancement System: {e}")
            adaptations['attention_enhancements'] = {'error': str(e)}
        
        return adaptations

    def get_attention_enhancement_diagnostics(self) -> Dict[str, Any]:
        """üî• –ü–æ–ª—É—á–∏—Ç—å –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫—É —Å–∏—Å—Ç–µ–º—ã —É–ª—É—á—à–µ–Ω–∏—è attention"""
        if self.attention_enhancement_available and self.attention_enhancement_system:
            diagnostics = {}
            
            # –î–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ attention diagnostics
            attention_diagnostics = self.attention_enhancement_system['attention_diagnostics']
            diagnostics['attention_diagnostics'] = {
                'target_diagonality': attention_diagnostics.target_diagonality,
                'history_length': len(attention_diagnostics.diagonality_history),
                'recent_diagonality': attention_diagnostics.diagonality_history[-5:] if attention_diagnostics.diagonality_history else []
            }
            
            # –î–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ progressive trainer
            progressive_trainer = self.attention_enhancement_system['progressive_trainer']
            diagnostics['progressive_trainer'] = {
                'current_step': progressive_trainer.current_step,
                'current_phase': progressive_trainer.current_phase.value,
                'max_steps': progressive_trainer.max_steps
            }
            
            # –î–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ regularization system
            regularization_system = self.attention_enhancement_system['regularization_system']
            diagnostics['regularization_system'] = {
                'entropy_weight': regularization_system.entropy_weight,
                'monotonic_weight': regularization_system.monotonic_weight,
                'temporal_weight': regularization_system.temporal_weight,
                'diversity_weight': regularization_system.diversity_weight
            }
            
            return diagnostics
        
        return {'status': 'unavailable'}

# –§—É–Ω–∫—Ü–∏—è –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –º–µ–Ω–µ–¥–∂–µ—Ä–∞ —Å —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ–º–æ–π –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–µ–π
def create_context_aware_manager(hparams) -> ContextAwareTrainingManager:
    """–°–æ–∑–¥–∞–Ω–∏–µ Context-Aware Training Manager —Å –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–π –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–µ–π –¥–ª—è Tacotron2"""
    
    config = {
        'initial_lr': getattr(hparams, 'learning_rate', 1e-3),
        'history_size': 100,
        'initial_guided_weight': getattr(hparams, 'guide_loss_weight', 4.5),
        'logging_level': 'INFO'
    }
    
    return ContextAwareTrainingManager(config)

if __name__ == "__main__":
    # –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
    config = {
        'initial_lr': 1e-3,
        'history_size': 100,
        'initial_guided_weight': 4.5
    }
    
    manager = ContextAwareTrainingManager(config)
    print("üß† Context-Aware Training Manager —Å–æ–∑–¥–∞–Ω —É—Å–ø–µ—à–Ω–æ!")
    print(f"üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞: {manager.get_statistics()}") 