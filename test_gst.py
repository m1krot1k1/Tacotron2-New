#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
–¢–µ—Å—Ç GST (Global Style Tokens) —Å–∏—Å—Ç–µ–º—ã
–ü—Ä–æ–≤–µ—Ä—è–µ—Ç —Ä–∞–±–æ—Ç–æ—Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç—å GST –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤
"""

import torch
import numpy as np
from hparams import create_hparams
from model import Tacotron2
from gst import GST, TPSEGST, ReferenceEncoder, STL
import warnings
warnings.filterwarnings('ignore')

def test_gst_components():
    """–¢–µ—Å—Ç–∏—Ä—É–µ—Ç –æ—Ç–¥–µ–ª—å–Ω—ã–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã GST"""
    print("üé≠ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤ GST...")
    
    hparams = create_hparams()
    
    # –¢–µ—Å—Ç ReferenceEncoder
    print("\n1Ô∏è‚É£ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ ReferenceEncoder...")
    try:
        ref_encoder = ReferenceEncoder(hparams)
        # –°–æ–∑–¥–∞–µ–º —Ç–µ—Å—Ç–æ–≤—ã–µ mel-—Å–ø–µ–∫—Ç—Ä–æ–≥—Ä–∞–º–º—ã
        batch_size = 2
        mel_length = 100
        mel_channels = hparams.n_mel_channels
        test_mels = torch.randn(batch_size, mel_length, mel_channels)
        
        output = ref_encoder(test_mels)
        print(f"   ‚úÖ ReferenceEncoder —Ä–∞–±–æ—Ç–∞–µ—Ç")
        print(f"   üìä –í—Ö–æ–¥: {test_mels.shape} -> –í—ã—Ö–æ–¥: {output.shape}")
        print(f"   üìè –û–∂–∏–¥–∞–µ–º—ã–π —Ä–∞–∑–º–µ—Ä –≤—ã—Ö–æ–¥–∞: [{batch_size}, {hparams.ref_enc_gru_size}]")
        
    except Exception as e:
        print(f"   ‚ùå –û—à–∏–±–∫–∞ ReferenceEncoder: {e}")
        return False
    
    # –¢–µ—Å—Ç STL
    print("\n2Ô∏è‚É£ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ STL (Style Token Layer)...")
    try:
        stl = STL(hparams)
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –≤—ã—Ö–æ–¥ ReferenceEncoder –∫–∞–∫ –≤—Ö–æ–¥ –¥–ª—è STL
        test_input = torch.randn(batch_size, hparams.ref_enc_gru_size)
        
        style_output = stl(test_input)
        print(f"   ‚úÖ STL —Ä–∞–±–æ—Ç–∞–µ—Ç")
        print(f"   üìä –í—Ö–æ–¥: {test_input.shape} -> –í—ã—Ö–æ–¥: {style_output.shape}")
        print(f"   üìè –û–∂–∏–¥–∞–µ–º—ã–π —Ä–∞–∑–º–µ—Ä –≤—ã—Ö–æ–¥–∞: [{batch_size}, 1, {hparams.token_embedding_size}]")
        
    except Exception as e:
        print(f"   ‚ùå –û—à–∏–±–∫–∞ STL: {e}")
        return False
    
    # –¢–µ—Å—Ç –ø–æ–ª–Ω–æ–≥–æ GST
    print("\n3Ô∏è‚É£ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–æ–ª–Ω–æ–≥–æ GST...")
    try:
        gst = GST(hparams)
        test_mels = torch.randn(batch_size, mel_length, mel_channels)
        
        gst_output = gst(test_mels)
        print(f"   ‚úÖ GST —Ä–∞–±–æ—Ç–∞–µ—Ç")
        print(f"   üìä –í—Ö–æ–¥: {test_mels.shape} -> –í—ã—Ö–æ–¥: {gst_output.shape}")
        print(f"   üìè –û–∂–∏–¥–∞–µ–º—ã–π —Ä–∞–∑–º–µ—Ä –≤—ã—Ö–æ–¥–∞: [{batch_size}, 1, {hparams.token_embedding_size}]")
        
    except Exception as e:
        print(f"   ‚ùå –û—à–∏–±–∫–∞ GST: {e}")
        return False
    
    # –¢–µ—Å—Ç TPSEGST
    print("\n4Ô∏è‚É£ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ TPSEGST...")
    try:
        tpse_gst = TPSEGST(hparams)
        # –°–æ–∑–¥–∞–µ–º —Ç–µ—Å—Ç–æ–≤—ã–µ encoder outputs
        encoder_outputs = torch.randn(batch_size, 50, hparams.encoder_embedding_dim)
        
        tpse_output = tpse_gst(encoder_outputs)
        print(f"   ‚úÖ TPSEGST —Ä–∞–±–æ—Ç–∞–µ—Ç")
        print(f"   üìä –í—Ö–æ–¥: {encoder_outputs.shape} -> –í—ã—Ö–æ–¥: {tpse_output.shape}")
        print(f"   üìè –û–∂–∏–¥–∞–µ–º—ã–π —Ä–∞–∑–º–µ—Ä –≤—ã—Ö–æ–¥–∞: [{batch_size}, 1, {hparams.token_embedding_size}]")
        
    except Exception as e:
        print(f"   ‚ùå –û—à–∏–±–∫–∞ TPSEGST: {e}")
        return False
    
    return True

def test_tacotron2_with_gst():
    """–¢–µ—Å—Ç–∏—Ä—É–µ—Ç Tacotron2 —Å –≤–∫–ª—é—á–µ–Ω–Ω—ã–º GST"""
    print("\nü§ñ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ Tacotron2 —Å GST...")
    
    hparams = create_hparams()
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    
    try:
        # –°–æ–∑–¥–∞–µ–º –º–æ–¥–µ–ª—å —Å GST
        model = Tacotron2(hparams).to(device)
        model.eval()  # –°—Ç–∞–≤–∏–º –≤ eval —Ä–µ–∂–∏–º –¥–ª—è BatchNorm
        print(f"   ‚úÖ –ú–æ–¥–µ–ª—å Tacotron2 —Å–æ–∑–¥–∞–Ω–∞ —Å GST")
        print(f"   üìä GST –∞–∫—Ç–∏–≤–µ–Ω: {model.use_gst}")
        print(f"   üéØ –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ style tokens: {hparams.token_num}")
        print(f"   üìè –†–∞–∑–º–µ—Ä token embedding: {hparams.token_embedding_size}")
        
        # –¢–µ—Å—Ç–∏—Ä—É–µ–º forward pass
        batch_size = 2
        text_length = 20
        mel_length = 100
        
        # –°–æ–∑–¥–∞–µ–º —Ç–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ –Ω–∞ —Ç–æ–º –∂–µ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–µ
        text_inputs = torch.randint(0, hparams.n_symbols, (batch_size, text_length)).to(device)
        text_lengths = torch.tensor([text_length, text_length-2]).to(device)
        mels = torch.randn(batch_size, hparams.n_mel_channels, mel_length).to(device)
        output_lengths = torch.tensor([mel_length, mel_length-10]).to(device)
        
        # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –≤—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –∫–∞–∫ –≤ —Ä–µ–∞–ª—å–Ω–æ–º –æ–±—É—á–µ–Ω–∏–∏
        inputs = (text_inputs, text_lengths, mels, text_length, output_lengths)
        
        print(f"\n   üîÑ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ forward pass...")
        with torch.no_grad():
            outputs = model(inputs)
            
        print(f"   ‚úÖ Forward pass —É—Å–ø–µ—à–µ–Ω")
        print(f"   üìä –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤—ã—Ö–æ–¥–æ–≤: {len(outputs)}")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ GST embedding –¥–æ–±–∞–≤–ª–µ–Ω
        if len(outputs) > 6 and outputs[6] is not None:  # gst_outputs
            print(f"   üé≠ GST outputs: {outputs[6].shape}")
        if len(outputs) > 5 and outputs[5] is not None:  # tpse_gst_outputs  
            print(f"   üîß TPSE GST outputs: {outputs[5].shape}")
            
    except Exception as e:
        print(f"   ‚ùå –û—à–∏–±–∫–∞ Tacotron2 —Å GST: {e}")
        return False
    
    return True

def test_gst_inference_modes():
    """–¢–µ—Å—Ç–∏—Ä—É–µ—Ç —Ä–∞–∑–ª–∏—á–Ω—ã–µ —Ä–µ–∂–∏–º—ã inference —Å GST"""
    print("\nüéØ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–µ–∂–∏–º–æ–≤ inference —Å GST...")
    
    hparams = create_hparams()
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    model = Tacotron2(hparams).to(device)
    model.eval()  # –°—Ç–∞–≤–∏–º –≤ eval —Ä–µ–∂–∏–º –¥–ª—è BatchNorm
    
    batch_size = 1
    text_length = 15
    text_inputs = torch.randint(0, hparams.n_symbols, (batch_size, text_length)).to(device)
    
    try:
        # 1. –û–±—ã—á–Ω—ã–π inference –±–µ–∑ reference mel
        print("\n   1Ô∏è‚É£ –û–±—ã—á–Ω—ã–π inference (TPSE GST)...")
        with torch.no_grad():
            outputs1 = model.inference(text_inputs)
        print(f"   ‚úÖ –û–±—ã—á–Ω—ã–π inference —Ä–∞–±–æ—Ç–∞–µ—Ç")
        
        # 2. Inference —Å reference mel
        print("\n   2Ô∏è‚É£ Inference —Å reference mel...")
        ref_mel = torch.randn(1, hparams.n_mel_channels, 50).to(device)
        with torch.no_grad():
            outputs2 = model.inference(text_inputs, reference_mel=ref_mel)
        print(f"   ‚úÖ Reference mel inference —Ä–∞–±–æ—Ç–∞–µ—Ç")
        
        # 3. Inference —Å –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–º token
        print("\n   3Ô∏è‚É£ Inference —Å –≤—ã–±—Ä–∞–Ω–Ω—ã–º style token...")
        token_idx = 3  # –í—ã–±–∏—Ä–∞–µ–º 4-–π —Å—Ç–∏–ª—å (–∏–Ω–¥–µ–∫—Å–∞—Ü–∏—è —Å 0)
        with torch.no_grad():
            outputs3 = model.inference(text_inputs, token_idx=token_idx)
        print(f"   ‚úÖ Style token inference —Ä–∞–±–æ—Ç–∞–µ—Ç")
        
        # 4. Inference —Å –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ–º
        print("\n   4Ô∏è‚É£ Inference —Å –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ–º —Å—Ç–∏–ª—è...")
        with torch.no_grad():
            outputs4 = model.inference(text_inputs, token_idx=token_idx, scale=2.0)
        print(f"   ‚úÖ –ú–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–Ω—ã–π inference —Ä–∞–±–æ—Ç–∞–µ—Ç")
        
        print(f"\n   üìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤—Å–µ—Ö —Ä–µ–∂–∏–º–æ–≤ –ø–æ–ª—É—á–µ–Ω—ã —É—Å–ø–µ—à–Ω–æ")
        
    except Exception as e:
        print(f"   ‚ùå –û—à–∏–±–∫–∞ inference —Ä–µ–∂–∏–º–æ–≤: {e}")
        return False
    
    return True

def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è"""
    print("=" * 60)
    print("üé≠ –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï GST (GLOBAL STYLE TOKENS)")
    print("=" * 60)
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å CUDA
    device = "cuda" if torch.cuda.is_available() else "cpu"
    print(f"üñ•Ô∏è  –£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: {device}")
    
    success_count = 0
    total_tests = 4
    
    # –¢–µ—Å—Ç 1: –ö–æ–º–ø–æ–Ω–µ–Ω—Ç—ã GST
    if test_gst_components():
        success_count += 1
    
    # –¢–µ—Å—Ç 2: Tacotron2 —Å GST
    if test_tacotron2_with_gst():
        success_count += 1
    
    # –¢–µ—Å—Ç 3: –†–µ–∂–∏–º—ã inference
    if test_gst_inference_modes():
        success_count += 1
    
    # –¢–µ—Å—Ç 4: –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
    print("\nüìã –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ GST...")
    hparams = create_hparams()
    print(f"   ‚úÖ use_gst: {hparams.use_gst}")
    print(f"   üî¢ token_num: {hparams.token_num}")
    print(f"   üìè token_embedding_size: {hparams.token_embedding_size}")
    print(f"   üß† ref_enc_gru_size: {hparams.ref_enc_gru_size}")
    print(f"   üë• num_heads: {hparams.num_heads}")
    success_count += 1
    
    # –ò—Ç–æ–≥–æ–≤—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç
    print("\n" + "=" * 60)
    print(f"üìä –†–ï–ó–£–õ–¨–¢–ê–¢–´ –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–Ø GST")
    print("=" * 60)
    print(f"‚úÖ –£—Å–ø–µ—à–Ω—ã—Ö —Ç–µ—Å—Ç–æ–≤: {success_count}/{total_tests}")
    
    if success_count == total_tests:
        print("üéâ –í–°–ï –¢–ï–°–¢–´ –ü–†–û–ô–î–ï–ù–´! GST –≥–æ—Ç–æ–≤ –∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é!")
        print("\nüöÄ –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏:")
        print("   ‚Ä¢ GST –≤–∫–ª—é—á–µ–Ω –∏ —Ä–∞–±–æ—Ç–∞–µ—Ç –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ")
        print("   ‚Ä¢ –ú–æ–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Ä–∞–∑–ª–∏—á–Ω—ã–µ style tokens")
        print("   ‚Ä¢ Reference mel –ø–æ–∑–≤–æ–ª—è–µ—Ç –∫–æ–ø–∏—Ä–æ–≤–∞—Ç—å —Å—Ç–∏–ª—å")
        print("   ‚Ä¢ TPSE GST –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –∏–∑–≤–ª–µ–∫–∞–µ—Ç —Å—Ç–∏–ª—å –∏–∑ —Ç–µ–∫—Å—Ç–∞")
    else:
        print("‚ö†Ô∏è  –ù–µ–∫–æ—Ç–æ—Ä—ã–µ —Ç–µ—Å—Ç—ã –Ω–µ –ø—Ä–æ—à–ª–∏. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –æ—à–∏–±–∫–∏ –≤—ã—à–µ.")
    
    print("=" * 60)

if __name__ == "__main__":
    main() 