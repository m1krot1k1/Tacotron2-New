#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
üß™ COMPREHENSIVE TEST SCRIPT FOR TRAINING FIXES
–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –≤—Å–µ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è –æ–±—É—á–µ–Ω–∏—è Tacotron2-New

–≠—Ç–æ—Ç —Å–∫—Ä–∏–ø—Ç —Ç–µ—Å—Ç–∏—Ä—É–µ—Ç:
1. ‚úÖ AdaptiveGradientClipper integration
2. ‚úÖ Alignment Diagnostics integration  
3. ‚úÖ Guided Attention Loss fixes
4. ‚úÖ Optimized hyperparameters
5. ‚úÖ Training stability improvements
"""

import sys
import os
import logging
import torch
import numpy as np
from pathlib import Path

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class TrainingFixesTest:
    """–ö–ª–∞—Å—Å –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –≤—Å–µ—Ö –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–π –æ–±—É—á–µ–Ω–∏—è."""
    
    def __init__(self):
        self.test_results = {}
        self.errors = []
        
    def run_all_tests(self):
        """–ó–∞–ø—É—Å–∫–∞–µ—Ç –≤—Å–µ —Ç–µ—Å—Ç—ã –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–π."""
        logger.info("üß™ –ù–ê–ß–ò–ù–ê–ï–ú –ö–û–ú–ü–õ–ï–ö–°–ù–û–ï –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï –ò–°–ü–†–ê–í–õ–ï–ù–ò–ô –û–ë–£–ß–ï–ù–ò–Ø")
        logger.info("=" * 60)
        
        # –¢–µ—Å—Ç 1: AdaptiveGradientClipper
        self.test_adaptive_gradient_clipper()
        
        # –¢–µ—Å—Ç 2: Alignment Diagnostics
        self.test_alignment_diagnostics()
        
        # –¢–µ—Å—Ç 3: Guided Attention fixes
        self.test_guided_attention_fixes()
        
        # –¢–µ—Å—Ç 4: Hyperparameters optimization
        self.test_hyperparameters_optimization()
        
        # –¢–µ—Å—Ç 5: Training loop integration
        self.test_training_loop_integration()
        
        # –§–∏–Ω–∞–ª—å–Ω—ã–π –æ—Ç—á–µ—Ç
        self.generate_final_report()
        
    def test_adaptive_gradient_clipper(self):
        """–¢–µ—Å—Ç 1: –ü—Ä–æ–≤–µ—Ä–∫–∞ –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ AdaptiveGradientClipper"""
        logger.info("üîß –¢–µ—Å—Ç 1: AdaptiveGradientClipper Integration")
        
        try:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ AdaptiveGradientClipper
            from smart_tuner.gradient_clipper import AdaptiveGradientClipper, get_global_clipper
            
            # –°–æ–∑–¥–∞–µ–º —Ç–µ—Å—Ç–æ–≤—ã–π clipper
            clipper = AdaptiveGradientClipper(
                max_norm=1.0,
                adaptive=True,
                emergency_threshold=100.0,
                history_size=1000,
                percentile=95
            )
            
            # –¢–µ—Å—Ç–∏—Ä—É–µ–º –±–∞–∑–æ–≤—É—é —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å
            logger.info("  ‚úÖ AdaptiveGradientClipper –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω —É—Å–ø–µ—à–Ω–æ")
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—é –≤ train.py
            with open('train.py', 'r', encoding='utf-8') as f:
                content = f.read()
            
            if 'AdaptiveGradientClipper' in content and 'get_global_clipper' in content:
                logger.info("  ‚úÖ AdaptiveGradientClipper –∏–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞–Ω –≤ train.py")
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø—Ä–∞–≤–∏–ª—å–Ω–æ—Å—Ç—å –≤—ã–∑–æ–≤–∞
                if 'clip_gradients(model, iteration)' in content:
                    logger.info("  ‚úÖ –ü—Ä–∞–≤–∏–ª—å–Ω—ã–π –≤—ã–∑–æ–≤ clip_gradients –Ω–∞–π–¥–µ–Ω")
                    self.test_results['adaptive_gradient_clipper'] = 'PASS'
                else:
                    logger.error("  ‚ùå –ù–µ–ø—Ä–∞–≤–∏–ª—å–Ω—ã–π –≤—ã–∑–æ–≤ clip_gradients")
                    self.test_results['adaptive_gradient_clipper'] = 'FAIL'
            else:
                logger.error("  ‚ùå AdaptiveGradientClipper –Ω–µ –∏–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞–Ω –≤ train.py")
                self.test_results['adaptive_gradient_clipper'] = 'FAIL'
                
        except Exception as e:
            logger.error(f"  ‚ùå –û—à–∏–±–∫–∞ —Ç–µ—Å—Ç–∞ AdaptiveGradientClipper: {e}")
            self.test_results['adaptive_gradient_clipper'] = 'ERROR'
            self.errors.append(f"AdaptiveGradientClipper: {e}")
    
    def test_alignment_diagnostics(self):
        """–¢–µ—Å—Ç 2: –ü—Ä–æ–≤–µ—Ä–∫–∞ –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ Alignment Diagnostics"""
        logger.info("üéØ –¢–µ—Å—Ç 2: Alignment Diagnostics Integration")
        
        try:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ AlignmentDiagnostics
            from alignment_diagnostics import AlignmentDiagnostics
            
            # –°–æ–∑–¥–∞–µ–º —Ç–µ—Å—Ç–æ–≤—ã–π –æ–±—ä–µ–∫—Ç
            diagnostics = AlignmentDiagnostics()
            logger.info("  ‚úÖ AlignmentDiagnostics –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω —É—Å–ø–µ—à–Ω–æ")
            
            # –¢–µ—Å—Ç–∏—Ä—É–µ–º –∞–Ω–∞–ª–∏–∑ —Ç–µ—Å—Ç–æ–≤–æ–π –º–∞—Ç—Ä–∏—Ü—ã
            test_matrix = np.random.rand(50, 30)  # [mel_time, text_time]
            results = diagnostics.analyze_alignment_matrix(test_matrix, step=100)
            
            if 'diagnostics' in results and 'overall_score' in results:
                logger.info("  ‚úÖ AlignmentDiagnostics —Ä–∞–±–æ—Ç–∞–µ—Ç –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ")
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—é –≤ train.py
                with open('train.py', 'r', encoding='utf-8') as f:
                    content = f.read()
                
                if 'alignment_diagnostics.analyze_alignment_matrix' in content:
                    logger.info("  ‚úÖ Alignment diagnostics –∏–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞–Ω –≤ train.py")
                    self.test_results['alignment_diagnostics'] = 'PASS'
                else:
                    logger.error("  ‚ùå Alignment diagnostics –Ω–µ –∏–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞–Ω –≤ train.py")
                    self.test_results['alignment_diagnostics'] = 'FAIL'
            else:
                logger.error("  ‚ùå AlignmentDiagnostics –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –Ω–µ–≤–µ—Ä–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã")
                self.test_results['alignment_diagnostics'] = 'FAIL'
                
        except Exception as e:
            logger.error(f"  ‚ùå –û—à–∏–±–∫–∞ —Ç–µ—Å—Ç–∞ Alignment Diagnostics: {e}")
            self.test_results['alignment_diagnostics'] = 'ERROR'
            self.errors.append(f"Alignment Diagnostics: {e}")
    
    def test_guided_attention_fixes(self):
        """–¢–µ—Å—Ç 3: –ü—Ä–æ–≤–µ—Ä–∫–∞ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–π Guided Attention"""
        logger.info("üéØ –¢–µ—Å—Ç 3: Guided Attention Fixes")
        
        try:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º loss_function.py
            from loss_function import GuidedAttentionLoss, Tacotron2Loss
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–æ–∑–¥–∞–Ω–∏–µ GuidedAttentionLoss
            guide_loss = GuidedAttentionLoss(alpha=2.0, sigma=0.4)
            logger.info("  ‚úÖ GuidedAttentionLoss —Å–æ–∑–¥–∞–Ω —É—Å–ø–µ—à–Ω–æ")
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—é –≤ train.py - –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –¥–≤–æ–π–Ω–æ–≥–æ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è
            with open('train.py', 'r', encoding='utf-8') as f:
                content = f.read()
            
            if 'criterion_has_guided_attention' in content and '–¥–≤–æ–π–Ω–æ–≥–æ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è guided attention' in content:
                logger.info("  ‚úÖ –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –¥–≤–æ–π–Ω–æ–≥–æ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è guided attention –Ω–∞–π–¥–µ–Ω–æ")
                self.test_results['guided_attention_fixes'] = 'PASS'
            else:
                logger.error("  ‚ùå –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –¥–≤–æ–π–Ω–æ–≥–æ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è guided attention –Ω–µ –Ω–∞–π–¥–µ–Ω–æ")
                self.test_results['guided_attention_fixes'] = 'FAIL'
                
        except Exception as e:
            logger.error(f"  ‚ùå –û—à–∏–±–∫–∞ —Ç–µ—Å—Ç–∞ Guided Attention: {e}")
            self.test_results['guided_attention_fixes'] = 'ERROR'
            self.errors.append(f"Guided Attention: {e}")
    
    def test_hyperparameters_optimization(self):
        """–¢–µ—Å—Ç 4: –ü—Ä–æ–≤–µ—Ä–∫–∞ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤"""
        logger.info("‚öôÔ∏è –¢–µ—Å—Ç 4: Hyperparameters Optimization")
        
        try:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º hparams.py
            from hparams import create_hparams
            
            hparams = create_hparams()
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
            checks = {
                'learning_rate': (hparams.learning_rate == 5e-5, f"Expected 5e-5, got {hparams.learning_rate}"),
                'grad_clip_thresh': (hparams.grad_clip_thresh == 1.0, f"Expected 1.0, got {hparams.grad_clip_thresh}"),
                'guide_loss_weight': (hparams.guide_loss_weight == 1.5, f"Expected 1.5, got {hparams.guide_loss_weight}"),
                'guide_loss_initial_weight': (hparams.guide_loss_initial_weight == 5.0, f"Expected 5.0, got {hparams.guide_loss_initial_weight}"),
                'batch_size': (hparams.batch_size == 16, f"Expected 16, got {hparams.batch_size}"),
                'gradient_accumulation_steps': (hparams.gradient_accumulation_steps == 2, f"Expected 2, got {hparams.gradient_accumulation_steps}")
            }
            
            passed_checks = 0
            for param_name, (check_result, error_msg) in checks.items():
                if check_result:
                    logger.info(f"  ‚úÖ {param_name}: –ø—Ä–∞–≤–∏–ª—å–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ")
                    passed_checks += 1
                else:
                    logger.error(f"  ‚ùå {param_name}: {error_msg}")
            
            if passed_checks == len(checks):
                logger.info("  ‚úÖ –í—Å–µ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä—ã –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω—ã")
                self.test_results['hyperparameters_optimization'] = 'PASS'
            else:
                logger.error(f"  ‚ùå {len(checks) - passed_checks} –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –Ω–µ –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω—ã")
                self.test_results['hyperparameters_optimization'] = 'FAIL'
                
        except Exception as e:
            logger.error(f"  ‚ùå –û—à–∏–±–∫–∞ —Ç–µ—Å—Ç–∞ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤: {e}")
            self.test_results['hyperparameters_optimization'] = 'ERROR'
            self.errors.append(f"Hyperparameters: {e}")
    
    def test_training_loop_integration(self):
        """–¢–µ—Å—Ç 5: –ü—Ä–æ–≤–µ—Ä–∫–∞ –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ –≤ –æ—Å–Ω–æ–≤–Ω–æ–π —Ü–∏–∫–ª –æ–±—É—á–µ–Ω–∏—è"""
        logger.info("üîÑ –¢–µ—Å—Ç 5: Training Loop Integration")
        
        try:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ –≤ train.py
            with open('train.py', 'r', encoding='utf-8') as f:
                content = f.read()
            
            integrations = {
                'smart_tuner_gradient_clipper': 'smart_tuner.gradient_clipper import get_global_clipper',
                'alignment_diagnostics_import': 'from alignment_diagnostics import AlignmentDiagnostics',
                'guided_attention_double_check': 'criterion_has_guided_attention',
                'adaptive_clipping_usage': 'clip_gradients(model, iteration)',
                'alignment_analysis': 'analyze_alignment_matrix'
            }
            
            passed_integrations = 0
            for integration_name, search_pattern in integrations.items():
                if search_pattern in content:
                    logger.info(f"  ‚úÖ {integration_name}: –∏–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞–Ω")
                    passed_integrations += 1
                else:
                    logger.error(f"  ‚ùå {integration_name}: –Ω–µ –Ω–∞–π–¥–µ–Ω")
            
            if passed_integrations == len(integrations):
                logger.info("  ‚úÖ –í—Å–µ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ –≤ training loop –Ω–∞–π–¥–µ–Ω—ã")
                self.test_results['training_loop_integration'] = 'PASS'
            else:
                logger.error(f"  ‚ùå {len(integrations) - passed_integrations} –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–π –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç")
                self.test_results['training_loop_integration'] = 'FAIL'
                
        except Exception as e:
            logger.error(f"  ‚ùå –û—à–∏–±–∫–∞ —Ç–µ—Å—Ç–∞ –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏: {e}")
            self.test_results['training_loop_integration'] = 'ERROR'
            self.errors.append(f"Training Loop Integration: {e}")
    
    def generate_final_report(self):
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Ñ–∏–Ω–∞–ª—å–Ω—ã–π –æ—Ç—á–µ—Ç –æ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–∏."""
        logger.info("")
        logger.info("=" * 60)
        logger.info("üìä –§–ò–ù–ê–õ–¨–ù–´–ô –û–¢–ß–ï–¢ –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–Ø –ò–°–ü–†–ê–í–õ–ï–ù–ò–ô")
        logger.info("=" * 60)
        
        total_tests = len(self.test_results)
        passed_tests = len([r for r in self.test_results.values() if r == 'PASS'])
        failed_tests = len([r for r in self.test_results.values() if r == 'FAIL'])
        error_tests = len([r for r in self.test_results.values() if r == 'ERROR'])
        
        logger.info(f"–í—Å–µ–≥–æ —Ç–µ—Å—Ç–æ–≤: {total_tests}")
        logger.info(f"‚úÖ –ü—Ä–æ—à–ª–æ: {passed_tests}")
        logger.info(f"‚ùå –ü—Ä–æ–≤–∞–ª–µ–Ω–æ: {failed_tests}")
        logger.info(f"üö® –û—à–∏–±–∫–∏: {error_tests}")
        logger.info("")
        
        # –î–µ—Ç–∞–ª—å–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        for test_name, result in self.test_results.items():
            status_icon = {"PASS": "‚úÖ", "FAIL": "‚ùå", "ERROR": "üö®"}[result]
            logger.info(f"{status_icon} {test_name}: {result}")
        
        logger.info("")
        
        # –û—à–∏–±–∫–∏
        if self.errors:
            logger.info("üö® –û–ë–ù–ê–†–£–ñ–ï–ù–ù–´–ï –û–®–ò–ë–ö–ò:")
            for error in self.errors:
                logger.error(f"  ‚Ä¢ {error}")
            logger.info("")
        
        # –ò—Ç–æ–≥–æ–≤–∞—è –æ—Ü–µ–Ω–∫–∞
        success_rate = (passed_tests / total_tests) * 100 if total_tests > 0 else 0
        
        if success_rate >= 80:
            logger.info(f"üéâ –û–¢–õ–ò–ß–ù–û! –í—Å–µ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è —Ä–∞–±–æ—Ç–∞—é—Ç ({success_rate:.1f}% —É—Å–ø–µ—Ö–∞)")
            logger.info("‚úÖ –°–∏—Å—Ç–µ–º–∞ –≥–æ—Ç–æ–≤–∞ –∫ –æ–±—É—á–µ–Ω–∏—é —Å –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è–º–∏")
        elif success_rate >= 60:
            logger.info(f"‚ö†Ô∏è –•–û–†–û–®–û. –ë–æ–ª—å—à–∏–Ω—Å—Ç–≤–æ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–π —Ä–∞–±–æ—Ç–∞–µ—Ç ({success_rate:.1f}% —É—Å–ø–µ—Ö–∞)")
            logger.info("üîß –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –∏—Å–ø—Ä–∞–≤–∏—Ç—å –æ—Å—Ç–∞–≤—à–∏–µ—Å—è –ø—Ä–æ–±–ª–µ–º—ã")
        else:
            logger.error(f"‚ùå –ö–†–ò–¢–ò–ß–ù–û! –ú–Ω–æ–≥–æ –ø—Ä–æ–±–ª–µ–º —Å –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è–º–∏ ({success_rate:.1f}% —É—Å–ø–µ—Ö–∞)")
            logger.error("üö® –ù–µ–æ–±—Ö–æ–¥–∏–º—ã –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è –ø–µ—Ä–µ–¥ –æ–±—É—á–µ–Ω–∏–µ–º")
        
        logger.info("")
        logger.info("=" * 60)
        
        # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
        logger.info("üí° –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò –î–õ–Ø –°–¢–ê–ë–ò–õ–¨–ù–û–ì–û –û–ë–£–ß–ï–ù–ò–Ø:")
        logger.info("1. üéØ –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –Ω–∞—á–∞–ª—å–Ω—ã–π learning_rate=5e-5")
        logger.info("2. üìä –ú–æ–Ω–∏—Ç–æ—Ä—å—Ç–µ gradient norms (–¥–æ–ª–∂–Ω—ã –±—ã—Ç—å <10 –¥–ª—è —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏)")  
        logger.info("3. üîß –ü—Ä–æ–≤–µ—Ä—è–π—Ç–µ alignment diagonality –∫–∞–∂–¥—ã–µ 100 —à–∞–≥–æ–≤")
        logger.info("4. üö® –ü—Ä–∏ gradient explosion >100 —Å–∏—Å—Ç–µ–º–∞ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —Å–Ω–∏–∑–∏—Ç LR")
        logger.info("5. üìà Alignment diagnostics –±—É–¥—É—Ç –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–∞—Ç—å –æ –ø—Ä–æ–±–ª–µ–º–∞—Ö")
        logger.info("=" * 60)

if __name__ == "__main__":
    # –ó–∞–ø—É—Å–∫–∞–µ–º —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ
    tester = TrainingFixesTest()
    tester.run_all_tests() 