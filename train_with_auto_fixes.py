#!/usr/bin/env python3
"""
üöÄ –£–ª—É—á—à–µ–Ω–Ω—ã–π –∑–∞–ø—É—Å–∫ –æ–±—É—á–µ–Ω–∏—è —Å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–º–∏ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è–º–∏
–ò–Ω—Ç–µ–≥—Ä–∏—Ä—É–µ—Ç –≤—Å–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã: EnhancedTacotronTrainer + AutoFixManager + Smart Tuner + Telegram

–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ:
python train_with_auto_fixes.py --epochs 10 --batch_size 16
"""

import argparse
import sys
import os
import torch
import logging
from pathlib import Path

# –î–æ–±–∞–≤–ª—è–µ–º –∫–æ—Ä–Ω–µ–≤—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –≤ –ø—É—Ç—å
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from enhanced_training_main import EnhancedTacotronTrainer, prepare_dataloaders
from hparams import create_hparams

def setup_logging():
    """–ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è"""
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
        handlers=[
            logging.StreamHandler(),
            logging.FileHandler('training_with_auto_fixes.log')
        ]
    )
    return logging.getLogger('TrainingWithAutoFixes')

def create_optimized_hparams(args):
    """–°–æ–∑–¥–∞–µ—Ç –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è —Å—Ç–∞–±–∏–ª—å–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è"""
    hparams = create_hparams()
    
    # üîß –ë–µ–∑–æ–ø–∞—Å–Ω—ã–µ –Ω–∞—á–∞–ª—å–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
    hparams.learning_rate = 1e-4  # –ö–æ–Ω—Å–µ—Ä–≤–∞—Ç–∏–≤–Ω—ã–π learning rate
    hparams.batch_size = args.batch_size if args.batch_size else 8
    hparams.grad_clip_thresh = 1.0  # –°—Ç—Ä–æ–≥–æ–µ –∫–ª–∏–ø–∏—Ä–æ–≤–∞–Ω–∏–µ –≥—Ä–∞–¥–∏–µ–Ω—Ç–æ–≤
    
    # üéØ –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–∞—è –∞–∫—Ç–∏–≤–∞—Ü–∏—è guided attention
    hparams.use_guided_attn = True
    hparams.guide_loss_weight = 10.0  # –í—ã—Å–æ–∫–∏–π –Ω–∞—á–∞–ª—å–Ω—ã–π –≤–µ—Å
    hparams.guide_loss_initial_weight = 10.0
    
    # üõ°Ô∏è –ö–æ–Ω—Å–µ—Ä–≤–∞—Ç–∏–≤–Ω—ã–µ dropout –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
    hparams.p_attention_dropout = 0.01  # –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π dropout
    hparams.p_decoder_dropout = 0.01
    
    # üö™ –°–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–π gate threshold
    hparams.gate_threshold = 0.5
    
    # üìä –£–≤–µ–ª–∏—á–µ–Ω–Ω—ã–µ –∏–Ω—Ç–µ—Ä–≤–∞–ª—ã –ø—Ä–æ–≤–µ—Ä–∫–∏ –¥–ª—è —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏
    hparams.iters_per_checkpoint = 500
    hparams.epochs_per_checkpoint = 1
    
    # üö´ –û—Ç–∫–ª—é—á–µ–Ω–∏–µ –Ω–µ—Å—Ç–∞–±–∏–ª—å–Ω—ã—Ö —Ñ—É–Ω–∫—Ü–∏–π
    hparams.use_mmi = False
    hparams.fp16_run = False  # –û—Ç–∫–ª—é—á–∞–µ–º fp16 –¥–ª—è –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏
    
    return hparams

def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –∑–∞–ø—É—Å–∫–∞ –æ–±—É—á–µ–Ω–∏—è"""
    parser = argparse.ArgumentParser(description='–û–±—É—á–µ–Ω–∏–µ Tacotron2 —Å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–º–∏ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è–º–∏')
    parser.add_argument('--epochs', type=int, default=10, help='–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —ç–ø–æ—Ö')
    parser.add_argument('--batch_size', type=int, default=8, help='–†–∞–∑–º–µ—Ä –±–∞—Ç—á–∞')
    parser.add_argument('--checkpoint', type=str, help='–ü—É—Ç—å –∫ checkpoint –¥–ª—è –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏—è')
    parser.add_argument('--output_dir', type=str, default='output_auto_fixes', help='–î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è')
    parser.add_argument('--log_dir', type=str, default='logs_auto_fixes', help='–î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è –ª–æ–≥–æ–≤')
    parser.add_argument('--disable_telegram', action='store_true', help='–û—Ç–∫–ª—é—á–∏—Ç—å Telegram —É–≤–µ–¥–æ–º–ª–µ–Ω–∏—è')
    parser.add_argument('--disable_mlflow', action='store_true', help='–û—Ç–∫–ª—é—á–∏—Ç—å MLflow –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ')
    
    args = parser.parse_args()
    
    # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
    logger = setup_logging()
    logger.info("üöÄ –ó–∞–ø—É—Å–∫ –æ–±—É—á–µ–Ω–∏—è —Å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–º–∏ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è–º–∏")
    
    try:
        # –°–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
        Path(args.output_dir).mkdir(exist_ok=True)
        Path(args.log_dir).mkdir(exist_ok=True)
        
        # –°–æ–∑–¥–∞–µ–º –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä—ã
        hparams = create_optimized_hparams(args)
        logger.info(f"üìã –ì–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä—ã: LR={hparams.learning_rate:.2e}, BS={hparams.batch_size}")
        
        # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ
        logger.info("üì¶ –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö...")
        train_loader, val_loader = prepare_dataloaders(hparams)
        logger.info(f"‚úÖ –î–∞–Ω–Ω—ã–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã: {len(train_loader)} –±–∞—Ç—á–µ–π –¥–ª—è –æ–±—É—á–µ–Ω–∏—è")
        
        # –°–æ–∑–¥–∞–µ–º EnhancedTacotronTrainer —Å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–º–∏ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è–º–∏
        logger.info("ü§ñ –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è EnhancedTacotronTrainer —Å AutoFixManager...")
        trainer = EnhancedTacotronTrainer(
            hparams=hparams,
            dataset_info={'train_size': len(train_loader), 'val_size': len(val_loader) if val_loader else 0}
        )
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –æ–±—É—á–µ–Ω–∏–µ
        trainer.initialize_training()
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—é AutoFixManager
        if hasattr(trainer, 'auto_fix_manager') and trainer.auto_fix_manager:
            logger.info("‚úÖ AutoFixManager —É—Å–ø–µ—à–Ω–æ –∏–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞–Ω")
        else:
            logger.warning("‚ö†Ô∏è AutoFixManager –Ω–µ –Ω–∞–π–¥–µ–Ω - –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è –æ—Ç–∫–ª—é—á–µ–Ω—ã")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—é Smart Tuner
        if hasattr(trainer, 'smart_tuner') and trainer.smart_tuner:
            logger.info("‚úÖ Smart Tuner —É—Å–ø–µ—à–Ω–æ –∏–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞–Ω")
        else:
            logger.warning("‚ö†Ô∏è Smart Tuner –Ω–µ –Ω–∞–π–¥–µ–Ω - –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –æ—Ç–∫–ª—é—á–µ–Ω–∞")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—é Telegram –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞
        if hasattr(trainer, 'telegram_monitor') and trainer.telegram_monitor:
            logger.info("‚úÖ Telegram –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ —É—Å–ø–µ—à–Ω–æ –∏–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞–Ω")
        else:
            logger.warning("‚ö†Ô∏è Telegram –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –Ω–µ –Ω–∞–π–¥–µ–Ω - —É–≤–µ–¥–æ–º–ª–µ–Ω–∏—è –æ—Ç–∫–ª—é—á–µ–Ω—ã")
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º checkpoint –µ—Å–ª–∏ —É–∫–∞–∑–∞–Ω
        if args.checkpoint and os.path.exists(args.checkpoint):
            logger.info(f"üìÇ –ó–∞–≥—Ä—É–∑–∫–∞ checkpoint: {args.checkpoint}")
            trainer.load_checkpoint(args.checkpoint)
        
        # –ó–∞–ø—É—Å–∫–∞–µ–º –æ–±—É—á–µ–Ω–∏–µ
        logger.info(f"üéØ –ù–∞—á–∏–Ω–∞–µ–º –æ–±—É—á–µ–Ω–∏–µ –Ω–∞ {args.epochs} —ç–ø–æ—Ö...")
        trainer.train(
            train_loader=train_loader,
            val_loader=val_loader,
            max_epochs=args.epochs
        )
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—É—é –º–æ–¥–µ–ª—å
        final_checkpoint = os.path.join(args.output_dir, 'final_model_auto_fixes.pth')
        trainer.save_checkpoint(final_checkpoint, {'epoch': args.epochs, 'final': True})
        logger.info(f"üíæ –§–∏–Ω–∞–ª—å–Ω–∞—è –º–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: {final_checkpoint}")
        
        # –í—ã–≤–æ–¥–∏–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏—Ö –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–π
        if hasattr(trainer, 'auto_fix_manager') and trainer.auto_fix_manager:
            stats = trainer.auto_fix_manager.get_fix_statistics()
            logger.info("üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏—Ö –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–π:")
            logger.info(f"  –í—Å–µ–≥–æ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–π: {stats['total_fixes']}")
            logger.info(f"  –£—Å–ø–µ—à–Ω—ã—Ö –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–π: {stats['successful_fixes']}")
            logger.info(f"  –°—á–µ—Ç—á–∏–∫–∏ –ø—Ä–æ–±–ª–µ–º: {stats['problem_counters']}")
        
        logger.info("üéâ –û–±—É—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ —É—Å–ø–µ—à–Ω–æ!")
        
    except KeyboardInterrupt:
        logger.info("‚èπÔ∏è –û–±—É—á–µ–Ω–∏–µ –ø—Ä–µ—Ä–≤–∞–Ω–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º")
        if 'trainer' in locals():
            trainer.save_checkpoint(
                os.path.join(args.output_dir, 'interrupted_auto_fixes.pth'),
                {'interrupted': True}
            )
            logger.info("üíæ Checkpoint —Å–æ—Ö—Ä–∞–Ω–µ–Ω –ø—Ä–∏ –ø—Ä–µ—Ä—ã–≤–∞–Ω–∏–∏")
        
    except Exception as e:
        logger.error(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {e}")
        import traceback
        logger.error(f"Traceback: {traceback.format_exc()}")
        
        # –ü—ã—Ç–∞–µ–º—Å—è —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å checkpoint –ø—Ä–∏ –æ—à–∏–±–∫–µ
        if 'trainer' in locals():
            try:
                trainer.save_checkpoint(
                    os.path.join(args.output_dir, 'error_auto_fixes.pth'),
                    {'error': str(e)}
                )
                logger.info("üíæ Checkpoint —Å–æ—Ö—Ä–∞–Ω–µ–Ω –ø—Ä–∏ –æ—à–∏–±–∫–µ")
            except:
                pass
        
        sys.exit(1)

if __name__ == "__main__":
    main() 