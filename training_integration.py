#!/usr/bin/env python3
"""
–ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å–∏—Å—Ç–µ–º —ç–∫—Å–ø–æ—Ä—Ç–∞ –∏ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è –≤ –ø—Ä–æ—Ü–µ—Å—Å –æ–±—É—á–µ–Ω–∏—è TTS

–ê–≤—Ç–æ—Ä: AI Assistant  
–ù–∞–∑–Ω–∞—á–µ–Ω–∏–µ: –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ —É–º–Ω—ã—Ö —Å–∏—Å—Ç–µ–º –∫ train.py
"""

import os
import sys
from pathlib import Path

# –î–æ–±–∞–≤–ª—è–µ–º —Ç–µ–∫—É—â—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –≤ –ø—É—Ç—å
current_dir = Path(__file__).parent
sys.path.append(str(current_dir))

try:
    from training_export_system import TrainingExportSystem, export_training_for_ai
    from smart_training_logger import SmartTrainingLogger, get_training_logger
    from smart_training_logger import log_training_start, log_training_metrics, log_param_change
    from smart_training_logger import log_training_warning, log_training_end
except ImportError as e:
    print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –∏–º–ø–æ—Ä—Ç–∞ –º–æ–¥—É–ª–µ–π –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è: {e}")
    print("–°–æ–∑–¥–∞–π—Ç–µ —Ñ–∞–π–ª—ã training_export_system.py –∏ smart_training_logger.py")

def setup_training_logging(run_id: str, hparams):
    """
    –ù–∞—Å—Ç—Ä–æ–π–∫–∞ —Å–∏—Å—Ç–µ–º –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è –¥–ª—è –æ–±—É—á–µ–Ω–∏—è
    
    Args:
        run_id: MLflow run ID
        hparams: –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –æ–±—É—á–µ–Ω–∏—è
    
    Returns:
        Tuple[TrainingExportSystem, SmartTrainingLogger]
    """
    print("üîß –ù–∞—Å—Ç—Ä–æ–π–∫–∞ —Å–∏—Å—Ç–µ–º –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è...")
    
    # –°–æ–∑–¥–∞–µ–º —Å–∏—Å—Ç–µ–º—ã
    export_system = TrainingExportSystem()
    
    # –ù–∞—á–∏–Ω–∞–µ–º —Å–µ—Å—Å–∏—é –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
    training_params = {
        "learning_rate": hparams.learning_rate,
        "batch_size": hparams.batch_size,
        "warmup_steps": hparams.warmup_steps,
        "model": "Tacotron2",
        "optimizer": "Adam",
        "scheduler": hparams.lr_scheduler_type if hasattr(hparams, 'lr_scheduler_type') else "StepLR",
        "early_stopping": hparams.early_stopping if hasattr(hparams, 'early_stopping') else True,
        "mixed_precision": hparams.fp16_run if hasattr(hparams, 'fp16_run') else False
    }
    
    session_id = log_training_start(run_id, training_params)
    
    print(f"‚úÖ –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–æ. Session ID: {session_id}")
    
    return export_system, get_training_logger()

def log_step_metrics(step: int, metrics: dict):
    """
    –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –º–µ—Ç—Ä–∏–∫ —à–∞–≥–∞ –æ–±—É—á–µ–Ω–∏—è
    
    Args:
        step: –Ω–æ–º–µ—Ä —à–∞–≥–∞
        metrics: —Å–ª–æ–≤–∞—Ä—å —Å –º–µ—Ç—Ä–∏–∫–∞–º–∏
    """
    try:
        # –ü—Ä–∏–≤–æ–¥–∏–º –º–µ—Ç—Ä–∏–∫–∏ –∫ –Ω—É–∂–Ω–æ–º—É —Ñ–æ—Ä–º–∞—Ç—É
        clean_metrics = {}
        for key, value in metrics.items():
            if isinstance(value, (int, float)):
                clean_metrics[key] = float(value)
            elif hasattr(value, 'item'):  # torch.Tensor
                clean_metrics[key] = float(value.item())
            else:
                clean_metrics[key] = str(value)
        
        log_training_metrics(step, clean_metrics)
        
    except Exception as e:
        print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è –º–µ—Ç—Ä–∏–∫ –Ω–∞ —à–∞–≥–µ {step}: {e}")

def log_smart_tuner_change(param_name: str, old_value, new_value, reason: str):
    """
    –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è –ø–∞—Ä–∞–º–µ—Ç—Ä–∞ —É–º–Ω–æ–π —Å–∏—Å—Ç–µ–º–æ–π
    
    Args:
        param_name: –∏–º—è –ø–∞—Ä–∞–º–µ—Ç—Ä–∞
        old_value: —Å—Ç–∞—Ä–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ
        new_value: –Ω–æ–≤–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ
        reason: –ø—Ä–∏—á–∏–Ω–∞ –∏–∑–º–µ–Ω–µ–Ω–∏—è
    """
    try:
        log_param_change(param_name, old_value, new_value, reason)
        print(f"üìù –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–æ –∏–∑–º–µ–Ω–µ–Ω–∏–µ {param_name}: {old_value} ‚Üí {new_value}")
        
    except Exception as e:
        print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è –∏–∑–º–µ–Ω–µ–Ω–∏—è –ø–∞—Ä–∞–º–µ—Ç—Ä–∞: {e}")

def log_training_warning_event(warning_type: str, message: str, data: dict = None):
    """
    –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è
    
    Args:
        warning_type: —Ç–∏–ø –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è
        message: —Å–æ–æ–±—â–µ–Ω–∏–µ
        data: –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
    """
    try:
        log_training_warning(warning_type, message, data)
        print(f"‚ö†Ô∏è –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–æ –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ: {warning_type}")
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è: {e}")

def finish_training_logging(final_metrics: dict = None, status: str = "completed"):
    """
    –ó–∞–≤–µ—Ä—à–µ–Ω–∏–µ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è –æ–±—É—á–µ–Ω–∏—è
    
    Args:
        final_metrics: —Ñ–∏–Ω–∞–ª—å–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏
        status: —Å—Ç–∞—Ç—É—Å –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è
    """
    try:
        # –ü—Ä–∏–≤–æ–¥–∏–º –º–µ—Ç—Ä–∏–∫–∏ –∫ –Ω—É–∂–Ω–æ–º—É —Ñ–æ—Ä–º–∞—Ç—É
        clean_final_metrics = {}
        if final_metrics:
            for key, value in final_metrics.items():
                if isinstance(value, (int, float)):
                    clean_final_metrics[key] = float(value)
                elif hasattr(value, 'item'):  # torch.Tensor
                    clean_final_metrics[key] = float(value.item())
                else:
                    clean_final_metrics[key] = str(value)
        
        log_training_end(clean_final_metrics, status)
        print(f"üèÅ –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ —Å–æ —Å—Ç–∞—Ç—É—Å–æ–º: {status}")
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è: {e}")

def export_current_training(run_id: str = None):
    """
    –≠–∫—Å–ø–æ—Ä—Ç —Ç–µ–∫—É—â–µ–≥–æ –æ–±—É—á–µ–Ω–∏—è –¥–ª—è –æ—Ç–ø—Ä–∞–≤–∫–∏ AI
    
    Args:
        run_id: MLflow run ID
    
    Returns:
        –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É –¥–ª—è –æ—Ç–ø—Ä–∞–≤–∫–∏ AI
    """
    try:
        text_file = export_training_for_ai(run_id)
        
        if text_file:
            print(f"\n" + "="*60)
            print("üì§ –≠–ö–°–ü–û–†–¢ –î–õ–Ø AI –ì–û–¢–û–í!")
            print("="*60)
            print(f"–§–∞–π–ª: {text_file}")
            print("üìã –°–∫–æ–ø–∏—Ä—É–π—Ç–µ —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ —Ñ–∞–π–ª–∞ –∏ –æ—Ç–ø—Ä–∞–≤—å—Ç–µ AI Assistant")
            print("="*60)
            
            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ —Å—Ç—Ä–æ–∫–∏ —Ñ–∞–π–ª–∞
            try:
                with open(text_file, 'r', encoding='utf-8') as f:
                    lines = f.readlines()[:10]
                    print("–ü—Ä–µ–¥–ø—Ä–æ—Å–º–æ—Ç—Ä:")
                    for line in lines:
                        print(f"  {line.rstrip()}")
                    if len(lines) >= 10:
                        print("  ...")
            except Exception:
                pass
        
        return text_file
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ —ç–∫—Å–ø–æ—Ä—Ç–∞ –æ–±—É—á–µ–Ω–∏—è: {e}")
        return None

# –ü–∞—Ç—á–∏ –¥–ª—è –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ —Å train.py
def patch_train_logging():
    """
    –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –ø–∞—Ç—á–∏–Ω–≥ train.py –¥–ª—è –¥–æ–±–∞–≤–ª–µ–Ω–∏—è –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
    """
    train_file = Path("train.py")
    
    if not train_file.exists():
        print("‚ùå –§–∞–π–ª train.py –Ω–µ –Ω–∞–π–¥–µ–Ω")
        return False
    
    try:
        # –ß–∏—Ç–∞–µ–º train.py
        with open(train_file, 'r', encoding='utf-8') as f:
            content = f.read()
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —É–∂–µ –ª–∏ –¥–æ–±–∞–≤–ª–µ–Ω–æ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ
        if "from training_integration import" in content:
            print("‚úÖ –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ —É–∂–µ –∏–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞–Ω–æ –≤ train.py")
            return True
        
        # –î–æ–±–∞–≤–ª—è–µ–º –∏–º–ø–æ—Ä—Ç—ã
        import_line = """
# === –ò–ù–¢–ï–ì–†–ê–¶–ò–Ø –£–ú–ù–û–ì–û –õ–û–ì–ò–†–û–í–ê–ù–ò–Ø ===
try:
    from training_integration import setup_training_logging, log_step_metrics
    from training_integration import log_smart_tuner_change, log_training_warning_event
    from training_integration import finish_training_logging, export_current_training
    SMART_LOGGING_ENABLED = True
    print("‚úÖ –£–º–Ω–æ–µ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –∞–∫—Ç–∏–≤–∏—Ä–æ–≤–∞–Ω–æ")
except ImportError as e:
    print(f"‚ö†Ô∏è –£–º–Ω–æ–µ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–æ: {e}")
    SMART_LOGGING_ENABLED = False
# === –ö–û–ù–ï–¶ –ò–ù–¢–ï–ì–†–ê–¶–ò–ò ===
"""
        
        # –í—Å—Ç–∞–≤–ª—è–µ–º –ø–æ—Å–ª–µ –∏–º–ø–æ—Ä—Ç–æ–≤ MLflow
        if "import mlflow" in content:
            content = content.replace(
                "import mlflow",
                "import mlflow" + import_line
            )
        else:
            # –ï—Å–ª–∏ –Ω–µ—Ç MLflow, –¥–æ–±–∞–≤–ª—è–µ–º –≤ –Ω–∞—á–∞–ª–æ –ø–æ—Å–ª–µ –æ—Å–Ω–æ–≤–Ω—ã—Ö –∏–º–ø–æ—Ä—Ç–æ–≤
            lines = content.split('\n')
            insert_pos = 0
            for i, line in enumerate(lines):
                if line.startswith('import ') or line.startswith('from '):
                    insert_pos = i + 1
            
            lines.insert(insert_pos, import_line)
            content = '\n'.join(lines)
        
        # –°–æ–∑–¥–∞–µ–º —Ä–µ–∑–µ—Ä–≤–Ω—É—é –∫–æ–ø–∏—é
        backup_file = train_file.with_suffix('.py.backup')
        with open(backup_file, 'w', encoding='utf-8') as f:
            f.write(content)
        
        print(f"üìÑ –°–æ–∑–¥–∞–Ω–∞ —Ä–µ–∑–µ—Ä–≤–Ω–∞—è –∫–æ–ø–∏—è: {backup_file}")
        
        # –ò–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏ –ø–æ –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏
        print("\n" + "="*60)
        print("üìã –ò–ù–°–¢–†–£–ö–¶–ò–ò –ü–û –ò–ù–¢–ï–ì–†–ê–¶–ò–ò")
        print("="*60)
        print("–î–æ–±–∞–≤—å—Ç–µ —Å–ª–µ–¥—É—é—â–∏–µ –≤—ã–∑–æ–≤—ã –≤ train.py:")
        print("")
        print("1. –í –Ω–∞—á–∞–ª–µ –æ–±—É—á–µ–Ω–∏—è (–ø–æ—Å–ª–µ mlflow.start_run):")
        print("   if SMART_LOGGING_ENABLED:")
        print("       export_system, logger = setup_training_logging(run.info.run_id, hparams)")
        print("")
        print("2. –í —Ü–∏–∫–ª–µ –æ–±—É—á–µ–Ω–∏—è (–∫–∞–∂–¥—ã–µ N —à–∞–≥–æ–≤):")
        print("   if SMART_LOGGING_ENABLED and iteration % 10 == 0:")
        print("       log_step_metrics(iteration, {")
        print("           'training.loss': train_loss,")
        print("           'validation.loss': val_loss,")
        print("           'grad_norm': grad_norm,")
        print("           'learning_rate': optimizer.param_groups[0]['lr']")
        print("       })")
        print("")
        print("3. –ü—Ä–∏ –∏–∑–º–µ–Ω–µ–Ω–∏–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ —É–º–Ω–æ–π —Å–∏—Å—Ç–µ–º–æ–π:")
        print("   if SMART_LOGGING_ENABLED:")
        print("       log_smart_tuner_change('learning_rate', old_lr, new_lr, '–ì—Ä–∞–¥–∏–µ–Ω—Ç—ã –Ω–µ—Å—Ç–∞–±–∏–ª—å–Ω—ã')")
        print("")
        print("4. –í –∫–æ–Ω—Ü–µ –æ–±—É—á–µ–Ω–∏—è:")
        print("   if SMART_LOGGING_ENABLED:")
        print("       finish_training_logging({'final_loss': final_loss}, 'completed')")
        print("       export_current_training(run.info.run_id)")
        print("")
        print("="*60)
        
        return True
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø–∞—Ç—á–∏–Ω–≥–∞ train.py: {e}")
        return False

if __name__ == "__main__":
    print("üöÄ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ —É–º–Ω–æ–≥–æ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è")
    
    # –¢–µ—Å—Ç –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
    class MockHparams:
        learning_rate = 0.001
        batch_size = 32
        warmup_steps = 1000
        
    mock_hparams = MockHparams()
    
    try:
        export_system, logger = setup_training_logging("test_run_12345", mock_hparams)
        
        # –¢–µ—Å—Ç –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è –º–µ—Ç—Ä–∏–∫
        log_step_metrics(100, {
            "training.loss": 2.5,
            "validation.loss": 2.8,
            "grad_norm": 5.2,
            "learning_rate": 0.001
        })
        
        # –¢–µ—Å—Ç –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è –∏–∑–º–µ–Ω–µ–Ω–∏—è –ø–∞—Ä–∞–º–µ—Ç—Ä–∞
        log_smart_tuner_change(
            "learning_rate", 
            0.001, 
            0.0008, 
            "–í—ã—Å–æ–∫–∞—è –Ω–æ—Ä–º–∞ –≥—Ä–∞–¥–∏–µ–Ω—Ç–æ–≤"
        )
        
        # –¢–µ—Å—Ç –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è
        log_training_warning_event(
            "GradientWarning",
            "–ì—Ä–∞–¥–∏–µ–Ω—Ç—ã –ø—Ä–µ–≤—ã—à–∞—é—Ç –ø–æ—Ä–æ–≥",
            {"grad_norm": 50.0}
        )
        
        # –ó–∞–≤–µ—Ä—à–µ–Ω–∏–µ
        finish_training_logging(
            {"final_loss": 1.2}, 
            "completed"
        )
        
        print("‚úÖ –¢–µ—Å—Ç –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ –∑–∞–≤–µ—Ä—à–µ–Ω —É—Å–ø–µ—à–Ω–æ")
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ —Ç–µ—Å—Ç–∞: {e}")
    
    # –¢–µ—Å—Ç –ø–∞—Ç—á–∏–Ω–≥–∞
    print("\nüîß –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–∞—Ç—á–∏–Ω–≥–∞ train.py...")
    patch_train_logging() 